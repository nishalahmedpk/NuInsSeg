{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a486d80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:36.395218Z",
     "iopub.status.busy": "2025-10-14T09:19:36.394796Z",
     "iopub.status.idle": "2025-10-14T09:19:36.403432Z",
     "shell.execute_reply": "2025-10-14T09:19:36.402779Z"
    },
    "papermill": {
     "duration": 0.023288,
     "end_time": "2025-10-14T09:19:36.404962",
     "exception": false,
     "start_time": "2025-10-14T09:19:36.381674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## disabeling warning msg\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import sys\n",
    "sys.stdout.flush() # resolving tqdm problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f33f73",
   "metadata": {
    "papermill": {
     "duration": 0.004776,
     "end_time": "2025-10-14T09:19:36.415248",
     "exception": false,
     "start_time": "2025-10-14T09:19:36.410472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fba48f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:36.426857Z",
     "iopub.status.busy": "2025-10-14T09:19:36.425963Z",
     "iopub.status.idle": "2025-10-14T09:19:53.845406Z",
     "shell.execute_reply": "2025-10-14T09:19:53.844684Z"
    },
    "papermill": {
     "duration": 17.426786,
     "end_time": "2025-10-14T09:19:53.847017",
     "exception": false,
     "start_time": "2025-10-14T09:19:36.420231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760433578.354657      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760433578.410037      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de007ba0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.859011Z",
     "iopub.status.busy": "2025-10-14T09:19:53.858424Z",
     "iopub.status.idle": "2025-10-14T09:19:53.864455Z",
     "shell.execute_reply": "2025-10-14T09:19:53.863736Z"
    },
    "papermill": {
     "duration": 0.013444,
     "end_time": "2025-10-14T09:19:53.865770",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.852326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "#####################################################################################\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
    "#####################################################################################################################\n",
    "def mse_score(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3662be29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.877744Z",
     "iopub.status.busy": "2025-10-14T09:19:53.876991Z",
     "iopub.status.idle": "2025-10-14T09:19:53.896983Z",
     "shell.execute_reply": "2025-10-14T09:19:53.896050Z"
    },
    "papermill": {
     "duration": 0.027449,
     "end_time": "2025-10-14T09:19:53.898375",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.870926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dual_decoder_unet_binary(IMG_CHANNELS, LearnRate):\n",
    "    inputs = Input((None, None, IMG_CHANNELS))\n",
    "    #encoder\n",
    "    s = Lambda(lambda x: x / 255)(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.1)(c5)\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    ## decoder for dis unet\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs1 = Conv2D(1, (1, 1), activation='linear', name='output_dis')(c9)\n",
    "\n",
    "\n",
    "    ## decoder for segmentation unet\n",
    "    u6_seg = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6_seg = concatenate([u6_seg, c4])\n",
    "    c6_seg = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6_seg)\n",
    "    c6_seg = Dropout(0.2)(c6_seg)\n",
    "    c6_seg = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6_seg)\n",
    "\n",
    "    u7_seg = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6_seg)\n",
    "    u7_seg = concatenate([u7_seg, c3])\n",
    "    c7_seg = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7_seg)\n",
    "    c7_seg = Dropout(0.2)(c7_seg)\n",
    "    c7_seg = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7_seg)\n",
    "\n",
    "    u8_seg = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7_seg)\n",
    "    u8_seg = concatenate([u8_seg, c2])\n",
    "    c8_seg = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8_seg)\n",
    "    c8_seg = Dropout(0.1)(c8_seg)\n",
    "    c8_seg = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8_seg)\n",
    "\n",
    "    u9_seg = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8_seg)\n",
    "    u9_seg = concatenate([u9_seg, c1], axis=3)\n",
    "    c9_seg = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9_seg)\n",
    "    c9_seg = Dropout(0.1)(c9_seg)\n",
    "    c9_seg = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9_seg)\n",
    "\n",
    "    outputs2 = Conv2D(1, (1, 1), activation='sigmoid', name='output_seg')(c9_seg)\n",
    "\n",
    "    model_dual_path = models.Model(inputs=[inputs], outputs=[outputs1, outputs2])\n",
    "    model_dual_path.compile(optimizer=Adam(learning_rate=LearnRate),\n",
    "                            loss={'output_dis': 'mean_squared_error', 'output_seg': bce_dice_loss},\n",
    "                            loss_weights=  {'output_dis': 1.0, 'output_seg': 1.0},\n",
    "                            metrics={'output_seg':dice_coef, 'output_dis':mse_score})\n",
    "    # model_dual_path.summary()\n",
    "    return model_dual_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da60cfe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.910459Z",
     "iopub.status.busy": "2025-10-14T09:19:53.910154Z",
     "iopub.status.idle": "2025-10-14T09:19:53.932900Z",
     "shell.execute_reply": "2025-10-14T09:19:53.931944Z"
    },
    "papermill": {
     "duration": 0.030589,
     "end_time": "2025-10-14T09:19:53.934267",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.903678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fast_aji(true, pred):\n",
    "    \"\"\"AJI version distributed by MoNuSeg, has no permutation problem but suffered from \n",
    "    over-penalisation similar to DICE2.\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4] \n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no \n",
    "    effect on the result.\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "    #print(len(pred_id_list))\n",
    "    if len(pred_id_list) == 1:\n",
    "        return 0\n",
    "\n",
    "    true_masks = [None,]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [None,]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    # pair of pred that give highest iou for each true, dont care\n",
    "    # about reusing pred instance multiple times\n",
    "    paired_pred = np.argmax(pairwise_iou, axis=1)\n",
    "    pairwise_iou = np.max(pairwise_iou, axis=1)\n",
    "    # exlude those dont have intersection\n",
    "    paired_true = np.nonzero(pairwise_iou > 0.0)[0]\n",
    "    paired_pred = paired_pred[paired_true]\n",
    "    # print(paired_true.shape, paired_pred.shape)\n",
    "    overall_inter = (pairwise_inter[paired_true, paired_pred]).sum()\n",
    "    overall_union = (pairwise_union[paired_true, paired_pred]).sum()\n",
    "\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "\n",
    "    aji_score = overall_inter / overall_union\n",
    "    #print(aji_score)\n",
    "    return aji_score\n",
    "\n",
    "#############################################################################################################\n",
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
    "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
    "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique \n",
    "    (1 prediction instance to 1 GT instance mapping).\n",
    "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
    "    in bipartite graphs) is caculated to find the maximal amount of unique pairing. \n",
    "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
    "    the number of pairs is also maximal.    \n",
    "    \n",
    "    Fast computation requires instance IDs are in contiguous orderding \n",
    "    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand \n",
    "    and `by_size` flag has no effect on the result.\n",
    "    Returns:\n",
    "        [dq, sq, pq]: measurement statistic\n",
    "        [paired_true, paired_pred, unpaired_true, unpaired_pred]: \n",
    "                      pairing information to perform measurement\n",
    "                    \n",
    "    \"\"\"\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "    \n",
    "    if len(pred_id_list) == 1:\n",
    "        return [0, 0, 0], [0,0, 0, 0]\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1  # index is instance id - 1\n",
    "        paired_pred += 1  # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence\n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum\n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "def get_dice_1(true, pred):\n",
    "    \"\"\"Traditional dice.\"\"\"\n",
    "    # cast to binary 1st\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true[true > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "    inter = true * pred\n",
    "    denom = true + pred\n",
    "    dice_score = 2.0 * np.sum(inter) / (np.sum(denom) + 0.0001)\n",
    "    if np.sum(inter)==0 and np.sum(denom)==0:\n",
    "        dice_score = 1 # to handel cases without any nuclei\n",
    "    #print(dice_score)\n",
    "    return dice_score\n",
    "#############################################################################################################\n",
    "def remap_label(pred, by_size=False):\n",
    "    \"\"\"Rename all instance id so that the id is contiguous i.e [0, 1, 2, 3] \n",
    "    not [0, 2, 4, 6]. The ordering of instances (which one comes first) \n",
    "    is preserved unless by_size=True, then the instances will be reordered\n",
    "    so that bigger nucler has smaller ID.\n",
    "    Args:\n",
    "        pred    : the 2d array contain instances where each instances is marked\n",
    "                  by non-zero integer\n",
    "        by_size : renaming with larger nuclei has smaller id (on-top)\n",
    "    \"\"\"\n",
    "    pred_id = list(np.unique(pred))\n",
    "    pred_id.remove(0)\n",
    "    if len(pred_id) == 0:\n",
    "        return pred  # no label\n",
    "    if by_size:\n",
    "        pred_size = []\n",
    "        for inst_id in pred_id:\n",
    "            size = (pred == inst_id).sum()\n",
    "            pred_size.append(size)\n",
    "        # sort the id by size in descending order\n",
    "        pair_list = zip(pred_id, pred_size)\n",
    "        pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
    "        pred_id, pred_size = zip(*pair_list)\n",
    "\n",
    "    new_pred = np.zeros(pred.shape, np.int32)\n",
    "    for idx, inst_id in enumerate(pred_id):\n",
    "        new_pred[pred == inst_id] = idx + 1\n",
    "    return new_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971e059d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.945893Z",
     "iopub.status.busy": "2025-10-14T09:19:53.945382Z",
     "iopub.status.idle": "2025-10-14T09:19:53.949016Z",
     "shell.execute_reply": "2025-10-14T09:19:53.948349Z"
    },
    "papermill": {
     "duration": 0.010749,
     "end_time": "2025-10-14T09:19:53.950335",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.939586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = dual_decoder_unet_binary(3,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d8fc4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.961896Z",
     "iopub.status.busy": "2025-10-14T09:19:53.961153Z",
     "iopub.status.idle": "2025-10-14T09:19:53.965156Z",
     "shell.execute_reply": "2025-10-14T09:19:53.964306Z"
    },
    "papermill": {
     "duration": 0.011158,
     "end_time": "2025-10-14T09:19:53.966571",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.955413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2889a443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.977660Z",
     "iopub.status.busy": "2025-10-14T09:19:53.977314Z",
     "iopub.status.idle": "2025-10-14T09:19:53.982692Z",
     "shell.execute_reply": "2025-10-14T09:19:53.981978Z"
    },
    "papermill": {
     "duration": 0.01244,
     "end_time": "2025-10-14T09:19:53.983913",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.971473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set all hyper parameters\n",
    "opts = {}\n",
    "opts['number_of_channel'] = 3                   \n",
    "opts['treshold'] = 0.5                          \n",
    "opts['epoch_num'] = 120                   \n",
    "opts['quick_run'] = 1   \n",
    "opts['batch_size'] = 8                         \n",
    "opts['random_seed_num'] = 19   \n",
    "opts['k_fold'] = 2                          \n",
    "opts['save_val_results'] = 1         \n",
    "opts['init_LR'] = 0.001                         \n",
    "opts['LR_decay_factor'] = 0.5                   \n",
    "opts['LR_drop_after_nth_epoch'] = 20            \n",
    "opts['crop_size'] = 512   \n",
    "## output directories\n",
    "opts['result_save_path'] ='/kaggle/working/prediction_image/'\n",
    "opts['model_save_path'] ='/kaggle/working/output_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c742509b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:53.995778Z",
     "iopub.status.busy": "2025-10-14T09:19:53.995420Z",
     "iopub.status.idle": "2025-10-14T09:19:54.000346Z",
     "shell.execute_reply": "2025-10-14T09:19:53.999536Z"
    },
    "papermill": {
     "duration": 0.012003,
     "end_time": "2025-10-14T09:19:54.001702",
     "exception": false,
     "start_time": "2025-10-14T09:19:53.989699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.1, epochs_drop=20):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/epochs_drop))\n",
    "    \n",
    "    return LearningRateScheduler(schedule, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fcdd59",
   "metadata": {
    "papermill": {
     "duration": 0.004598,
     "end_time": "2025-10-14T09:19:54.011358",
     "exception": false,
     "start_time": "2025-10-14T09:19:54.006760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b569f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:54.022212Z",
     "iopub.status.busy": "2025-10-14T09:19:54.021911Z",
     "iopub.status.idle": "2025-10-14T09:19:54.058766Z",
     "shell.execute_reply": "2025-10-14T09:19:54.057857Z"
    },
    "papermill": {
     "duration": 0.044094,
     "end_time": "2025-10-14T09:19:54.060214",
     "exception": false,
     "start_time": "2025-10-14T09:19:54.016120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mouse muscle_tibia',\n",
       " 'mouse liver',\n",
       " 'human liver',\n",
       " 'human umbilical cord',\n",
       " 'mouse thymus',\n",
       " 'human lung',\n",
       " 'human epiglottis',\n",
       " 'human spleen',\n",
       " 'mouse fat (white and brown)_subscapula',\n",
       " 'human cardia',\n",
       " 'human salivory gland',\n",
       " 'human melanoma',\n",
       " 'human kidney',\n",
       " 'human pylorus',\n",
       " 'human jejunum',\n",
       " 'human testis',\n",
       " 'mouse spleen',\n",
       " 'human tongue',\n",
       " 'human cerebellum',\n",
       " 'human oesophagus',\n",
       " 'mouse heart',\n",
       " 'human pancreas',\n",
       " 'human brain',\n",
       " 'human muscle',\n",
       " 'human placenta',\n",
       " 'human bladder',\n",
       " 'mouse kidney',\n",
       " 'human tonsile',\n",
       " 'human rectum',\n",
       " 'mouse femur',\n",
       " 'human peritoneum']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../input/nuinsseg/'\n",
    "organ_names = [ name for name in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, name)) ]\n",
    "organ_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e439222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:54.072026Z",
     "iopub.status.busy": "2025-10-14T09:19:54.071483Z",
     "iopub.status.idle": "2025-10-14T09:19:55.149031Z",
     "shell.execute_reply": "2025-10-14T09:19:55.148296Z"
    },
    "papermill": {
     "duration": 1.085023,
     "end_time": "2025-10-14T09:19:55.150555",
     "exception": false,
     "start_time": "2025-10-14T09:19:54.065532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "img_path = glob('{}*{}'.format('../input/nuinsseg/*/tissue images/', 'png'))\n",
    "binary_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/mask binary/', 'png'))\n",
    "distance_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/distance maps/', 'png'))\n",
    "label_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/label masks modify/', 'tif'))\n",
    "vague_mask_path =  glob('{}*{}'.format('../input/nuinsseg/*/vague areas/mask binary/', 'png'))\n",
    "\n",
    "\n",
    "img_path.sort()\n",
    "binary_mask_path.sort()\n",
    "distance_mask_path.sort()\n",
    "label_mask_path.sort()\n",
    "vague_mask_path.sort()\n",
    "\n",
    "\n",
    "# create folders to save the best models and images (if needed) for each fold\n",
    "if not os.path.exists('/kaggle/working/prediction_image/'):\n",
    "    os.makedirs('/kaggle/working/prediction_image/')\n",
    "if not os.path.exists('/kaggle/working/output_model/'):\n",
    "    os.makedirs('/kaggle/working/output_model/')    \n",
    "if not os.path.exists(opts['result_save_path']+ 'validation/unet'):\n",
    "    os.makedirs(opts['result_save_path'] + 'validation/unet')\n",
    "if not os.path.exists(opts['result_save_path']+ 'validation/watershed_unet'):\n",
    "    os.makedirs(opts['result_save_path'] + 'validation/watershed_unet')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e841f0c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.164017Z",
     "iopub.status.busy": "2025-10-14T09:19:55.163097Z",
     "iopub.status.idle": "2025-10-14T09:19:55.169724Z",
     "shell.execute_reply": "2025-10-14T09:19:55.168397Z"
    },
    "papermill": {
     "duration": 0.015184,
     "end_time": "2025-10-14T09:19:55.171120",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.155936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image path: ../input/nuinsseg/mouse kidney/tissue images/mouse_kidney_31.png\n",
      " binary mask path: ../input/nuinsseg/mouse kidney/mask binary/mouse_kidney_31.png\n",
      " distance mask path: ../input/nuinsseg/mouse kidney/distance maps/mouse_kidney_31.png\n",
      " label mask path: ../input/nuinsseg/mouse kidney/label masks modify/mouse_kidney_31.tif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random check\n",
    "import numpy as np\n",
    "import random\n",
    "rand_num = np.random.randint(len(img_path))\n",
    "print('image path: {}\\n'.format(img_path[rand_num]),\n",
    "      'binary mask path: {}\\n'.format(binary_mask_path[rand_num]),\n",
    "      'distance mask path: {}\\n'.format(distance_mask_path[rand_num]),\n",
    "      'label mask path: {}\\n'.format(label_mask_path[rand_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93c5a9",
   "metadata": {
    "papermill": {
     "duration": 0.005468,
     "end_time": "2025-10-14T09:19:55.182956",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.177488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00da0e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.195821Z",
     "iopub.status.busy": "2025-10-14T09:19:55.195259Z",
     "iopub.status.idle": "2025-10-14T09:19:55.229007Z",
     "shell.execute_reply": "2025-10-14T09:19:55.228237Z"
    },
    "papermill": {
     "duration": 0.042096,
     "end_time": "2025-10-14T09:19:55.230659",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.188563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import cv2\n",
    "from keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff5bb8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.243762Z",
     "iopub.status.busy": "2025-10-14T09:19:55.242996Z",
     "iopub.status.idle": "2025-10-14T09:19:55.350510Z",
     "shell.execute_reply": "2025-10-14T09:19:55.349578Z"
    },
    "papermill": {
     "duration": 0.115883,
     "end_time": "2025-10-14T09:19:55.352021",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.236138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "kf = KFold(n_splits= opts['k_fold'],random_state= opts['random_seed_num'],shuffle=True)\n",
    "kf.get_n_splits(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6c88f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.364123Z",
     "iopub.status.busy": "2025-10-14T09:19:55.363517Z",
     "iopub.status.idle": "2025-10-14T09:19:55.374223Z",
     "shell.execute_reply": "2025-10-14T09:19:55.373484Z"
    },
    "papermill": {
     "duration": 0.018244,
     "end_time": "2025-10-14T09:19:55.375575",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.357331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Data Generator Needed not to run out of \n",
    "def get_id_from_file_path(file_path, indicator):\n",
    "    return file_path.split(os.path.sep)[-1].replace(indicator, '')\n",
    "    \n",
    "def chunker(seq, seq2, seq3, size):\n",
    "    return ([seq[pos:pos + size], seq2[pos:pos + size], seq3[pos:pos + size]] for pos in range(0, len(seq), size))\n",
    "\n",
    "def data_gen(list_files, list_files2, list_files3, batch_size, p , size_row, size_col, distance_unet_flag = 0,\n",
    "             augment= False, BACKBONE_model = None, use_pretrain_flag = 1):\n",
    "    while True:\n",
    "        for batch in chunker(list_files, list_files2, list_files3, batch_size):\n",
    "            Y = []\n",
    "            Y_seg = []\n",
    "            Y_dis = []\n",
    "            X = []\n",
    "            \n",
    "            image_paths = batch[0]\n",
    "            mask_paths = batch[1]\n",
    "            dis_paths = batch[2] \n",
    "\n",
    "            for count in range(len(image_paths)):\n",
    "                # 1. Load Image (X)\n",
    "                x = cv2.imread(image_paths[count])\n",
    "                x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # 2. Load Segmentation Mask (Y_seg) - For output_seg\n",
    "                seg_mask = cv2.imread(mask_paths[count], cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                # 3. Load Distance Map (Y_dis) - For output_dis\n",
    "                dis_map = cv2.imread(dis_paths[count], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                x = x.astype(np.float32)\n",
    "                x = x/255.0\n",
    "                \n",
    "                seg_mask = (seg_mask > 0).astype(np.float32) \n",
    "                \n",
    "                # Normalize distance map (Regression: 0.0 to 1.0)\n",
    "                # Your old distance normalization logic (good for distance maps):\n",
    "                dis_map = dis_map.astype(np.float32)\n",
    "                min_dis = np.min(dis_map)\n",
    "                max_dis = np.max(dis_map)\n",
    "                dis_map = (dis_map - min_dis) / (max_dis - min_dis + 0.0000001)\n",
    "\n",
    "                X.append(x)\n",
    "                Y_seg.append(seg_mask)\n",
    "                Y_dis.append(dis_map)\n",
    "                \n",
    "                del x, seg_mask, dis_map\n",
    "            X = np.array(X)\n",
    "            Y_seg = np.expand_dims(np.array(Y_seg), axis=-1)\n",
    "            Y_dis = np.expand_dims(np.array(Y_dis), axis=-1)\n",
    "            yield X, {'output_seg': Y_seg, 'output_dis': Y_dis}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6a5a91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.387256Z",
     "iopub.status.busy": "2025-10-14T09:19:55.386969Z",
     "iopub.status.idle": "2025-10-14T09:19:55.392040Z",
     "shell.execute_reply": "2025-10-14T09:19:55.391384Z"
    },
    "papermill": {
     "duration": 0.012326,
     "end_time": "2025-10-14T09:19:55.393216",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.380890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_smoothing(distance_map_array, average_diameter):\n",
    "    \"\"\"\n",
    "    Applies Gaussian smoothing to the predicted distance map.\n",
    "    \n",
    "    Args:\n",
    "        distance_map_array (np.ndarray): The 2D distance map predicted by the UNet head.\n",
    "        average_diameter (float): The average nucleus equivalent diameter (in pixels).\n",
    "                                  \n",
    "    Returns:\n",
    "        np.ndarray: The smoothed distance map, ready for watershed markers extraction.\n",
    "    \"\"\"\n",
    "    # Set the standard deviation (sigma, σ) for the Gaussian filter.\n",
    "    # Sigma is typically set to the average radius of the object (Diameter / 2).\n",
    "    # This choice ensures the filter smooths the distance peaks for *one* nucleus, \n",
    "    # while generally preserving the boundaries between overlapping nuclei.\n",
    "    GAUSSIAN_SIGMA = average_diameter / 2.0\n",
    "    \n",
    "    # Apply the Gaussian filter. \n",
    "    # truncate=4.0 ensures the kernel covers about 4 standard deviations, making \n",
    "    # the smoothing effective.\n",
    "    smoothed_dis_map = gaussian_filter(\n",
    "        input=distance_map_array, \n",
    "        sigma=GAUSSIAN_SIGMA, \n",
    "        truncate=4.0\n",
    "    )\n",
    "    \n",
    "    return smoothed_dis_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "706cdb1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.405482Z",
     "iopub.status.busy": "2025-10-14T09:19:55.405099Z",
     "iopub.status.idle": "2025-10-14T09:19:55.467779Z",
     "shell.execute_reply": "2025-10-14T09:19:55.466864Z"
    },
    "papermill": {
     "duration": 0.070813,
     "end_time": "2025-10-14T09:19:55.469430",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.398617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from math import sqrt, pi\n",
    "from scipy.ndimage import gaussian_filter # Needed for the next step\n",
    "\n",
    "def calculate_average_nucleus_diameter(binary_mask_array, min_area_threshold=50):\n",
    "    \"\"\"\n",
    "    Calculates the average equivalent nucleus diameter (in pixels) from the \n",
    "    predicted binary semantic mask.\n",
    "    \n",
    "    The diameter is derived from the average nucleus area, assuming a circular shape \n",
    "    (Area = pi * (D/2)^2 => D = 2 * sqrt(Area / pi)).\n",
    "    \n",
    "    Args:\n",
    "        binary_mask_array (np.ndarray): The 2D numpy array of the predicted \n",
    "                                        binary semantic mask (0s and 1s).\n",
    "        min_area_threshold (int): Filters out small regions (noise) that are not nuclei.\n",
    "                                  \n",
    "    Returns:\n",
    "        float: The average nucleus equivalent diameter in pixels.\n",
    "    \"\"\"\n",
    "    # 1. Label connected components to identify individual (or clustered) nuclei\n",
    "    # Use boolean array for skimage.label\n",
    "    labeled_mask = label(binary_mask_array > 0)\n",
    "\n",
    "    # 2. Calculate properties (Area) for each labeled region\n",
    "    props = regionprops(labeled_mask)\n",
    "    all_areas = []\n",
    "\n",
    "    # 3. Collect areas\n",
    "    for prop in props:\n",
    "        if prop.area >= min_area_threshold:\n",
    "            all_areas.append(prop.area)\n",
    "\n",
    "    if not all_areas:\n",
    "        # Fallback to a common size if no objects are detected\n",
    "        return 20.0 \n",
    "\n",
    "    # 4. Calculate average area\n",
    "    average_area = np.mean(all_areas)\n",
    "    \n",
    "    # 5. Convert average area to equivalent diameter (D)\n",
    "    average_diameter_pixels = 2 * sqrt(average_area / pi)\n",
    "    \n",
    "    return average_diameter_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1099182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.481580Z",
     "iopub.status.busy": "2025-10-14T09:19:55.481006Z",
     "iopub.status.idle": "2025-10-14T09:19:55.488366Z",
     "shell.execute_reply": "2025-10-14T09:19:55.487514Z"
    },
    "papermill": {
     "duration": 0.014984,
     "end_time": "2025-10-14T09:19:55.489821",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.474837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dice_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# AJI_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# PQ_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "\n",
    "# dice_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# AJI_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# PQ_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "# dice_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# AJI_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# PQ_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "# Calculate the maximum size required for any fold (using ceiling division)\n",
    "num_folds = opts['k_fold']\n",
    "total_images = len(img_path)\n",
    "max_fold_size = (total_images + num_folds - 1) // num_folds\n",
    "\n",
    "# Initialize all arrays using the calculated maximum fold size\n",
    "dice_unet = np.zeros([num_folds, max_fold_size])\n",
    "AJI_unet = np.zeros([num_folds, max_fold_size])\n",
    "PQ_unet = np.zeros([num_folds, max_fold_size])\n",
    "\n",
    "dice_unet_watershed = np.zeros([num_folds, max_fold_size])\n",
    "AJI_unet_watershed = np.zeros([num_folds, max_fold_size])\n",
    "PQ_unet_watershed = np.zeros([num_folds, max_fold_size])\n",
    "\n",
    "dice_unet_watershed_without_vague = np.zeros([num_folds, max_fold_size])\n",
    "AJI_unet_watershed_without_vague = np.zeros([num_folds, max_fold_size])\n",
    "PQ_unet_watershed_without_vague = np.zeros([num_folds, max_fold_size])\n",
    "\n",
    "dice_mean = []\n",
    "aji_mean = []\n",
    "pq_mean = []\n",
    "                   \n",
    "dice_watershed_mean = []\n",
    "aji_watershed_mean = []\n",
    "pq_watershed_mean = []\n",
    "                   \n",
    "dice_watershed_wovague_mean = []\n",
    "aji_watershed_wovague_mean = []\n",
    "pq_watershed_wovague_mean = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fffa7c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T09:19:55.501779Z",
     "iopub.status.busy": "2025-10-14T09:19:55.501434Z",
     "iopub.status.idle": "2025-10-14T10:21:06.085245Z",
     "shell.execute_reply": "2025-10-14T10:21:06.084093Z"
    },
    "papermill": {
     "duration": 3670.591666,
     "end_time": "2025-10-14T10:21:06.086699",
     "exception": false,
     "start_time": "2025-10-14T09:19:55.495033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760433607.368812      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760433627.888613      60 service.cc:148] XLA service 0x7d49e8003820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1760433627.889436      60 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1760433629.846535      60 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1760433655.463779      60 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.0853 - output_dis_loss: 0.0151 - output_dis_mse_score: 0.0151 - output_seg_dice_coef: 0.2129 - output_seg_loss: 0.0701\n",
      "Epoch 1: val_output_seg_dice_coef improved from -inf to 0.13683, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 453ms/step - loss: 0.0849 - output_dis_loss: 0.0151 - output_dis_mse_score: 0.0151 - output_seg_dice_coef: 0.2126 - output_seg_loss: 0.0698 - val_loss: 0.0965 - val_output_dis_loss: 0.0092 - val_output_dis_mse_score: 0.0092 - val_output_seg_dice_coef: 0.1368 - val_output_seg_loss: 0.0873 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760433678.679089      60 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1760433678.911752      60 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0371 - output_dis_loss: 0.0156 - output_dis_mse_score: 0.0152 - output_seg_dice_coef: 0.2175 - output_seg_loss: 0.0212\n",
      "Epoch 2: val_output_seg_dice_coef improved from 0.13683 to 0.16417, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 226ms/step - loss: 0.0365 - output_dis_loss: 0.0156 - output_dis_mse_score: 0.0152 - output_seg_dice_coef: 0.2178 - output_seg_loss: 0.0207 - val_loss: 0.1049 - val_output_dis_loss: 0.0084 - val_output_dis_mse_score: 0.0084 - val_output_seg_dice_coef: 0.1642 - val_output_seg_loss: 0.0965 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.0760 - output_dis_loss: 0.0141 - output_dis_mse_score: 0.0136 - output_seg_dice_coef: 0.2941 - output_seg_loss: -0.0893\n",
      "Epoch 3: val_output_seg_dice_coef improved from 0.16417 to 0.19820, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.0767 - output_dis_loss: 0.0140 - output_dis_mse_score: 0.0136 - output_seg_dice_coef: 0.2945 - output_seg_loss: -0.0901 - val_loss: 0.0320 - val_output_dis_loss: 0.0134 - val_output_dis_mse_score: 0.0134 - val_output_seg_dice_coef: 0.1982 - val_output_seg_loss: 0.0186 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.1674 - output_dis_loss: 0.0137 - output_dis_mse_score: 0.0133 - output_seg_dice_coef: 0.3811 - output_seg_loss: -0.1768\n",
      "Epoch 4: val_output_seg_dice_coef improved from 0.19820 to 0.23318, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.1679 - output_dis_loss: 0.0137 - output_dis_mse_score: 0.0133 - output_seg_dice_coef: 0.3816 - output_seg_loss: -0.1773 - val_loss: 0.1691 - val_output_dis_loss: 0.0115 - val_output_dis_mse_score: 0.0115 - val_output_seg_dice_coef: 0.2332 - val_output_seg_loss: 0.1576 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.1691 - output_dis_loss: 0.0141 - output_dis_mse_score: 0.0139 - output_seg_dice_coef: 0.4505 - output_seg_loss: -0.1791\n",
      "Epoch 5: val_output_seg_dice_coef did not improve from 0.23318\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.1688 - output_dis_loss: 0.0141 - output_dis_mse_score: 0.0138 - output_seg_dice_coef: 0.4497 - output_seg_loss: -0.1789 - val_loss: 0.0387 - val_output_dis_loss: 0.0109 - val_output_dis_mse_score: 0.0109 - val_output_seg_dice_coef: 0.2151 - val_output_seg_loss: 0.0278 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.2185 - output_dis_loss: 0.0130 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4399 - output_seg_loss: -0.2280\n",
      "Epoch 6: val_output_seg_dice_coef did not improve from 0.23318\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.2180 - output_dis_loss: 0.0130 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4394 - output_seg_loss: -0.2275 - val_loss: 0.0588 - val_output_dis_loss: 0.0110 - val_output_dis_mse_score: 0.0110 - val_output_seg_dice_coef: 0.2324 - val_output_seg_loss: 0.0478 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: -0.2775 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.4914 - output_seg_loss: -0.2859\n",
      "Epoch 7: val_output_seg_dice_coef improved from 0.23318 to 0.26046, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 224ms/step - loss: -0.2769 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.4909 - output_seg_loss: -0.2854 - val_loss: 0.0354 - val_output_dis_loss: 0.0132 - val_output_dis_mse_score: 0.0132 - val_output_seg_dice_coef: 0.2605 - val_output_seg_loss: 0.0222 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.3274 - output_dis_loss: 0.0118 - output_dis_mse_score: 0.0116 - output_seg_dice_coef: 0.5204 - output_seg_loss: -0.3367\n",
      "Epoch 8: val_output_seg_dice_coef did not improve from 0.26046\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.3269 - output_dis_loss: 0.0118 - output_dis_mse_score: 0.0116 - output_seg_dice_coef: 0.5201 - output_seg_loss: -0.3362 - val_loss: 0.0098 - val_output_dis_loss: 0.0123 - val_output_dis_mse_score: 0.0123 - val_output_seg_dice_coef: 0.2477 - val_output_seg_loss: -0.0025 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.3101 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0119 - output_seg_dice_coef: 0.5031 - output_seg_loss: -0.3201\n",
      "Epoch 9: val_output_seg_dice_coef improved from 0.26046 to 0.31858, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.3098 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0120 - output_seg_dice_coef: 0.5030 - output_seg_loss: -0.3199 - val_loss: -0.1176 - val_output_dis_loss: 0.0092 - val_output_dis_mse_score: 0.0092 - val_output_seg_dice_coef: 0.3186 - val_output_seg_loss: -0.1268 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.3205 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0119 - output_seg_dice_coef: 0.5119 - output_seg_loss: -0.3321\n",
      "Epoch 10: val_output_seg_dice_coef improved from 0.31858 to 0.32242, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.3200 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0119 - output_seg_dice_coef: 0.5116 - output_seg_loss: -0.3316 - val_loss: -0.0665 - val_output_dis_loss: 0.0133 - val_output_dis_mse_score: 0.0133 - val_output_seg_dice_coef: 0.3224 - val_output_seg_loss: -0.0798 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.3551 - output_dis_loss: 0.0108 - output_dis_mse_score: 0.0106 - output_seg_dice_coef: 0.5411 - output_seg_loss: -0.3659\n",
      "Epoch 11: val_output_seg_dice_coef did not improve from 0.32242\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.3556 - output_dis_loss: 0.0108 - output_dis_mse_score: 0.0106 - output_seg_dice_coef: 0.5415 - output_seg_loss: -0.3663 - val_loss: 0.0918 - val_output_dis_loss: 0.0118 - val_output_dis_mse_score: 0.0118 - val_output_seg_dice_coef: 0.2807 - val_output_seg_loss: 0.0800 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.3120 - output_dis_loss: 0.0107 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.5151 - output_seg_loss: -0.3220\n",
      "Epoch 12: val_output_seg_dice_coef improved from 0.32242 to 0.46565, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.3131 - output_dis_loss: 0.0107 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.5159 - output_seg_loss: -0.3231 - val_loss: -0.3635 - val_output_dis_loss: 0.0057 - val_output_dis_mse_score: 0.0057 - val_output_seg_dice_coef: 0.4657 - val_output_seg_loss: -0.3692 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.3200 - output_dis_loss: 0.0138 - output_dis_mse_score: 0.0137 - output_seg_dice_coef: 0.5256 - output_seg_loss: -0.3319\n",
      "Epoch 13: val_output_seg_dice_coef did not improve from 0.46565\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.3202 - output_dis_loss: 0.0138 - output_dis_mse_score: 0.0136 - output_seg_dice_coef: 0.5256 - output_seg_loss: -0.3322 - val_loss: -0.3462 - val_output_dis_loss: 0.0069 - val_output_dis_mse_score: 0.0069 - val_output_seg_dice_coef: 0.4560 - val_output_seg_loss: -0.3531 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.3696 - output_dis_loss: 0.0114 - output_dis_mse_score: 0.0112 - output_seg_dice_coef: 0.5633 - output_seg_loss: -0.3806\n",
      "Epoch 14: val_output_seg_dice_coef improved from 0.46565 to 0.48577, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.3696 - output_dis_loss: 0.0114 - output_dis_mse_score: 0.0112 - output_seg_dice_coef: 0.5632 - output_seg_loss: -0.3807 - val_loss: -0.3827 - val_output_dis_loss: 0.0064 - val_output_dis_mse_score: 0.0064 - val_output_seg_dice_coef: 0.4858 - val_output_seg_loss: -0.3891 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.3682 - output_dis_loss: 0.0107 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.5550 - output_seg_loss: -0.3773\n",
      "Epoch 15: val_output_seg_dice_coef improved from 0.48577 to 0.53815, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.3687 - output_dis_loss: 0.0107 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.5553 - output_seg_loss: -0.3778 - val_loss: -0.4377 - val_output_dis_loss: 0.0058 - val_output_dis_mse_score: 0.0058 - val_output_seg_dice_coef: 0.5381 - val_output_seg_loss: -0.4435 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.2815 - output_dis_loss: 0.0110 - output_dis_mse_score: 0.0108 - output_seg_dice_coef: 0.4934 - output_seg_loss: -0.2902\n",
      "Epoch 16: val_output_seg_dice_coef did not improve from 0.53815\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.2820 - output_dis_loss: 0.0110 - output_dis_mse_score: 0.0108 - output_seg_dice_coef: 0.4936 - output_seg_loss: -0.2906 - val_loss: -0.3396 - val_output_dis_loss: 0.0067 - val_output_dis_mse_score: 0.0067 - val_output_seg_dice_coef: 0.4574 - val_output_seg_loss: -0.3463 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.3508 - output_dis_loss: 0.0105 - output_dis_mse_score: 0.0104 - output_seg_dice_coef: 0.5460 - output_seg_loss: -0.3596\n",
      "Epoch 17: val_output_seg_dice_coef did not improve from 0.53815\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.3512 - output_dis_loss: 0.0105 - output_dis_mse_score: 0.0104 - output_seg_dice_coef: 0.5462 - output_seg_loss: -0.3599 - val_loss: -0.4025 - val_output_dis_loss: 0.0059 - val_output_dis_mse_score: 0.0059 - val_output_seg_dice_coef: 0.5060 - val_output_seg_loss: -0.4085 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.3925 - output_dis_loss: 0.0099 - output_dis_mse_score: 0.0098 - output_seg_dice_coef: 0.5718 - output_seg_loss: -0.4023\n",
      "Epoch 18: val_output_seg_dice_coef did not improve from 0.53815\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.3928 - output_dis_loss: 0.0099 - output_dis_mse_score: 0.0098 - output_seg_dice_coef: 0.5720 - output_seg_loss: -0.4025 - val_loss: -0.3909 - val_output_dis_loss: 0.0058 - val_output_dis_mse_score: 0.0058 - val_output_seg_dice_coef: 0.4938 - val_output_seg_loss: -0.3967 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.3941 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.5638 - output_seg_loss: -0.4023\n",
      "Epoch 19: val_output_seg_dice_coef did not improve from 0.53815\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.3942 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0094 - output_seg_dice_coef: 0.5640 - output_seg_loss: -0.4023 - val_loss: -0.4397 - val_output_dis_loss: 0.0054 - val_output_dis_mse_score: 0.0054 - val_output_seg_dice_coef: 0.5381 - val_output_seg_loss: -0.4451 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4318 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5871 - output_seg_loss: -0.4403\n",
      "Epoch 20: val_output_seg_dice_coef improved from 0.53815 to 0.54602, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.4314 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5871 - output_seg_loss: -0.4399 - val_loss: -0.4522 - val_output_dis_loss: 0.0056 - val_output_dis_mse_score: 0.0056 - val_output_seg_dice_coef: 0.5460 - val_output_seg_loss: -0.4578 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.4249 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.5843 - output_seg_loss: -0.4338\n",
      "Epoch 21: val_output_seg_dice_coef improved from 0.54602 to 0.55557, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.4249 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.5843 - output_seg_loss: -0.4337 - val_loss: -0.4651 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.5556 - val_output_seg_loss: -0.4702 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4416 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6010 - output_seg_loss: -0.4502\n",
      "Epoch 22: val_output_seg_dice_coef improved from 0.55557 to 0.55715, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.4414 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6009 - output_seg_loss: -0.4500 - val_loss: -0.4650 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.5572 - val_output_seg_loss: -0.4700 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4271 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.5973 - output_seg_loss: -0.4360\n",
      "Epoch 23: val_output_seg_dice_coef improved from 0.55715 to 0.55936, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.4272 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.5973 - output_seg_loss: -0.4362 - val_loss: -0.4668 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.5594 - val_output_seg_loss: -0.4717 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.4366 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5967 - output_seg_loss: -0.4453\n",
      "Epoch 24: val_output_seg_dice_coef improved from 0.55936 to 0.57192, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.4366 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5967 - output_seg_loss: -0.4453 - val_loss: -0.4780 - val_output_dis_loss: 0.0048 - val_output_dis_mse_score: 0.0048 - val_output_seg_dice_coef: 0.5719 - val_output_seg_loss: -0.4828 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.4447 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6063 - output_seg_loss: -0.4533\n",
      "Epoch 25: val_output_seg_dice_coef improved from 0.57192 to 0.57740, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.4446 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6061 - output_seg_loss: -0.4533 - val_loss: -0.4846 - val_output_dis_loss: 0.0047 - val_output_dis_mse_score: 0.0047 - val_output_seg_dice_coef: 0.5774 - val_output_seg_loss: -0.4893 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.4514 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.6114 - output_seg_loss: -0.4598\n",
      "Epoch 26: val_output_seg_dice_coef improved from 0.57740 to 0.60137, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.4514 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.6113 - output_seg_loss: -0.4598 - val_loss: -0.5126 - val_output_dis_loss: 0.0046 - val_output_dis_mse_score: 0.0046 - val_output_seg_dice_coef: 0.6014 - val_output_seg_loss: -0.5172 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4645 - output_dis_loss: 0.0081 - output_dis_mse_score: 0.0081 - output_seg_dice_coef: 0.6218 - output_seg_loss: -0.4729\n",
      "Epoch 27: val_output_seg_dice_coef improved from 0.60137 to 0.62506, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.4645 - output_dis_loss: 0.0081 - output_dis_mse_score: 0.0081 - output_seg_dice_coef: 0.6218 - output_seg_loss: -0.4729 - val_loss: -0.5379 - val_output_dis_loss: 0.0045 - val_output_dis_mse_score: 0.0045 - val_output_seg_dice_coef: 0.6251 - val_output_seg_loss: -0.5424 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.4785 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0081 - output_seg_dice_coef: 0.6377 - output_seg_loss: -0.4869\n",
      "Epoch 28: val_output_seg_dice_coef did not improve from 0.62506\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.4784 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0081 - output_seg_dice_coef: 0.6375 - output_seg_loss: -0.4868 - val_loss: -0.5294 - val_output_dis_loss: 0.0046 - val_output_dis_mse_score: 0.0046 - val_output_seg_dice_coef: 0.6170 - val_output_seg_loss: -0.5340 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4947 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6458 - output_seg_loss: -0.5029\n",
      "Epoch 29: val_output_seg_dice_coef improved from 0.62506 to 0.62780, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.4947 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6457 - output_seg_loss: -0.5029 - val_loss: -0.5415 - val_output_dis_loss: 0.0045 - val_output_dis_mse_score: 0.0045 - val_output_seg_dice_coef: 0.6278 - val_output_seg_loss: -0.5460 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5119 - output_dis_loss: 0.0077 - output_dis_mse_score: 0.0077 - output_seg_dice_coef: 0.6590 - output_seg_loss: -0.5200\n",
      "Epoch 30: val_output_seg_dice_coef improved from 0.62780 to 0.63485, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5118 - output_dis_loss: 0.0077 - output_dis_mse_score: 0.0077 - output_seg_dice_coef: 0.6589 - output_seg_loss: -0.5199 - val_loss: -0.5495 - val_output_dis_loss: 0.0046 - val_output_dis_mse_score: 0.0046 - val_output_seg_dice_coef: 0.6349 - val_output_seg_loss: -0.5541 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 31/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5263 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6706 - output_seg_loss: -0.5343\n",
      "Epoch 31: val_output_seg_dice_coef improved from 0.63485 to 0.64849, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5262 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6705 - output_seg_loss: -0.5342 - val_loss: -0.5658 - val_output_dis_loss: 0.0044 - val_output_dis_mse_score: 0.0044 - val_output_seg_dice_coef: 0.6485 - val_output_seg_loss: -0.5702 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 32/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5331 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6688 - output_seg_loss: -0.5406\n",
      "Epoch 32: val_output_seg_dice_coef improved from 0.64849 to 0.65348, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5330 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6689 - output_seg_loss: -0.5405 - val_loss: -0.5705 - val_output_dis_loss: 0.0044 - val_output_dis_mse_score: 0.0044 - val_output_seg_dice_coef: 0.6535 - val_output_seg_loss: -0.5749 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 33/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5442 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6754 - output_seg_loss: -0.5513\n",
      "Epoch 33: val_output_seg_dice_coef improved from 0.65348 to 0.65721, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5442 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6755 - output_seg_loss: -0.5513 - val_loss: -0.5713 - val_output_dis_loss: 0.0047 - val_output_dis_mse_score: 0.0047 - val_output_seg_dice_coef: 0.6572 - val_output_seg_loss: -0.5759 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 34/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5492 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6861 - output_seg_loss: -0.5567\n",
      "Epoch 34: val_output_seg_dice_coef improved from 0.65721 to 0.66630, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5493 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6861 - output_seg_loss: -0.5569 - val_loss: -0.5816 - val_output_dis_loss: 0.0045 - val_output_dis_mse_score: 0.0045 - val_output_seg_dice_coef: 0.6663 - val_output_seg_loss: -0.5861 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 35/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5568 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6911 - output_seg_loss: -0.5641\n",
      "Epoch 35: val_output_seg_dice_coef did not improve from 0.66630\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5570 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6912 - output_seg_loss: -0.5642 - val_loss: -0.5512 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.6485 - val_output_seg_loss: -0.5564 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 36/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5623 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6933 - output_seg_loss: -0.5695\n",
      "Epoch 36: val_output_seg_dice_coef did not improve from 0.66630\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5626 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6935 - output_seg_loss: -0.5698 - val_loss: -0.5521 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.6516 - val_output_seg_loss: -0.5574 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 37/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5576 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6891 - output_seg_loss: -0.5645\n",
      "Epoch 37: val_output_seg_dice_coef did not improve from 0.66630\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.5581 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6895 - output_seg_loss: -0.5650 - val_loss: -0.5515 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.6511 - val_output_seg_loss: -0.5568 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 38/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5708 - output_dis_loss: 0.0066 - output_dis_mse_score: 0.0066 - output_seg_dice_coef: 0.6977 - output_seg_loss: -0.5775\n",
      "Epoch 38: val_output_seg_dice_coef did not improve from 0.66630\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.5711 - output_dis_loss: 0.0066 - output_dis_mse_score: 0.0066 - output_seg_dice_coef: 0.6980 - output_seg_loss: -0.5778 - val_loss: -0.5652 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.6599 - val_output_seg_loss: -0.5702 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 39/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5858 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7080 - output_seg_loss: -0.5923\n",
      "Epoch 39: val_output_seg_dice_coef improved from 0.66630 to 0.67232, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5859 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7081 - output_seg_loss: -0.5924 - val_loss: -0.5824 - val_output_dis_loss: 0.0048 - val_output_dis_mse_score: 0.0048 - val_output_seg_dice_coef: 0.6723 - val_output_seg_loss: -0.5872 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 40/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5935 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7131 - output_seg_loss: -0.5998\n",
      "Epoch 40: val_output_seg_dice_coef improved from 0.67232 to 0.67901, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5935 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7132 - output_seg_loss: -0.5999 - val_loss: -0.5933 - val_output_dis_loss: 0.0044 - val_output_dis_mse_score: 0.0044 - val_output_seg_dice_coef: 0.6790 - val_output_seg_loss: -0.5977 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 41/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6108 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7274 - output_seg_loss: -0.6171\n",
      "Epoch 41: val_output_seg_dice_coef improved from 0.67901 to 0.69003, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6107 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7273 - output_seg_loss: -0.6171 - val_loss: -0.6097 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6900 - val_output_seg_loss: -0.6137 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 42/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6142 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7315 - output_seg_loss: -0.6205\n",
      "Epoch 42: val_output_seg_dice_coef improved from 0.69003 to 0.69376, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6141 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7314 - output_seg_loss: -0.6204 - val_loss: -0.6143 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6938 - val_output_seg_loss: -0.6183 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 43/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.6216 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7350 - output_seg_loss: -0.6277\n",
      "Epoch 43: val_output_seg_dice_coef improved from 0.69376 to 0.69438, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.6214 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7349 - output_seg_loss: -0.6274 - val_loss: -0.6149 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6944 - val_output_seg_loss: -0.6190 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 44/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.6280 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7440 - output_seg_loss: -0.6363\n",
      "Epoch 44: val_output_seg_dice_coef did not improve from 0.69438\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.6276 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7437 - output_seg_loss: -0.6359 - val_loss: -0.6146 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6944 - val_output_seg_loss: -0.6186 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 45/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6181 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7333 - output_seg_loss: -0.6268\n",
      "Epoch 45: val_output_seg_dice_coef improved from 0.69438 to 0.69504, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.6179 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7332 - output_seg_loss: -0.6266 - val_loss: -0.6155 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6950 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 46/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6290 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7416 - output_seg_loss: -0.6369\n",
      "Epoch 46: val_output_seg_dice_coef improved from 0.69504 to 0.69573, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6286 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7413 - output_seg_loss: -0.6365 - val_loss: -0.6163 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6204 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 47/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6245 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7407 - output_seg_loss: -0.6320\n",
      "Epoch 47: val_output_seg_dice_coef improved from 0.69573 to 0.69602, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6242 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7405 - output_seg_loss: -0.6316 - val_loss: -0.6167 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6960 - val_output_seg_loss: -0.6207 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 48/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6293 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7413 - output_seg_loss: -0.6365\n",
      "Epoch 48: val_output_seg_dice_coef did not improve from 0.69602\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6290 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7411 - output_seg_loss: -0.6361 - val_loss: -0.6164 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6205 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 49/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6271 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7404 - output_seg_loss: -0.6345\n",
      "Epoch 49: val_output_seg_dice_coef did not improve from 0.69602\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6268 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7402 - output_seg_loss: -0.6341 - val_loss: -0.6161 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6956 - val_output_seg_loss: -0.6201 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 50/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6241 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7354 - output_seg_loss: -0.6316\n",
      "Epoch 50: val_output_seg_dice_coef improved from 0.69602 to 0.69641, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6239 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7354 - output_seg_loss: -0.6314 - val_loss: -0.6171 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6964 - val_output_seg_loss: -0.6211 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 51/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6213 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7355 - output_seg_loss: -0.6285\n",
      "Epoch 51: val_output_seg_dice_coef did not improve from 0.69641\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6211 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7354 - output_seg_loss: -0.6284 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6955 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 52/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6216 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7369 - output_seg_loss: -0.6290\n",
      "Epoch 52: val_output_seg_dice_coef did not improve from 0.69641\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6214 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7369 - output_seg_loss: -0.6288 - val_loss: -0.6163 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6960 - val_output_seg_loss: -0.6203 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 53/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6221 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7321 - output_seg_loss: -0.6290\n",
      "Epoch 53: val_output_seg_dice_coef improved from 0.69641 to 0.69697, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6220 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7321 - output_seg_loss: -0.6289 - val_loss: -0.6175 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6970 - val_output_seg_loss: -0.6216 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 54/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6223 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7330 - output_seg_loss: -0.6291\n",
      "Epoch 54: val_output_seg_dice_coef did not improve from 0.69697\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6223 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7330 - output_seg_loss: -0.6290 - val_loss: -0.6170 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6966 - val_output_seg_loss: -0.6210 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 55/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6020 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7269 - output_seg_loss: -0.6093\n",
      "Epoch 55: val_output_seg_dice_coef improved from 0.69697 to 0.69796, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.6023 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7270 - output_seg_loss: -0.6096 - val_loss: -0.6188 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6980 - val_output_seg_loss: -0.6228 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 56/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6108 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7340 - output_seg_loss: -0.6181\n",
      "Epoch 56: val_output_seg_dice_coef did not improve from 0.69796\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6110 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7340 - output_seg_loss: -0.6183 - val_loss: -0.6176 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6972 - val_output_seg_loss: -0.6216 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 57/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6010 - output_dis_loss: 0.0064 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7274 - output_seg_loss: -0.6084\n",
      "Epoch 57: val_output_seg_dice_coef did not improve from 0.69796\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.6014 - output_dis_loss: 0.0064 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7276 - output_seg_loss: -0.6088 - val_loss: -0.6178 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6973 - val_output_seg_loss: -0.6218 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 58/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6018 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7237 - output_seg_loss: -0.6091\n",
      "Epoch 58: val_output_seg_dice_coef did not improve from 0.69796\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6023 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7240 - output_seg_loss: -0.6095 - val_loss: -0.6170 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6967 - val_output_seg_loss: -0.6210 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 59/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6003 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7235 - output_seg_loss: -0.6076\n",
      "Epoch 59: val_output_seg_dice_coef improved from 0.69796 to 0.69803, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.6007 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7237 - output_seg_loss: -0.6079 - val_loss: -0.6189 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6980 - val_output_seg_loss: -0.6229 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 60/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6084 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7296 - output_seg_loss: -0.6154\n",
      "Epoch 60: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6086 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7297 - output_seg_loss: -0.6156 - val_loss: -0.6185 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6978 - val_output_seg_loss: -0.6225 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 61/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6147 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7312 - output_seg_loss: -0.6215\n",
      "Epoch 61: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6148 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7314 - output_seg_loss: -0.6216 - val_loss: -0.6172 - val_output_dis_loss: 0.0040 - val_output_dis_mse_score: 0.0040 - val_output_seg_dice_coef: 0.6969 - val_output_seg_loss: -0.6212 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 62/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6179 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7290 - output_seg_loss: -0.6242\n",
      "Epoch 62: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6179 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7292 - output_seg_loss: -0.6243 - val_loss: -0.6164 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6964 - val_output_seg_loss: -0.6205 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 63/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6140 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7308 - output_seg_loss: -0.6208\n",
      "Epoch 63: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6141 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7309 - output_seg_loss: -0.6209 - val_loss: -0.6161 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6962 - val_output_seg_loss: -0.6202 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 64/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6163 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7344 - output_seg_loss: -0.6230\n",
      "Epoch 64: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6165 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7345 - output_seg_loss: -0.6232 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 65/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6047 - output_dis_loss: 0.0064 - output_dis_mse_score: 0.0064 - output_seg_dice_coef: 0.7301 - output_seg_loss: -0.6118\n",
      "Epoch 65: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6050 - output_dis_loss: 0.0064 - output_dis_mse_score: 0.0064 - output_seg_dice_coef: 0.7302 - output_seg_loss: -0.6122 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6198 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 66/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6130 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7318 - output_seg_loss: -0.6197\n",
      "Epoch 66: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6131 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7319 - output_seg_loss: -0.6199 - val_loss: -0.6154 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6195 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 67/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6196 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7376 - output_seg_loss: -0.6263\n",
      "Epoch 67: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6196 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7375 - output_seg_loss: -0.6263 - val_loss: -0.6154 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6195 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 68/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6189 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7367 - output_seg_loss: -0.6255\n",
      "Epoch 68: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6190 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7367 - output_seg_loss: -0.6255 - val_loss: -0.6154 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6195 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 69/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6185 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7349 - output_seg_loss: -0.6249\n",
      "Epoch 69: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6185 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7349 - output_seg_loss: -0.6250 - val_loss: -0.6153 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6956 - val_output_seg_loss: -0.6193 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 70/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6199 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7364 - output_seg_loss: -0.6264\n",
      "Epoch 70: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6199 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7365 - output_seg_loss: -0.6265 - val_loss: -0.6154 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6194 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 71/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6202 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7351 - output_seg_loss: -0.6266\n",
      "Epoch 71: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6202 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7351 - output_seg_loss: -0.6266 - val_loss: -0.6153 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6956 - val_output_seg_loss: -0.6194 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 72/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6203 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7362 - output_seg_loss: -0.6267\n",
      "Epoch 72: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6202 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7361 - output_seg_loss: -0.6267 - val_loss: -0.6154 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6194 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 73/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6275 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7417 - output_seg_loss: -0.6339\n",
      "Epoch 73: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6273 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7416 - output_seg_loss: -0.6337 - val_loss: -0.6153 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6194 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 74/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6241 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7354 - output_seg_loss: -0.6303\n",
      "Epoch 74: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6240 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7354 - output_seg_loss: -0.6302 - val_loss: -0.6153 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6956 - val_output_seg_loss: -0.6193 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 75/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6243 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7339 - output_seg_loss: -0.6302\n",
      "Epoch 75: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6242 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7339 - output_seg_loss: -0.6302 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 76/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6212 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7381 - output_seg_loss: -0.6277\n",
      "Epoch 76: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6213 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7381 - output_seg_loss: -0.6278 - val_loss: -0.6154 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6195 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 77/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6212 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7382 - output_seg_loss: -0.6276\n",
      "Epoch 77: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6212 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7382 - output_seg_loss: -0.6276 - val_loss: -0.6152 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6955 - val_output_seg_loss: -0.6192 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 78/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6208 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7360 - output_seg_loss: -0.6270\n",
      "Epoch 78: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6208 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7360 - output_seg_loss: -0.6271 - val_loss: -0.6152 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6956 - val_output_seg_loss: -0.6193 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 79/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6106 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7259 - output_seg_loss: -0.6167\n",
      "Epoch 79: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6109 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7261 - output_seg_loss: -0.6170 - val_loss: -0.6152 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6956 - val_output_seg_loss: -0.6193 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 80/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6168 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7297 - output_seg_loss: -0.6228\n",
      "Epoch 80: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6168 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7298 - output_seg_loss: -0.6229 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6195 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 81/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6255 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7353 - output_seg_loss: -0.6314\n",
      "Epoch 81: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6254 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7353 - output_seg_loss: -0.6313 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6957 - val_output_seg_loss: -0.6195 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 82/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6245 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7336 - output_seg_loss: -0.6304\n",
      "Epoch 82: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6244 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7337 - output_seg_loss: -0.6303 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 83/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6260 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7397 - output_seg_loss: -0.6322\n",
      "Epoch 83: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6259 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7396 - output_seg_loss: -0.6321 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 84/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6270 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7416 - output_seg_loss: -0.6331\n",
      "Epoch 84: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6268 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7415 - output_seg_loss: -0.6330 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 85/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.6318 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7428 - output_seg_loss: -0.6377\n",
      "Epoch 85: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.6315 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7426 - output_seg_loss: -0.6375 - val_loss: -0.6155 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 86/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.6347 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7490 - output_seg_loss: -0.6425\n",
      "Epoch 86: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6343 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7488 - output_seg_loss: -0.6422 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 87/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6247 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7381 - output_seg_loss: -0.6329\n",
      "Epoch 87: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6245 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7380 - output_seg_loss: -0.6327 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6196 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 88/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6353 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7461 - output_seg_loss: -0.6429\n",
      "Epoch 88: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6350 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7458 - output_seg_loss: -0.6426 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 89/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6333 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7468 - output_seg_loss: -0.6408\n",
      "Epoch 89: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6330 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7466 - output_seg_loss: -0.6405 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 90/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6362 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7463 - output_seg_loss: -0.6435\n",
      "Epoch 90: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6359 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7461 - output_seg_loss: -0.6431 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 91/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6347 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7459 - output_seg_loss: -0.6420\n",
      "Epoch 91: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6344 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7457 - output_seg_loss: -0.6417 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 92/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6308 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7401 - output_seg_loss: -0.6379\n",
      "Epoch 92: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6306 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7400 - output_seg_loss: -0.6377 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 93/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6269 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7398 - output_seg_loss: -0.6343\n",
      "Epoch 93: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6268 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7397 - output_seg_loss: -0.6341 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 94/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6278 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7413 - output_seg_loss: -0.6352\n",
      "Epoch 94: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6276 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7413 - output_seg_loss: -0.6350 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 95/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6276 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7361 - output_seg_loss: -0.6343\n",
      "Epoch 95: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.6274 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7361 - output_seg_loss: -0.6341 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 96/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6264 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7359 - output_seg_loss: -0.6332\n",
      "Epoch 96: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6264 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7359 - output_seg_loss: -0.6332 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 97/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.6074 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7306 - output_seg_loss: -0.6149\n",
      "Epoch 97: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.6077 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7307 - output_seg_loss: -0.6152 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 98/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6166 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7375 - output_seg_loss: -0.6237\n",
      "Epoch 98: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6168 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7376 - output_seg_loss: -0.6238 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6958 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 99/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6060 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7305 - output_seg_loss: -0.6133\n",
      "Epoch 99: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6064 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7306 - output_seg_loss: -0.6137 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 100/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.6040 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7247 - output_seg_loss: -0.6112\n",
      "Epoch 100: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6045 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7250 - output_seg_loss: -0.6117 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 101/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6055 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7273 - output_seg_loss: -0.6125\n",
      "Epoch 101: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6058 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7275 - output_seg_loss: -0.6129 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 102/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6094 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7303 - output_seg_loss: -0.6165\n",
      "Epoch 102: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6097 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7304 - output_seg_loss: -0.6167 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 103/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6153 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7316 - output_seg_loss: -0.6221\n",
      "Epoch 103: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6154 - output_dis_loss: 0.0059 - output_dis_mse_score: 0.0059 - output_seg_dice_coef: 0.7317 - output_seg_loss: -0.6222 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 104/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6198 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7310 - output_seg_loss: -0.6261\n",
      "Epoch 104: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6198 - output_dis_loss: 0.0057 - output_dis_mse_score: 0.0057 - output_seg_dice_coef: 0.7311 - output_seg_loss: -0.6262 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 105/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6148 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7311 - output_seg_loss: -0.6216\n",
      "Epoch 105: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6149 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7312 - output_seg_loss: -0.6218 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 106/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6143 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7333 - output_seg_loss: -0.6211\n",
      "Epoch 106: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6145 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7334 - output_seg_loss: -0.6213 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 107/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6032 - output_dis_loss: 0.0065 - output_dis_mse_score: 0.0065 - output_seg_dice_coef: 0.7292 - output_seg_loss: -0.6103\n",
      "Epoch 107: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6036 - output_dis_loss: 0.0065 - output_dis_mse_score: 0.0065 - output_seg_dice_coef: 0.7294 - output_seg_loss: -0.6107 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 108/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6124 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7316 - output_seg_loss: -0.6192\n",
      "Epoch 108: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6125 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7316 - output_seg_loss: -0.6193 - val_loss: -0.6157 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 109/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6166 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7357 - output_seg_loss: -0.6233\n",
      "Epoch 109: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6166 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7357 - output_seg_loss: -0.6234 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 110/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6189 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7369 - output_seg_loss: -0.6255\n",
      "Epoch 110: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6189 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7369 - output_seg_loss: -0.6256 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 111/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6186 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7348 - output_seg_loss: -0.6250\n",
      "Epoch 111: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6187 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7349 - output_seg_loss: -0.6251 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 112/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6199 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7367 - output_seg_loss: -0.6265\n",
      "Epoch 112: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6199 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7367 - output_seg_loss: -0.6265 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 113/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6212 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7358 - output_seg_loss: -0.6276\n",
      "Epoch 113: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6212 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7358 - output_seg_loss: -0.6276 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 114/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6225 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7375 - output_seg_loss: -0.6289\n",
      "Epoch 114: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6224 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7374 - output_seg_loss: -0.6288 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 115/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6282 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7422 - output_seg_loss: -0.6346\n",
      "Epoch 115: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6280 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.7421 - output_seg_loss: -0.6344 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 116/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.6274 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7370 - output_seg_loss: -0.6334\n",
      "Epoch 116: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.6272 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7370 - output_seg_loss: -0.6333 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 117/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6240 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7337 - output_seg_loss: -0.6300\n",
      "Epoch 117: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6239 - output_dis_loss: 0.0058 - output_dis_mse_score: 0.0058 - output_seg_dice_coef: 0.7337 - output_seg_loss: -0.6300 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 118/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6205 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7376 - output_seg_loss: -0.6270\n",
      "Epoch 118: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6205 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0063 - output_seg_dice_coef: 0.7376 - output_seg_loss: -0.6270 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 119/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6191 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7368 - output_seg_loss: -0.6255\n",
      "Epoch 119: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6191 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.7368 - output_seg_loss: -0.6255 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 120/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: -0.6211 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7362 - output_seg_loss: -0.6273\n",
      "Epoch 120: val_output_seg_dice_coef did not improve from 0.69803\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.6211 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.7362 - output_seg_loss: -0.6274 - val_loss: -0.6156 - val_output_dis_loss: 0.0041 - val_output_dis_mse_score: 0.0041 - val_output_seg_dice_coef: 0.6959 - val_output_seg_loss: -0.6197 - learning_rate: 1.0000e-08\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333/333 [11:18<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold1: 0.00\n",
      "average AJI pure Unet for fold1: 0.00\n",
      "average PQ pure Unet for fold1: 0.00\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold1: 0.37\n",
      "average AJI Unet watershed for fold1: 0.18\n",
      "average PQ Unet watershed for fold1: 0.18\n",
      "==========\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.1028 - output_dis_loss: 0.0157 - output_dis_mse_score: 0.0157 - output_seg_dice_coef: 0.2298 - output_seg_loss: 0.0871\n",
      "Epoch 1: val_output_seg_dice_coef improved from -inf to 0.10234, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 319ms/step - loss: 0.1024 - output_dis_loss: 0.0157 - output_dis_mse_score: 0.0157 - output_seg_dice_coef: 0.2294 - output_seg_loss: 0.0867 - val_loss: 0.0851 - val_output_dis_loss: 0.0075 - val_output_dis_mse_score: 0.0075 - val_output_seg_dice_coef: 0.1023 - val_output_seg_loss: 0.0776 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760435491.502904      63 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1760435491.736671      63 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0518 - output_dis_loss: 0.0147 - output_dis_mse_score: 0.0148 - output_seg_dice_coef: 0.1980 - output_seg_loss: 0.0374\n",
      "Epoch 2: val_output_seg_dice_coef did not improve from 0.10234\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 215ms/step - loss: 0.0518 - output_dis_loss: 0.0147 - output_dis_mse_score: 0.0148 - output_seg_dice_coef: 0.1980 - output_seg_loss: 0.0374 - val_loss: 0.0593 - val_output_dis_loss: 0.0075 - val_output_dis_mse_score: 0.0075 - val_output_seg_dice_coef: 0.0976 - val_output_seg_loss: 0.0518 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0325 - output_dis_loss: 0.0152 - output_dis_mse_score: 0.0154 - output_seg_dice_coef: 0.2130 - output_seg_loss: 0.0174\n",
      "Epoch 3: val_output_seg_dice_coef improved from 0.10234 to 0.11202, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0327 - output_dis_loss: 0.0152 - output_dis_mse_score: 0.0154 - output_seg_dice_coef: 0.2133 - output_seg_loss: 0.0175 - val_loss: 0.1834 - val_output_dis_loss: 0.0073 - val_output_dis_mse_score: 0.0073 - val_output_seg_dice_coef: 0.1120 - val_output_seg_loss: 0.1761 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0596 - output_dis_loss: 0.0152 - output_dis_mse_score: 0.0154 - output_seg_dice_coef: 0.2100 - output_seg_loss: 0.0457\n",
      "Epoch 4: val_output_seg_dice_coef did not improve from 0.11202\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0595 - output_dis_loss: 0.0152 - output_dis_mse_score: 0.0154 - output_seg_dice_coef: 0.2099 - output_seg_loss: 0.0457 - val_loss: 0.0857 - val_output_dis_loss: 0.0072 - val_output_dis_mse_score: 0.0072 - val_output_seg_dice_coef: 0.1029 - val_output_seg_loss: 0.0785 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0512 - output_dis_loss: 0.0139 - output_dis_mse_score: 0.0140 - output_seg_dice_coef: 0.1930 - output_seg_loss: 0.0375\n",
      "Epoch 5: val_output_seg_dice_coef did not improve from 0.11202\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0511 - output_dis_loss: 0.0139 - output_dis_mse_score: 0.0140 - output_seg_dice_coef: 0.1932 - output_seg_loss: 0.0374 - val_loss: 0.0745 - val_output_dis_loss: 0.0074 - val_output_dis_mse_score: 0.0074 - val_output_seg_dice_coef: 0.1071 - val_output_seg_loss: 0.0671 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0056 - output_dis_loss: 0.0132 - output_dis_mse_score: 0.0133 - output_seg_dice_coef: 0.2224 - output_seg_loss: -0.0074\n",
      "Epoch 6: val_output_seg_dice_coef improved from 0.11202 to 0.14188, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.0049 - output_dis_loss: 0.0132 - output_dis_mse_score: 0.0133 - output_seg_dice_coef: 0.2231 - output_seg_loss: -0.0081 - val_loss: 0.0943 - val_output_dis_loss: 0.0071 - val_output_dis_mse_score: 0.0071 - val_output_seg_dice_coef: 0.1419 - val_output_seg_loss: 0.0872 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.0652 - output_dis_loss: 0.0131 - output_dis_mse_score: 0.0131 - output_seg_dice_coef: 0.2977 - output_seg_loss: -0.0812\n",
      "Epoch 7: val_output_seg_dice_coef improved from 0.14188 to 0.16849, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.0654 - output_dis_loss: 0.0131 - output_dis_mse_score: 0.0131 - output_seg_dice_coef: 0.2980 - output_seg_loss: -0.0814 - val_loss: 0.0388 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.1685 - val_output_seg_loss: 0.0307 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.1206 - output_dis_loss: 0.0132 - output_dis_mse_score: 0.0133 - output_seg_dice_coef: 0.3609 - output_seg_loss: -0.1340\n",
      "Epoch 8: val_output_seg_dice_coef did not improve from 0.16849\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.1221 - output_dis_loss: 0.0132 - output_dis_mse_score: 0.0132 - output_seg_dice_coef: 0.3620 - output_seg_loss: -0.1355 - val_loss: 0.0789 - val_output_dis_loss: 0.0072 - val_output_dis_mse_score: 0.0072 - val_output_seg_dice_coef: 0.0745 - val_output_seg_loss: 0.0717 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.1933 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4252 - output_seg_loss: -0.2078\n",
      "Epoch 9: val_output_seg_dice_coef did not improve from 0.16849\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.1939 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4256 - output_seg_loss: -0.2084 - val_loss: 0.1338 - val_output_dis_loss: 0.0072 - val_output_dis_mse_score: 0.0072 - val_output_seg_dice_coef: 0.0487 - val_output_seg_loss: 0.1266 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.1790 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.4142 - output_seg_loss: -0.1938\n",
      "Epoch 10: val_output_seg_dice_coef improved from 0.16849 to 0.17324, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.1794 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.4144 - output_seg_loss: -0.1942 - val_loss: -0.0520 - val_output_dis_loss: 0.0070 - val_output_dis_mse_score: 0.0070 - val_output_seg_dice_coef: 0.1732 - val_output_seg_loss: -0.0589 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.2191 - output_dis_loss: 0.0112 - output_dis_mse_score: 0.0113 - output_seg_dice_coef: 0.4271 - output_seg_loss: -0.2319\n",
      "Epoch 11: val_output_seg_dice_coef improved from 0.17324 to 0.21726, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.2191 - output_dis_loss: 0.0112 - output_dis_mse_score: 0.0113 - output_seg_dice_coef: 0.4273 - output_seg_loss: -0.2319 - val_loss: -0.1081 - val_output_dis_loss: 0.0066 - val_output_dis_mse_score: 0.0066 - val_output_seg_dice_coef: 0.2173 - val_output_seg_loss: -0.1147 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.2301 - output_dis_loss: 0.0116 - output_dis_mse_score: 0.0116 - output_seg_dice_coef: 0.4357 - output_seg_loss: -0.2434\n",
      "Epoch 12: val_output_seg_dice_coef improved from 0.21726 to 0.21791, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.2306 - output_dis_loss: 0.0116 - output_dis_mse_score: 0.0116 - output_seg_dice_coef: 0.4361 - output_seg_loss: -0.2438 - val_loss: -0.1064 - val_output_dis_loss: 0.0067 - val_output_dis_mse_score: 0.0067 - val_output_seg_dice_coef: 0.2179 - val_output_seg_loss: -0.1131 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.2610 - output_dis_loss: 0.0118 - output_dis_mse_score: 0.0118 - output_seg_dice_coef: 0.4684 - output_seg_loss: -0.2732\n",
      "Epoch 13: val_output_seg_dice_coef improved from 0.21791 to 0.24054, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.2614 - output_dis_loss: 0.0118 - output_dis_mse_score: 0.0118 - output_seg_dice_coef: 0.4686 - output_seg_loss: -0.2736 - val_loss: -0.1292 - val_output_dis_loss: 0.0066 - val_output_dis_mse_score: 0.0066 - val_output_seg_dice_coef: 0.2405 - val_output_seg_loss: -0.1358 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.2804 - output_dis_loss: 0.0117 - output_dis_mse_score: 0.0118 - output_seg_dice_coef: 0.4902 - output_seg_loss: -0.2927\n",
      "Epoch 14: val_output_seg_dice_coef improved from 0.24054 to 0.25149, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.2803 - output_dis_loss: 0.0117 - output_dis_mse_score: 0.0118 - output_seg_dice_coef: 0.4901 - output_seg_loss: -0.2927 - val_loss: -0.1362 - val_output_dis_loss: 0.0066 - val_output_dis_mse_score: 0.0066 - val_output_seg_dice_coef: 0.2515 - val_output_seg_loss: -0.1428 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.3209 - output_dis_loss: 0.0112 - output_dis_mse_score: 0.0112 - output_seg_dice_coef: 0.5080 - output_seg_loss: -0.3319\n",
      "Epoch 15: val_output_seg_dice_coef did not improve from 0.25149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.3210 - output_dis_loss: 0.0112 - output_dis_mse_score: 0.0112 - output_seg_dice_coef: 0.5083 - output_seg_loss: -0.3320 - val_loss: -0.0995 - val_output_dis_loss: 0.0068 - val_output_dis_mse_score: 0.0068 - val_output_seg_dice_coef: 0.2297 - val_output_seg_loss: -0.1063 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.3485 - output_dis_loss: 0.0110 - output_dis_mse_score: 0.0111 - output_seg_dice_coef: 0.5351 - output_seg_loss: -0.3603\n",
      "Epoch 16: val_output_seg_dice_coef did not improve from 0.25149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.3488 - output_dis_loss: 0.0110 - output_dis_mse_score: 0.0111 - output_seg_dice_coef: 0.5353 - output_seg_loss: -0.3605 - val_loss: -0.1258 - val_output_dis_loss: 0.0067 - val_output_dis_mse_score: 0.0067 - val_output_seg_dice_coef: 0.2473 - val_output_seg_loss: -0.1325 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.3740 - output_dis_loss: 0.0109 - output_dis_mse_score: 0.0109 - output_seg_dice_coef: 0.5593 - output_seg_loss: -0.3844\n",
      "Epoch 17: val_output_seg_dice_coef improved from 0.25149 to 0.35450, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.3743 - output_dis_loss: 0.0108 - output_dis_mse_score: 0.0108 - output_seg_dice_coef: 0.5594 - output_seg_loss: -0.3846 - val_loss: -0.2393 - val_output_dis_loss: 0.0061 - val_output_dis_mse_score: 0.0061 - val_output_seg_dice_coef: 0.3545 - val_output_seg_loss: -0.2454 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4102 - output_dis_loss: 0.0103 - output_dis_mse_score: 0.0104 - output_seg_dice_coef: 0.5914 - output_seg_loss: -0.4209\n",
      "Epoch 18: val_output_seg_dice_coef improved from 0.35450 to 0.38443, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.4102 - output_dis_loss: 0.0103 - output_dis_mse_score: 0.0103 - output_seg_dice_coef: 0.5912 - output_seg_loss: -0.4208 - val_loss: -0.2573 - val_output_dis_loss: 0.0061 - val_output_dis_mse_score: 0.0061 - val_output_seg_dice_coef: 0.3844 - val_output_seg_loss: -0.2634 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.4199 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5883 - output_seg_loss: -0.4301\n",
      "Epoch 19: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.4200 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5884 - output_seg_loss: -0.4302 - val_loss: -0.2487 - val_output_dis_loss: 0.0062 - val_output_dis_mse_score: 0.0062 - val_output_seg_dice_coef: 0.3758 - val_output_seg_loss: -0.2549 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4256 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5968 - output_seg_loss: -0.4355\n",
      "Epoch 20: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.4259 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5969 - output_seg_loss: -0.4357 - val_loss: -0.2605 - val_output_dis_loss: 0.0060 - val_output_dis_mse_score: 0.0060 - val_output_seg_dice_coef: 0.3780 - val_output_seg_loss: -0.2665 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4440 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6099 - output_seg_loss: -0.4536\n",
      "Epoch 21: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: -0.4443 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6099 - output_seg_loss: -0.4539 - val_loss: -0.2442 - val_output_dis_loss: 0.0060 - val_output_dis_mse_score: 0.0060 - val_output_seg_dice_coef: 0.3631 - val_output_seg_loss: -0.2502 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4766 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6368 - output_seg_loss: -0.4861\n",
      "Epoch 22: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: -0.4765 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6366 - output_seg_loss: -0.4860 - val_loss: -0.2439 - val_output_dis_loss: 0.0059 - val_output_dis_mse_score: 0.0059 - val_output_seg_dice_coef: 0.3644 - val_output_seg_loss: -0.2498 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4787 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6391 - output_seg_loss: -0.4880\n",
      "Epoch 23: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.4787 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6389 - output_seg_loss: -0.4880 - val_loss: -0.2454 - val_output_dis_loss: 0.0059 - val_output_dis_mse_score: 0.0059 - val_output_seg_dice_coef: 0.3654 - val_output_seg_loss: -0.2512 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4829 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6409 - output_seg_loss: -0.4920\n",
      "Epoch 24: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.4828 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6407 - output_seg_loss: -0.4920 - val_loss: -0.2541 - val_output_dis_loss: 0.0058 - val_output_dis_mse_score: 0.0058 - val_output_seg_dice_coef: 0.3719 - val_output_seg_loss: -0.2599 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.4942 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.6478 - output_seg_loss: -0.5030\n",
      "Epoch 25: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.4941 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.6476 - output_seg_loss: -0.5029 - val_loss: -0.2603 - val_output_dis_loss: 0.0058 - val_output_dis_mse_score: 0.0058 - val_output_seg_dice_coef: 0.3784 - val_output_seg_loss: -0.2660 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.4962 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6510 - output_seg_loss: -0.5051\n",
      "Epoch 26: val_output_seg_dice_coef did not improve from 0.38443\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.4961 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6509 - output_seg_loss: -0.5051 - val_loss: -0.2647 - val_output_dis_loss: 0.0058 - val_output_dis_mse_score: 0.0058 - val_output_seg_dice_coef: 0.3835 - val_output_seg_loss: -0.2705 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5056 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0082 - output_seg_dice_coef: 0.6546 - output_seg_loss: -0.5141\n",
      "Epoch 27: val_output_seg_dice_coef improved from 0.38443 to 0.39415, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5055 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0082 - output_seg_dice_coef: 0.6545 - output_seg_loss: -0.5141 - val_loss: -0.2760 - val_output_dis_loss: 0.0057 - val_output_dis_mse_score: 0.0057 - val_output_seg_dice_coef: 0.3942 - val_output_seg_loss: -0.2817 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.4914 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6363 - output_seg_loss: -0.4996\n",
      "Epoch 28: val_output_seg_dice_coef improved from 0.39415 to 0.39770, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.4917 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6366 - output_seg_loss: -0.4999 - val_loss: -0.2795 - val_output_dis_loss: 0.0057 - val_output_dis_mse_score: 0.0057 - val_output_seg_dice_coef: 0.3977 - val_output_seg_loss: -0.2852 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5050 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6473 - output_seg_loss: -0.5131\n",
      "Epoch 29: val_output_seg_dice_coef improved from 0.39770 to 0.40208, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5051 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6474 - output_seg_loss: -0.5132 - val_loss: -0.2840 - val_output_dis_loss: 0.0057 - val_output_dis_mse_score: 0.0057 - val_output_seg_dice_coef: 0.4021 - val_output_seg_loss: -0.2897 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5022 - output_dis_loss: 0.0081 - output_dis_mse_score: 0.0081 - output_seg_dice_coef: 0.6507 - output_seg_loss: -0.5105\n",
      "Epoch 30: val_output_seg_dice_coef improved from 0.40208 to 0.41052, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5024 - output_dis_loss: 0.0081 - output_dis_mse_score: 0.0081 - output_seg_dice_coef: 0.6509 - output_seg_loss: -0.5108 - val_loss: -0.2940 - val_output_dis_loss: 0.0056 - val_output_dis_mse_score: 0.0056 - val_output_seg_dice_coef: 0.4105 - val_output_seg_loss: -0.2996 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 31/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5161 - output_dis_loss: 0.0077 - output_dis_mse_score: 0.0077 - output_seg_dice_coef: 0.6574 - output_seg_loss: -0.5240\n",
      "Epoch 31: val_output_seg_dice_coef improved from 0.41052 to 0.41548, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5161 - output_dis_loss: 0.0077 - output_dis_mse_score: 0.0077 - output_seg_dice_coef: 0.6575 - output_seg_loss: -0.5241 - val_loss: -0.2994 - val_output_dis_loss: 0.0055 - val_output_dis_mse_score: 0.0055 - val_output_seg_dice_coef: 0.4155 - val_output_seg_loss: -0.3050 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 32/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5150 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6542 - output_seg_loss: -0.5228\n",
      "Epoch 32: val_output_seg_dice_coef improved from 0.41548 to 0.42137, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5151 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6544 - output_seg_loss: -0.5229 - val_loss: -0.3069 - val_output_dis_loss: 0.0055 - val_output_dis_mse_score: 0.0055 - val_output_seg_dice_coef: 0.4214 - val_output_seg_loss: -0.3123 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 33/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5275 - output_dis_loss: 0.0077 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6669 - output_seg_loss: -0.5355\n",
      "Epoch 33: val_output_seg_dice_coef improved from 0.42137 to 0.42584, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.5275 - output_dis_loss: 0.0077 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6668 - output_seg_loss: -0.5354 - val_loss: -0.3130 - val_output_dis_loss: 0.0054 - val_output_dis_mse_score: 0.0054 - val_output_seg_dice_coef: 0.4258 - val_output_seg_loss: -0.3184 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 34/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5365 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6734 - output_seg_loss: -0.5443\n",
      "Epoch 34: val_output_seg_dice_coef improved from 0.42584 to 0.42978, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5363 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6733 - output_seg_loss: -0.5441 - val_loss: -0.3183 - val_output_dis_loss: 0.0054 - val_output_dis_mse_score: 0.0054 - val_output_seg_dice_coef: 0.4298 - val_output_seg_loss: -0.3237 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 35/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5385 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6762 - output_seg_loss: -0.5463\n",
      "Epoch 35: val_output_seg_dice_coef improved from 0.42978 to 0.43516, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5384 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6761 - output_seg_loss: -0.5462 - val_loss: -0.3245 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.4352 - val_output_seg_loss: -0.3299 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 36/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: -0.5406 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6775 - output_seg_loss: -0.5483\n",
      "Epoch 36: val_output_seg_dice_coef improved from 0.43516 to 0.43922, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.5405 - output_dis_loss: 0.0076 - output_dis_mse_score: 0.0076 - output_seg_dice_coef: 0.6774 - output_seg_loss: -0.5482 - val_loss: -0.3292 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.4392 - val_output_seg_loss: -0.3345 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 37/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5492 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.6834 - output_seg_loss: -0.5568\n",
      "Epoch 37: val_output_seg_dice_coef improved from 0.43922 to 0.44237, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5490 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.6833 - output_seg_loss: -0.5567 - val_loss: -0.3331 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.4424 - val_output_seg_loss: -0.3384 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 38/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: -0.5484 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6822 - output_seg_loss: -0.5558\n",
      "Epoch 38: val_output_seg_dice_coef improved from 0.44237 to 0.44482, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.5483 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6822 - output_seg_loss: -0.5557 - val_loss: -0.3372 - val_output_dis_loss: 0.0052 - val_output_dis_mse_score: 0.0052 - val_output_seg_dice_coef: 0.4448 - val_output_seg_loss: -0.3424 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 39/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5492 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6819 - output_seg_loss: -0.5565\n",
      "Epoch 39: val_output_seg_dice_coef improved from 0.44482 to 0.44854, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5491 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6819 - output_seg_loss: -0.5564 - val_loss: -0.3421 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4485 - val_output_seg_loss: -0.3472 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 40/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5616 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6921 - output_seg_loss: -0.5688\n",
      "Epoch 40: val_output_seg_dice_coef did not improve from 0.44854\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: -0.5613 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6919 - output_seg_loss: -0.5686 - val_loss: -0.3420 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4485 - val_output_seg_loss: -0.3471 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 41/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5659 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6940 - output_seg_loss: -0.5732\n",
      "Epoch 41: val_output_seg_dice_coef improved from 0.44854 to 0.45647, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5656 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6938 - output_seg_loss: -0.5730 - val_loss: -0.3481 - val_output_dis_loss: 0.0052 - val_output_dis_mse_score: 0.0052 - val_output_seg_dice_coef: 0.4565 - val_output_seg_loss: -0.3533 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 42/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5786 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7035 - output_seg_loss: -0.5857\n",
      "Epoch 42: val_output_seg_dice_coef improved from 0.45647 to 0.46121, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5783 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7032 - output_seg_loss: -0.5854 - val_loss: -0.3540 - val_output_dis_loss: 0.0052 - val_output_dis_mse_score: 0.0052 - val_output_seg_dice_coef: 0.4612 - val_output_seg_loss: -0.3591 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 43/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: -0.5628 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6951 - output_seg_loss: -0.5701\n",
      "Epoch 43: val_output_seg_dice_coef improved from 0.46121 to 0.46419, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.5627 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6950 - output_seg_loss: -0.5700 - val_loss: -0.3573 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4642 - val_output_seg_loss: -0.3625 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 44/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: -0.5680 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6960 - output_seg_loss: -0.5766\n",
      "Epoch 44: val_output_seg_dice_coef improved from 0.46419 to 0.46654, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5678 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6959 - output_seg_loss: -0.5764 - val_loss: -0.3601 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4665 - val_output_seg_loss: -0.3652 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 45/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5766 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7043 - output_seg_loss: -0.5846\n",
      "Epoch 45: val_output_seg_dice_coef improved from 0.46654 to 0.46757, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5762 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7039 - output_seg_loss: -0.5842 - val_loss: -0.3612 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4676 - val_output_seg_loss: -0.3664 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 46/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5850 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7101 - output_seg_loss: -0.5925\n",
      "Epoch 46: val_output_seg_dice_coef improved from 0.46757 to 0.46911, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5846 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7098 - output_seg_loss: -0.5920 - val_loss: -0.3630 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4691 - val_output_seg_loss: -0.3681 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 47/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: -0.5760 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7011 - output_seg_loss: -0.5839\n",
      "Epoch 47: val_output_seg_dice_coef improved from 0.46911 to 0.47028, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.5758 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7010 - output_seg_loss: -0.5836 - val_loss: -0.3642 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4703 - val_output_seg_loss: -0.3693 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 48/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5733 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6988 - output_seg_loss: -0.5811\n",
      "Epoch 48: val_output_seg_dice_coef improved from 0.47028 to 0.47113, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5731 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6987 - output_seg_loss: -0.5809 - val_loss: -0.3653 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4711 - val_output_seg_loss: -0.3704 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 49/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5672 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6914 - output_seg_loss: -0.5748\n",
      "Epoch 49: val_output_seg_dice_coef improved from 0.47113 to 0.47228, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5672 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6915 - output_seg_loss: -0.5748 - val_loss: -0.3668 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4723 - val_output_seg_loss: -0.3718 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 50/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5580 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6853 - output_seg_loss: -0.5657\n",
      "Epoch 50: val_output_seg_dice_coef improved from 0.47228 to 0.47362, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5582 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6855 - output_seg_loss: -0.5658 - val_loss: -0.3682 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4736 - val_output_seg_loss: -0.3733 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 51/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5657 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6947 - output_seg_loss: -0.5736\n",
      "Epoch 51: val_output_seg_dice_coef improved from 0.47362 to 0.47470, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5657 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6947 - output_seg_loss: -0.5736 - val_loss: -0.3694 - val_output_dis_loss: 0.0051 - val_output_dis_mse_score: 0.0051 - val_output_seg_dice_coef: 0.4747 - val_output_seg_loss: -0.3745 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 52/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5577 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6887 - output_seg_loss: -0.5655\n",
      "Epoch 52: val_output_seg_dice_coef improved from 0.47470 to 0.47558, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5579 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6889 - output_seg_loss: -0.5658 - val_loss: -0.3705 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4756 - val_output_seg_loss: -0.3755 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 53/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5489 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6772 - output_seg_loss: -0.5566\n",
      "Epoch 53: val_output_seg_dice_coef improved from 0.47558 to 0.47700, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5493 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6777 - output_seg_loss: -0.5570 - val_loss: -0.3723 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4770 - val_output_seg_loss: -0.3773 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 54/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5546 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6836 - output_seg_loss: -0.5621\n",
      "Epoch 54: val_output_seg_dice_coef improved from 0.47700 to 0.47797, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5549 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6839 - output_seg_loss: -0.5625 - val_loss: -0.3735 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4780 - val_output_seg_loss: -0.3785 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 55/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5444 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6802 - output_seg_loss: -0.5523\n",
      "Epoch 55: val_output_seg_dice_coef improved from 0.47797 to 0.47829, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5448 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6805 - output_seg_loss: -0.5527 - val_loss: -0.3739 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4783 - val_output_seg_loss: -0.3789 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 56/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5560 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6881 - output_seg_loss: -0.5637\n",
      "Epoch 56: val_output_seg_dice_coef improved from 0.47829 to 0.47870, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5562 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6883 - output_seg_loss: -0.5639 - val_loss: -0.3745 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4787 - val_output_seg_loss: -0.3795 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 57/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5649 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6939 - output_seg_loss: -0.5725\n",
      "Epoch 57: val_output_seg_dice_coef improved from 0.47870 to 0.47993, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5649 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6940 - output_seg_loss: -0.5725 - val_loss: -0.3762 - val_output_dis_loss: 0.0050 - val_output_dis_mse_score: 0.0050 - val_output_seg_dice_coef: 0.4799 - val_output_seg_loss: -0.3812 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 58/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5662 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6950 - output_seg_loss: -0.5738\n",
      "Epoch 58: val_output_seg_dice_coef improved from 0.47993 to 0.48100, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5663 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6950 - output_seg_loss: -0.5738 - val_loss: -0.3778 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4810 - val_output_seg_loss: -0.3827 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 59/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5623 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6955 - output_seg_loss: -0.5701\n",
      "Epoch 59: val_output_seg_dice_coef improved from 0.48100 to 0.48170, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5625 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6955 - output_seg_loss: -0.5702 - val_loss: -0.3786 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4817 - val_output_seg_loss: -0.3835 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 60/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5670 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.7017 - output_seg_loss: -0.5749\n",
      "Epoch 60: val_output_seg_dice_coef improved from 0.48170 to 0.48237, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5670 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.7016 - output_seg_loss: -0.5749 - val_loss: -0.3795 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4824 - val_output_seg_loss: -0.3844 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 61/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5677 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6979 - output_seg_loss: -0.5754\n",
      "Epoch 61: val_output_seg_dice_coef improved from 0.48237 to 0.48244, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5678 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6980 - output_seg_loss: -0.5755 - val_loss: -0.3796 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4824 - val_output_seg_loss: -0.3845 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 62/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5629 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.6961 - output_seg_loss: -0.5708\n",
      "Epoch 62: val_output_seg_dice_coef improved from 0.48244 to 0.48256, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5630 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.6961 - output_seg_loss: -0.5709 - val_loss: -0.3797 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4826 - val_output_seg_loss: -0.3846 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 63/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5616 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6965 - output_seg_loss: -0.5693\n",
      "Epoch 63: val_output_seg_dice_coef improved from 0.48256 to 0.48268, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5617 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6965 - output_seg_loss: -0.5695 - val_loss: -0.3799 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4827 - val_output_seg_loss: -0.3848 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 64/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5693 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.7034 - output_seg_loss: -0.5771\n",
      "Epoch 64: val_output_seg_dice_coef improved from 0.48268 to 0.48278, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5693 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.7033 - output_seg_loss: -0.5771 - val_loss: -0.3800 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4828 - val_output_seg_loss: -0.3849 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 65/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5654 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7005 - output_seg_loss: -0.5729\n",
      "Epoch 65: val_output_seg_dice_coef improved from 0.48278 to 0.48283, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5655 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7005 - output_seg_loss: -0.5730 - val_loss: -0.3800 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4828 - val_output_seg_loss: -0.3849 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 66/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5658 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6999 - output_seg_loss: -0.5733\n",
      "Epoch 66: val_output_seg_dice_coef improved from 0.48283 to 0.48293, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5659 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6998 - output_seg_loss: -0.5734 - val_loss: -0.3802 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4829 - val_output_seg_loss: -0.3851 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 67/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5717 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7038 - output_seg_loss: -0.5791\n",
      "Epoch 67: val_output_seg_dice_coef improved from 0.48293 to 0.48293, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5716 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7037 - output_seg_loss: -0.5791 - val_loss: -0.3802 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4829 - val_output_seg_loss: -0.3851 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 68/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5704 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7037 - output_seg_loss: -0.5779\n",
      "Epoch 68: val_output_seg_dice_coef improved from 0.48293 to 0.48305, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5704 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7036 - output_seg_loss: -0.5779 - val_loss: -0.3803 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4831 - val_output_seg_loss: -0.3852 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 69/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5712 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7021 - output_seg_loss: -0.5785\n",
      "Epoch 69: val_output_seg_dice_coef improved from 0.48305 to 0.48313, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5712 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7021 - output_seg_loss: -0.5785 - val_loss: -0.3804 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4831 - val_output_seg_loss: -0.3853 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 70/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5640 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6884 - output_seg_loss: -0.5710\n",
      "Epoch 70: val_output_seg_dice_coef improved from 0.48313 to 0.48323, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5641 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6886 - output_seg_loss: -0.5711 - val_loss: -0.3805 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4832 - val_output_seg_loss: -0.3854 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 71/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5725 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6953 - output_seg_loss: -0.5794\n",
      "Epoch 71: val_output_seg_dice_coef improved from 0.48323 to 0.48333, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5724 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6954 - output_seg_loss: -0.5794 - val_loss: -0.3806 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4833 - val_output_seg_loss: -0.3856 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 72/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5659 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.6956 - output_seg_loss: -0.5733\n",
      "Epoch 72: val_output_seg_dice_coef improved from 0.48333 to 0.48340, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5660 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6957 - output_seg_loss: -0.5734 - val_loss: -0.3807 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4834 - val_output_seg_loss: -0.3856 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 73/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5718 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6965 - output_seg_loss: -0.5788\n",
      "Epoch 73: val_output_seg_dice_coef did not improve from 0.48340\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5718 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6966 - output_seg_loss: -0.5788 - val_loss: -0.3806 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4834 - val_output_seg_loss: -0.3855 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 74/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5649 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6895 - output_seg_loss: -0.5718\n",
      "Epoch 74: val_output_seg_dice_coef improved from 0.48340 to 0.48344, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5649 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6896 - output_seg_loss: -0.5719 - val_loss: -0.3807 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4834 - val_output_seg_loss: -0.3856 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 75/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5750 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6998 - output_seg_loss: -0.5821\n",
      "Epoch 75: val_output_seg_dice_coef improved from 0.48344 to 0.48349, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5748 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6997 - output_seg_loss: -0.5820 - val_loss: -0.3808 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4835 - val_output_seg_loss: -0.3857 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 76/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5782 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7030 - output_seg_loss: -0.5853\n",
      "Epoch 76: val_output_seg_dice_coef improved from 0.48349 to 0.48354, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5781 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7030 - output_seg_loss: -0.5852 - val_loss: -0.3808 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4835 - val_output_seg_loss: -0.3857 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 77/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5739 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7014 - output_seg_loss: -0.5811\n",
      "Epoch 77: val_output_seg_dice_coef improved from 0.48354 to 0.48363, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5738 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7013 - output_seg_loss: -0.5810 - val_loss: -0.3809 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4836 - val_output_seg_loss: -0.3858 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 78/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5736 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7011 - output_seg_loss: -0.5808\n",
      "Epoch 78: val_output_seg_dice_coef improved from 0.48363 to 0.48373, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5735 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7011 - output_seg_loss: -0.5807 - val_loss: -0.3810 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4837 - val_output_seg_loss: -0.3859 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 79/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5754 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7021 - output_seg_loss: -0.5826\n",
      "Epoch 79: val_output_seg_dice_coef improved from 0.48373 to 0.48381, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5753 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7021 - output_seg_loss: -0.5824 - val_loss: -0.3811 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4838 - val_output_seg_loss: -0.3860 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 80/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5716 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6989 - output_seg_loss: -0.5787\n",
      "Epoch 80: val_output_seg_dice_coef improved from 0.48381 to 0.48396, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5716 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6989 - output_seg_loss: -0.5787 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 81/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5710 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6975 - output_seg_loss: -0.5780\n",
      "Epoch 81: val_output_seg_dice_coef improved from 0.48396 to 0.48397, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5710 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6975 - output_seg_loss: -0.5780 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 82/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5759 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7028 - output_seg_loss: -0.5829\n",
      "Epoch 82: val_output_seg_dice_coef improved from 0.48397 to 0.48397, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5757 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7027 - output_seg_loss: -0.5827 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 83/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5830 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7079 - output_seg_loss: -0.5900\n",
      "Epoch 83: val_output_seg_dice_coef improved from 0.48397 to 0.48398, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5827 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7077 - output_seg_loss: -0.5897 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 84/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5884 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7113 - output_seg_loss: -0.5953\n",
      "Epoch 84: val_output_seg_dice_coef improved from 0.48398 to 0.48400, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5881 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7111 - output_seg_loss: -0.5950 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 85/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5713 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7019 - output_seg_loss: -0.5785\n",
      "Epoch 85: val_output_seg_dice_coef improved from 0.48400 to 0.48400, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5713 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7018 - output_seg_loss: -0.5784 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 86/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5770 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7031 - output_seg_loss: -0.5855\n",
      "Epoch 86: val_output_seg_dice_coef improved from 0.48400 to 0.48401, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5768 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7029 - output_seg_loss: -0.5853 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 87/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5834 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7097 - output_seg_loss: -0.5914\n",
      "Epoch 87: val_output_seg_dice_coef improved from 0.48401 to 0.48401, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5830 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7094 - output_seg_loss: -0.5910 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 88/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5931 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7165 - output_seg_loss: -0.6007\n",
      "Epoch 88: val_output_seg_dice_coef improved from 0.48401 to 0.48402, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5927 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7162 - output_seg_loss: -0.6002 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 89/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5794 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7041 - output_seg_loss: -0.5871\n",
      "Epoch 89: val_output_seg_dice_coef improved from 0.48402 to 0.48402, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5792 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7039 - output_seg_loss: -0.5869 - val_loss: -0.3813 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3862 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 90/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5807 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7040 - output_seg_loss: -0.5882\n",
      "Epoch 90: val_output_seg_dice_coef improved from 0.48402 to 0.48402, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5805 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7040 - output_seg_loss: -0.5880 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 91/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5734 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6962 - output_seg_loss: -0.5809\n",
      "Epoch 91: val_output_seg_dice_coef improved from 0.48402 to 0.48403, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5734 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6963 - output_seg_loss: -0.5809 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 92/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5656 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6910 - output_seg_loss: -0.5732\n",
      "Epoch 92: val_output_seg_dice_coef improved from 0.48403 to 0.48404, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5657 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6912 - output_seg_loss: -0.5733 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 93/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5706 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6982 - output_seg_loss: -0.5783\n",
      "Epoch 93: val_output_seg_dice_coef improved from 0.48404 to 0.48405, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5707 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6982 - output_seg_loss: -0.5783 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 94/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5644 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6931 - output_seg_loss: -0.5721\n",
      "Epoch 94: val_output_seg_dice_coef did not improve from 0.48405\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5646 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6933 - output_seg_loss: -0.5723 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4840 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 95/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5543 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6811 - output_seg_loss: -0.5618\n",
      "Epoch 95: val_output_seg_dice_coef improved from 0.48405 to 0.48405, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: -0.5547 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6815 - output_seg_loss: -0.5622 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 96/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: -0.5601 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6873 - output_seg_loss: -0.5676\n",
      "Epoch 96: val_output_seg_dice_coef improved from 0.48405 to 0.48406, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 226ms/step - loss: -0.5605 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6876 - output_seg_loss: -0.5679 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 97/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5506 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6844 - output_seg_loss: -0.5584\n",
      "Epoch 97: val_output_seg_dice_coef improved from 0.48406 to 0.48406, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5510 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6847 - output_seg_loss: -0.5589 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 98/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5617 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6919 - output_seg_loss: -0.5693\n",
      "Epoch 98: val_output_seg_dice_coef improved from 0.48406 to 0.48407, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5618 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6921 - output_seg_loss: -0.5695 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 99/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5683 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6960 - output_seg_loss: -0.5758\n",
      "Epoch 99: val_output_seg_dice_coef improved from 0.48407 to 0.48407, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5683 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6961 - output_seg_loss: -0.5758 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 100/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5707 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6978 - output_seg_loss: -0.5781\n",
      "Epoch 100: val_output_seg_dice_coef improved from 0.48407 to 0.48408, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5707 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6978 - output_seg_loss: -0.5782 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 101/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5650 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6972 - output_seg_loss: -0.5727\n",
      "Epoch 101: val_output_seg_dice_coef improved from 0.48408 to 0.48408, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5651 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6972 - output_seg_loss: -0.5728 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 102/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5689 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.7027 - output_seg_loss: -0.5768\n",
      "Epoch 102: val_output_seg_dice_coef improved from 0.48408 to 0.48408, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5690 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.7027 - output_seg_loss: -0.5769 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 103/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5696 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6994 - output_seg_loss: -0.5773\n",
      "Epoch 103: val_output_seg_dice_coef did not improve from 0.48408\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5697 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.6994 - output_seg_loss: -0.5773 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 104/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5647 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0075 - output_seg_dice_coef: 0.6972 - output_seg_loss: -0.5725\n",
      "Epoch 104: val_output_seg_dice_coef improved from 0.48408 to 0.48408, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: -0.5648 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6973 - output_seg_loss: -0.5727 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 105/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5607 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6958 - output_seg_loss: -0.5684\n",
      "Epoch 105: val_output_seg_dice_coef improved from 0.48408 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5609 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6958 - output_seg_loss: -0.5686 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 106/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5713 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.7047 - output_seg_loss: -0.5791\n",
      "Epoch 106: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5713 - output_dis_loss: 0.0074 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.7046 - output_seg_loss: -0.5791 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 107/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5656 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7008 - output_seg_loss: -0.5732\n",
      "Epoch 107: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5657 - output_dis_loss: 0.0073 - output_dis_mse_score: 0.0073 - output_seg_dice_coef: 0.7007 - output_seg_loss: -0.5733 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 108/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5683 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7019 - output_seg_loss: -0.5758\n",
      "Epoch 108: val_output_seg_dice_coef did not improve from 0.48409\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5683 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7018 - output_seg_loss: -0.5759 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 109/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5731 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7047 - output_seg_loss: -0.5805\n",
      "Epoch 109: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5730 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7046 - output_seg_loss: -0.5804 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 110/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5720 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7047 - output_seg_loss: -0.5795\n",
      "Epoch 110: val_output_seg_dice_coef did not improve from 0.48409\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5720 - output_dis_loss: 0.0072 - output_dis_mse_score: 0.0072 - output_seg_dice_coef: 0.7046 - output_seg_loss: -0.5795 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 111/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5742 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7042 - output_seg_loss: -0.5815\n",
      "Epoch 111: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5742 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7042 - output_seg_loss: -0.5815 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 112/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5650 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6891 - output_seg_loss: -0.5720\n",
      "Epoch 112: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5651 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6893 - output_seg_loss: -0.5721 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 113/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5729 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6958 - output_seg_loss: -0.5799\n",
      "Epoch 113: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5729 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6959 - output_seg_loss: -0.5799 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 114/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: -0.5650 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6951 - output_seg_loss: -0.5723\n",
      "Epoch 114: val_output_seg_dice_coef did not improve from 0.48409\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: -0.5651 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.6952 - output_seg_loss: -0.5725 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 115/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5702 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6957 - output_seg_loss: -0.5772\n",
      "Epoch 115: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5702 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.6958 - output_seg_loss: -0.5773 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 116/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5646 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6896 - output_seg_loss: -0.5716\n",
      "Epoch 116: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5647 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6897 - output_seg_loss: -0.5716 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 117/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5756 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7003 - output_seg_loss: -0.5828\n",
      "Epoch 117: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: -0.5755 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7003 - output_seg_loss: -0.5827 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 118/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5776 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7026 - output_seg_loss: -0.5847\n",
      "Epoch 118: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: -0.5775 - output_dis_loss: 0.0069 - output_dis_mse_score: 0.0069 - output_seg_dice_coef: 0.7025 - output_seg_loss: -0.5846 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 119/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: -0.5745 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7019 - output_seg_loss: -0.5817\n",
      "Epoch 119: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5744 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.7018 - output_seg_loss: -0.5816 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 120/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: -0.5729 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7007 - output_seg_loss: -0.5800\n",
      "Epoch 120: val_output_seg_dice_coef improved from 0.48409 to 0.48409, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: -0.5728 - output_dis_loss: 0.0071 - output_dis_mse_score: 0.0071 - output_seg_dice_coef: 0.7006 - output_seg_loss: -0.5800 - val_loss: -0.3814 - val_output_dis_loss: 0.0049 - val_output_dis_mse_score: 0.0049 - val_output_seg_dice_coef: 0.4841 - val_output_seg_loss: -0.3863 - learning_rate: 1.0000e-08\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [11:19<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold2: 0.00\n",
      "average AJI pure Unet for fold2: 0.00\n",
      "average PQ pure Unet for fold2: 0.00\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold2: 0.50\n",
      "average AJI Unet watershed for fold2: 0.22\n",
      "average PQ Unet watershed for fold2: 0.21\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "current_fold = 1\n",
    "\n",
    "import time\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "import skimage.morphology\n",
    "from skimage.io import imsave\n",
    "from skimage.morphology import remove_small_objects\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "start_time = time.time()\n",
    "for index,[train_index,  test_index] in enumerate(kf.split(img_path)):\n",
    "    \n",
    "    shuffle(train_index)\n",
    "    shuffle(test_index)\n",
    "    \n",
    "    train_img   = [img_path[name] for name in train_index]\n",
    "    train_mask  = [binary_mask_path[name] for name in train_index]\n",
    "    train_DIS   = [distance_mask_path[name] for name in train_index]\n",
    "    train_label = [label_mask_path[name] for name in train_index]\n",
    "\n",
    "    test_img   = [img_path[name] for name in test_index]\n",
    "    test_mask  = [binary_mask_path[name] for name in test_index]\n",
    "    test_DIS   = [distance_mask_path[name] for name in test_index]\n",
    "    test_label = [label_mask_path[name] for name in test_index]\n",
    "\n",
    "    ## creating validation set ##\n",
    "    \n",
    "    validation_set_img = []\n",
    "    validation_set_label = []\n",
    "    validation_DIS = []\n",
    "    # validation_set_vague = []\n",
    "    # test_masks = []\n",
    "    \n",
    "    for counter in range(len(test_img)):\n",
    "        val_img = cv2.imread(test_img[counter])\n",
    "        val_img = cv2.cvtColor(val_img, cv2.COLOR_BGR2RGB)\n",
    "        val_img = val_img.astype(np.float32) / 255.0 \n",
    "        validation_set_img.append(val_img)\n",
    "\n",
    "        \n",
    "        val_label = cv2.imread(test_label[counter], -1) # cv2.IMREAD_UNCHANGED: \n",
    "        #It specifies to load an image as such including alpha channel. \n",
    "        #Alternatively, we can pass integer value -1 for this flag.\n",
    "        # val_vague = cv2.imread(test_vague[counter], -1)\n",
    "        \n",
    "        \n",
    "        validation_set_label.append(val_label)\n",
    "        # validation_set_vague.append(val_vague)\n",
    "        \n",
    "        # val_mask = cv2.imread(test_mask[counter],-1)\n",
    "        # val_mask = val_mask.astype(np.float32) / 255.0         \n",
    "        # test_masks.append(val_mask)\n",
    "        \n",
    "        # val_DIS = cv2.imread(test_DIS[counter], -1) \n",
    "        # val_DIS = val_DIS.astype(np.float32) / 255.0\n",
    "        # validation_DIS.append(val_DIS)\n",
    "        \n",
    "    validation_set_img = np.array(validation_set_img)\n",
    "    # validation_DIS = np.array(validation_DIS)\n",
    "\n",
    "    # test_img = validation_set_img\n",
    "    # test_mask = np.array(test_masks)\n",
    "    # test_mask = np.expand_dims(test_mask, axis=-1)\n",
    "    # test_DIS = np.expand_dims(validation_DIS, axis=-1)\n",
    "    validation_set_label = np.array(validation_set_label)\n",
    "    # validation_set_vague = np.array(validation_set_vague)\n",
    "\n",
    "    \n",
    "\n",
    "    model_path = opts['model_save_path'] + 'unet_{}.weights.h5'.format(current_fold)\n",
    "    logger = CSVLogger(opts['model_save_path']+ 'unet_{}.log'.format(current_fold))\n",
    "    LR_drop = step_decay_schedule()\n",
    "    model = dual_decoder_unet_binary(opts['number_of_channel'], opts['init_LR'])\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_output_seg_dice_coef', verbose=1,\n",
    "                         save_best_only=True, mode='max', save_weights_only = True)\n",
    "    # history = model.fit(x=train_img,y={\n",
    "    #                         'output_dis': train_DIS,  # Targets for the Distance Map head\n",
    "    #                         'output_seg': train_mask    # Targets for the Segmentation Mask head\n",
    "    #                     },\n",
    "    #                     validation_data=(test_img,{\n",
    "    #                         'output_dis': test_DIS,  # Targets for the Distance Map head\n",
    "    #                         'output_seg': test_mask    # Targets for the Segmentation Mask head\n",
    "    #                     }),  \n",
    "    #                   #validation_steps=1,\n",
    "    #                   epochs=opts['epoch_num'], verbose=1,\n",
    "    #                   callbacks=[checkpoint, logger, LR_drop],\n",
    "    #                   steps_per_epoch=(len(train_img) // opts['batch_size']) // opts['quick_run'])\n",
    "\n",
    "    history = model.fit(data_gen(train_img,train_mask,train_DIS,\n",
    "                                                 opts['batch_size'],\n",
    "                                                 1,\n",
    "                                                 opts['crop_size'], opts['crop_size']),\n",
    "                        validation_data=data_gen(test_img,test_mask,test_DIS,\n",
    "                                                 opts['batch_size'],\n",
    "                                                 1,\n",
    "                                                 opts['crop_size'], opts['crop_size']),  \n",
    "                      validation_steps=1,\n",
    "                      epochs=opts['epoch_num'], verbose=1,\n",
    "                      callbacks=[checkpoint, logger, LR_drop],\n",
    "                      steps_per_epoch=(len(train_img) // opts['batch_size']) // opts['quick_run'])\n",
    "    \n",
    "    model.load_weights(opts['model_save_path'] + 'unet_{}.weights.h5'.format(current_fold))\n",
    "\n",
    "    ## FOLD RESULTS ##\n",
    "\n",
    "    pred_val = model.predict(validation_set_img, verbose=1, batch_size=1)\n",
    "\n",
    "    pred_dis = pred_val[0]\n",
    "    pred_seg = pred_val[1]\n",
    "\n",
    "    pred_val_t = (pred_seg > opts['treshold']).astype(np.uint8) # Add this later\n",
    "\n",
    "    for val_len in tqdm.tqdm(range(len(pred_dis))):\n",
    "        avg_nuclei = calculate_average_nucleus_diameter(pred_seg[val_len])\n",
    "        pred_dis[val_len] = apply_gaussian_smoothing(pred_dis[val_len],avg_nuclei)\n",
    "        \n",
    "        peak_coords = peak_local_max(np.squeeze(pred_dis[val_len]), \n",
    "                              # indices=False,\n",
    "                            exclude_border=False, footprint=np.ones((15, 15)))\n",
    "        image_shape = np.squeeze(pred_dis[val_len]).shape\n",
    "        local_maxi = np.zeros(image_shape, dtype=bool)\n",
    "        if peak_coords.size > 0:\n",
    "    # Set the pixels at the peak coordinates to True\n",
    "            local_maxi[peak_coords[:, 0], peak_coords[:, 1]] = True\n",
    "\n",
    "        \n",
    "        marker = ndi.label(local_maxi)[0]\n",
    "        output_watershed = watershed(-np.squeeze(pred_dis[val_len]), marker,mask = np.squeeze(pred_val_t[[val_len]]))\n",
    "        output_watershed[np.squeeze(pred_seg[[val_len]])==0] = 0\n",
    "        output_watershed = remove_small_objects(output_watershed, min_size=50, connectivity=2)#remove small objects\n",
    "\n",
    "        output_raw_0 = np.squeeze(pred_seg[val_len])\n",
    "        output_raw = skimage.morphology.label(output_raw_0)\n",
    "        output_raw = remove_small_objects(output_raw, min_size=50, connectivity=2) #remove small objects\n",
    "\n",
    "        output_watershed = remap_label(output_watershed)\n",
    "        validation_set_label[val_len] = remap_label(validation_set_label[val_len])\n",
    "        output_raw = remap_label(output_raw)\n",
    "        \n",
    "        test_name = get_id_from_file_path(test_img[val_len],'.png' )\n",
    "        \n",
    "        imsave(opts['result_save_path']+'validation/watershed_unet/{}.png'.format(test_name),\n",
    "               output_watershed.astype(np.uint16))\n",
    "        imsave(opts['result_save_path']+'validation/unet/{}.png'.format(test_name),output_raw.astype(np.uint16))\n",
    "\n",
    "        dice_unet[current_fold-1, val_len]= get_dice_1(validation_set_label[val_len], output_raw)\n",
    "        AJI_unet[current_fold-1, val_len] = get_fast_aji(validation_set_label[val_len], output_raw)\n",
    "        PQ_unet[current_fold-1, val_len] = get_fast_pq(validation_set_label[val_len], output_raw)[0][2]\n",
    "        \n",
    "        \n",
    "        dice_unet_watershed[current_fold-1, val_len]= get_dice_1(validation_set_label[val_len],output_watershed)\n",
    "        AJI_unet_watershed[current_fold-1, val_len] = get_fast_aji(validation_set_label[val_len], output_watershed)\n",
    "        PQ_unet_watershed[current_fold-1, val_len]  = get_fast_pq(validation_set_label[val_len], output_watershed)[0][2]\n",
    "\n",
    "    print('==========')    \n",
    "    print('average dice pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(dice_unet[current_fold-1, :]*100)))\n",
    "    print('average AJI pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(AJI_unet[current_fold-1, :]*100)))\n",
    "    print('average PQ pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(PQ_unet[current_fold-1, :]*100)))\n",
    "    dice_mean.append(np.mean(dice_unet[current_fold-1, :]*100))\n",
    "    aji_mean.append(np.mean(AJI_unet[current_fold-1, :]*100))\n",
    "    pq_mean.append(np.mean(PQ_unet[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "    \n",
    "    print('==========')    \n",
    "    print('average Dice Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                   np.mean(dice_unet_watershed[current_fold-1, :]*100)))\n",
    "    print('average AJI Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                  np.mean(AJI_unet_watershed[current_fold-1, :]*100)))\n",
    "    print('average PQ Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                 np.mean(PQ_unet_watershed[current_fold-1, :]*100)))\n",
    "    dice_watershed_mean.append(np.mean(dice_unet_watershed[current_fold-1, :]*100))\n",
    "    aji_watershed_mean.append(np.mean(AJI_unet_watershed[current_fold-1, :]*100))\n",
    "    pq_watershed_mean.append(np.mean(PQ_unet_watershed[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    current_fold += 1\n",
    "    \n",
    "finish_time = time.time() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2b7524d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T10:21:07.340366Z",
     "iopub.status.busy": "2025-10-14T10:21:07.339789Z",
     "iopub.status.idle": "2025-10-14T10:21:07.369404Z",
     "shell.execute_reply": "2025-10-14T10:21:07.368356Z"
    },
    "papermill": {
     "duration": 0.63774,
     "end_time": "2025-10-14T10:21:07.370908",
     "exception": false,
     "start_time": "2025-10-14T10:21:06.733168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fold num  dice unet  dice unet watershed\n",
      "0    fold1        0.0             0.372956\n",
      "1    fold2        0.0             0.500928\n",
      "============================================================\n",
      "  fold num  AJI unet  AJI unet watershed\n",
      "0    fold1       0.0            0.179279\n",
      "1    fold2       0.0            0.219019\n",
      "============================================================\n",
      "  fold num  PQ unet  PQ unet watershed\n",
      "0    fold1      0.0           0.180263\n",
      "1    fold2      0.0           0.210256\n",
      "============================================================\n",
      "==========\n",
      "total training time (all 5 folds): 61.17 minutes\n"
     ]
    }
   ],
   "source": [
    "# fold_names = ['fold1', 'fold2','fold3','fold4','fold5']\n",
    "fold_names = ['fold1','fold2']\n",
    "df_dice = pd.DataFrame({'fold num':fold_names, 'dice unet':dice_mean,'dice unet watershed':dice_watershed_mean})\n",
    "\n",
    "df_aji = pd.DataFrame({'fold num':fold_names, 'AJI unet':aji_mean,'AJI unet watershed':aji_watershed_mean})\n",
    "\n",
    "df_pq = pd.DataFrame({'fold num':fold_names, 'PQ unet':pq_mean,'PQ unet watershed':pq_watershed_mean})\n",
    "\n",
    "df_dice.to_csv('/kaggle/working/dice.csv', index=False)\n",
    "df_aji.to_csv('/kaggle/working/aji.csv', index=False)\n",
    "df_pq.to_csv('/kaggle/working/pq.csv', index=False)\n",
    "\n",
    "print(df_dice.head())\n",
    "print('============================================================')\n",
    "print(df_aji.head())\n",
    "print('============================================================')\n",
    "print(df_pq.head())\n",
    "print('============================================================')\n",
    "\n",
    "print('==========') \n",
    "print('total training time (all 5 folds): {:.2f} minutes'.format((finish_time- start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1997efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T10:21:08.672060Z",
     "iopub.status.busy": "2025-10-14T10:21:08.671752Z",
     "iopub.status.idle": "2025-10-14T10:21:09.027208Z",
     "shell.execute_reply": "2025-10-14T10:21:09.026241Z"
    },
    "papermill": {
     "duration": 0.94854,
     "end_time": "2025-10-14T10:21:09.028542",
     "exception": false,
     "start_time": "2025-10-14T10:21:08.080002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "# --- Configuration (Set these variables based on your environment) ---\n",
    "# NOTE: The predictions must already be saved by the previous code!\n",
    "\n",
    "# Assuming 'val_len' was the last index processed or you choose a specific index (e.g., 0)\n",
    "val_index_to_view = 0 \n",
    "test_name = get_id_from_file_path(test_img[val_index_to_view], '.png')\n",
    "\n",
    "# Assuming opts['result_save_path'] is defined as in your code\n",
    "# Replace this with the actual base path if 'opts' is not accessible\n",
    "BASE_SAVE_PATH = opts['result_save_path'] \n",
    "\n",
    "# Define paths to the saved images\n",
    "GT_LABEL = validation_set_label[val_index_to_view]\n",
    "UNET_PATH = BASE_SAVE_PATH + 'validation/unet/{}.png'.format(test_name)\n",
    "WS_PATH = BASE_SAVE_PATH + 'validation/watershed_unet/{}.png'.format(test_name)\n",
    "\n",
    "# --- Load the saved predictions ---\n",
    "try:\n",
    "    unet_pred = imread(UNET_PATH)\n",
    "    ws_pred = imread(WS_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Prediction files not found. Ensure the previous code ran and saved the files correctly.\")\n",
    "    # Fallback/Debug: You might try displaying the final in-memory variables if available\n",
    "    # print(\"Attempting to show in-memory variables...\")\n",
    "    # unet_pred = output_raw # Only works if run right after the loop\n",
    "    # ws_pred = output_watershed\n",
    "    \n",
    "    # If using in-memory variables, ensure you remap them again:\n",
    "    # unet_pred = remap_label(unet_pred)\n",
    "    # ws_pred = remap_label(ws_pred)\n",
    "    # GT_LABEL = remap_label(validation_set_label[val_index_to_view])\n",
    "    \n",
    "    \n",
    "# --- Visualization ---\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "titles = [\"Ground Truth Label\", \"Pure U-Net Output\", \"U-Net + Watershed Output\"]\n",
    "images = [GT_LABEL, unet_pred, ws_pred]\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    # Use 'viridis' colormap for labeled images to distinguish instances\n",
    "    ax.imshow(img, cmap='nipy_spectral', interpolation='none')\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Predictions for Image: {test_name}\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0affa72",
   "metadata": {
    "papermill": {
     "duration": 0.704241,
     "end_time": "2025-10-14T10:21:10.329096",
     "exception": false,
     "start_time": "2025-10-14T10:21:09.624855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1911713,
     "sourceId": 5909621,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3702.58152,
   "end_time": "2025-10-14T10:21:14.819908",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-14T09:19:32.238388",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
