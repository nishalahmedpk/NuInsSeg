{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bf32e7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:50.958286Z",
     "iopub.status.busy": "2025-10-09T06:26:50.957489Z",
     "iopub.status.idle": "2025-10-09T06:26:50.960935Z",
     "shell.execute_reply": "2025-10-09T06:26:50.961490Z",
     "shell.execute_reply.started": "2025-10-09T06:23:55.455010Z"
    },
    "papermill": {
     "duration": 0.025339,
     "end_time": "2025-10-09T06:26:50.961736",
     "exception": false,
     "start_time": "2025-10-09T06:26:50.936397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set all hyper parameters\n",
    "opts = {}\n",
    "opts['number_of_channel'] = 3                   \n",
    "opts['treshold'] = 0.5                          \n",
    "opts['epoch_num'] = 100                   \n",
    "opts['quick_run'] = 1   \n",
    "opts['batch_size'] = 16                          \n",
    "opts['random_seed_num'] = 19   \n",
    "opts['k_fold'] = 5                             \n",
    "opts['save_val_results'] = 1         \n",
    "opts['init_LR'] = 0.001                         \n",
    "opts['LR_decay_factor'] = 0.5                   \n",
    "opts['LR_drop_after_nth_epoch'] = 20            \n",
    "opts['crop_size'] = 512   \n",
    "## output directories\n",
    "opts['result_save_path'] ='/kaggle/working/prediction_image/'\n",
    "opts['model_save_path'] ='/kaggle/working/output_model/'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46f983e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:50.987043Z",
     "iopub.status.busy": "2025-10-09T06:26:50.986535Z",
     "iopub.status.idle": "2025-10-09T06:26:57.484453Z",
     "shell.execute_reply": "2025-10-09T06:26:57.483975Z",
     "shell.execute_reply.started": "2025-10-09T06:23:56.553094Z"
    },
    "papermill": {
     "duration": 6.512234,
     "end_time": "2025-10-09T06:26:57.484570",
     "exception": false,
     "start_time": "2025-10-09T06:26:50.972336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libs\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import time  \n",
    "import cv2\n",
    "import keras\n",
    "from keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import adam_v2\n",
    "from albumentations import *\n",
    "from keras import backend as K\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "import skimage.morphology\n",
    "from skimage.io import imsave\n",
    "from skimage.morphology import remove_small_objects\n",
    "import tqdm\n",
    "from random import shuffle \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fad23c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:57.508055Z",
     "iopub.status.busy": "2025-10-09T06:26:57.507571Z",
     "iopub.status.idle": "2025-10-09T06:26:57.510110Z",
     "shell.execute_reply": "2025-10-09T06:26:57.510462Z",
     "shell.execute_reply.started": "2025-10-08T16:53:09.589332Z"
    },
    "papermill": {
     "duration": 0.016142,
     "end_time": "2025-10-09T06:26:57.510580",
     "exception": false,
     "start_time": "2025-10-09T06:26:57.494438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## disabeling warning msg\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import sys\n",
    "sys.stdout.flush() # resolving tqdm problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bdddac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:57.533222Z",
     "iopub.status.busy": "2025-10-09T06:26:57.532707Z",
     "iopub.status.idle": "2025-10-09T06:26:57.555982Z",
     "shell.execute_reply": "2025-10-09T06:26:57.555497Z",
     "shell.execute_reply.started": "2025-10-09T06:24:34.391435Z"
    },
    "papermill": {
     "duration": 0.036003,
     "end_time": "2025-10-09T06:26:57.556107",
     "exception": false,
     "start_time": "2025-10-09T06:26:57.520104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mouse muscle_tibia',\n",
       " 'mouse liver',\n",
       " 'human liver',\n",
       " 'human umbilical cord',\n",
       " 'mouse thymus',\n",
       " 'human lung',\n",
       " 'human epiglottis',\n",
       " 'human spleen',\n",
       " 'mouse fat (white and brown)_subscapula',\n",
       " 'human cardia',\n",
       " 'human salivory gland',\n",
       " 'human melanoma',\n",
       " 'human kidney',\n",
       " 'human pylorus',\n",
       " 'human jejunum',\n",
       " 'human testis',\n",
       " 'mouse spleen',\n",
       " 'human tongue',\n",
       " 'human cerebellum',\n",
       " 'human oesophagus',\n",
       " 'mouse heart',\n",
       " 'human pancreas',\n",
       " 'human brain',\n",
       " 'human muscle',\n",
       " 'human placenta',\n",
       " 'human bladder',\n",
       " 'mouse kidney',\n",
       " 'human tonsile',\n",
       " 'human rectum',\n",
       " 'mouse femur',\n",
       " 'human peritoneum']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../input/nuinsseg/'\n",
    "organ_names = [ name for name in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, name)) ]\n",
    "organ_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9717b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:57.582072Z",
     "iopub.status.busy": "2025-10-09T06:26:57.581510Z",
     "iopub.status.idle": "2025-10-09T06:26:58.419487Z",
     "shell.execute_reply": "2025-10-09T06:26:58.418972Z",
     "shell.execute_reply.started": "2025-10-09T06:24:35.359699Z"
    },
    "papermill": {
     "duration": 0.853367,
     "end_time": "2025-10-09T06:26:58.419625",
     "exception": false,
     "start_time": "2025-10-09T06:26:57.566258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input and outpu paths\n",
    "img_path = glob('{}*{}'.format('../input/nuinsseg/*/tissue images/', 'png'))\n",
    "binary_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/mask binary/', 'png'))\n",
    "distance_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/distance maps/', 'png'))\n",
    "label_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/label masks modify/', 'tif'))\n",
    "vague_mask_path =  glob('{}*{}'.format('../input/nuinsseg/*/vague areas/mask binary/', 'png'))\n",
    "\n",
    "\n",
    "img_path.sort()\n",
    "binary_mask_path.sort()\n",
    "distance_mask_path.sort()\n",
    "label_mask_path.sort()\n",
    "vague_mask_path.sort()\n",
    "\n",
    "\n",
    "# create folders to save the best models and images (if needed) for each fold\n",
    "if not os.path.exists('/kaggle/working/prediction_image/'):\n",
    "    os.makedirs('/kaggle/working/prediction_image/')\n",
    "if not os.path.exists('/kaggle/working/output_model/'):\n",
    "    os.makedirs('/kaggle/working/output_model/')    \n",
    "if not os.path.exists(opts['result_save_path']+ 'validation/unet'):\n",
    "    os.makedirs(opts['result_save_path'] + 'validation/unet')\n",
    "if not os.path.exists(opts['result_save_path']+ 'validation/watershed_unet'):\n",
    "    os.makedirs(opts['result_save_path'] + 'validation/watershed_unet')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2688cc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.444883Z",
     "iopub.status.busy": "2025-10-09T06:26:58.444050Z",
     "iopub.status.idle": "2025-10-09T06:26:58.447243Z",
     "shell.execute_reply": "2025-10-09T06:26:58.447625Z",
     "shell.execute_reply.started": "2025-10-09T06:24:41.176543Z"
    },
    "papermill": {
     "duration": 0.017738,
     "end_time": "2025-10-09T06:26:58.447741",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.430003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image path: ../input/nuinsseg/human placenta/tissue images/human_placenta_40.png\n",
      " binary mask path: ../input/nuinsseg/human placenta/mask binary/human_placenta_40.png\n",
      " distance mask path: ../input/nuinsseg/human placenta/distance maps/human_placenta_40.png\n",
      " label mask path: ../input/nuinsseg/human placenta/label masks modify/human_placenta_40.tif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random check\n",
    "rand_num = np.random.randint(len(img_path))\n",
    "print('image path: {}\\n'.format(img_path[rand_num]),\n",
    "      'binary mask path: {}\\n'.format(binary_mask_path[rand_num]),\n",
    "      'distance mask path: {}\\n'.format(distance_mask_path[rand_num]),\n",
    "      'label mask path: {}\\n'.format(label_mask_path[rand_num]))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d664993d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.472174Z",
     "iopub.status.busy": "2025-10-09T06:26:58.471682Z",
     "iopub.status.idle": "2025-10-09T06:26:58.473953Z",
     "shell.execute_reply": "2025-10-09T06:26:58.473591Z",
     "shell.execute_reply.started": "2025-10-09T06:24:42.173048Z"
    },
    "papermill": {
     "duration": 0.01648,
     "end_time": "2025-10-09T06:26:58.474051",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.457571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define loss function\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "#####################################################################################\n",
    "# Combination of Dice and binary cross entophy loss function that is used in this baseline segmentation\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ee212c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.498421Z",
     "iopub.status.busy": "2025-10-09T06:26:58.497915Z",
     "iopub.status.idle": "2025-10-09T06:26:58.499766Z",
     "shell.execute_reply": "2025-10-09T06:26:58.500219Z",
     "shell.execute_reply.started": "2025-10-09T06:24:43.769783Z"
    },
    "papermill": {
     "duration": 0.016236,
     "end_time": "2025-10-09T06:26:58.500349",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.484113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# learning rate scheduler\n",
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, epochs_drop=1000):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/epochs_drop))\n",
    "    \n",
    "    return LearningRateScheduler(schedule, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f8790d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.548638Z",
     "iopub.status.busy": "2025-10-09T06:26:58.533027Z",
     "iopub.status.idle": "2025-10-09T06:26:58.550997Z",
     "shell.execute_reply": "2025-10-09T06:26:58.550637Z",
     "shell.execute_reply.started": "2025-10-09T06:24:45.450562Z"
    },
    "papermill": {
     "duration": 0.040688,
     "end_time": "2025-10-09T06:26:58.551095",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.510407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# U-net models\n",
    "#############################################################################################################\n",
    "def shallow_unet( IMG_CHANNELS, LearnRate):\n",
    "    inputs = Input((None, None, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255) (inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p2)\n",
    "    c3 = Dropout(0.1) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p3)\n",
    "    c4 = Dropout(0.1) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p4)\n",
    "    c5 = Dropout(0.1) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u6)\n",
    "    c6 = Dropout(0.1) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u7)\n",
    "    c7 = Dropout(0.1) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9) # for binary\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer = adam_v2.Adam(learning_rate= LearnRate), loss= bce_dice_loss , metrics=[dice_coef]) \n",
    "    #model.summary()\n",
    "    return model\n",
    "#############################################################################################################\n",
    "def deep_unet(IMG_CHANNELS, LearnRate):\n",
    "    # Build U-Net model\n",
    "    inputs = Input((None, None, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255) (inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.1) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.1) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    \n",
    "    \n",
    "    c4_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c4_new = Dropout(0.1) (c4_new)\n",
    "    c4_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4_new)\n",
    "    p4_new = MaxPooling2D(pool_size=(2, 2)) (c4_new)\n",
    "\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4_new)\n",
    "    c5 = Dropout(0.1) (c5)\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "    \n",
    "    \n",
    "    u6_new = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6_new = concatenate([u6_new, c4_new])\n",
    "    c6_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6_new)\n",
    "    c6_new = Dropout(0.1) (c6_new)\n",
    "    c6_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6_new)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c6_new)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.1) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.1) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model_deep = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model_deep.compile(optimizer = adam_v2.Adam(learning_rate=LearnRate), loss= bce_dice_loss , metrics=[ dice_coef])\n",
    "    #model_deeper.summary()\n",
    "    return model_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89d73d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.577233Z",
     "iopub.status.busy": "2025-10-09T06:26:58.576728Z",
     "iopub.status.idle": "2025-10-09T06:26:58.578892Z",
     "shell.execute_reply": "2025-10-09T06:26:58.579280Z",
     "shell.execute_reply.started": "2025-10-09T06:24:48.274543Z"
    },
    "papermill": {
     "duration": 0.017876,
     "end_time": "2025-10-09T06:26:58.579397",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.561521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmentation function\n",
    "def albumentation_aug(p=1.0, crop_size_row = 448, crop_size_col = 448 ):\n",
    "    return Compose([\n",
    "        RandomCrop(crop_size_row, crop_size_col, always_apply=True, p=1),\n",
    "        CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, brightness_by_max=True, p=0.4),\n",
    "        HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.1),\n",
    "        HorizontalFlip(always_apply=False, p=0.5),\n",
    "        VerticalFlip(always_apply=False, p=0.5),\n",
    "        RandomRotate90(always_apply=False, p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=20, interpolation=1, \n",
    "                         border_mode=4, always_apply=False, p=0.1),\n",
    "\n",
    "    ], p=p)\n",
    "# last  p has the second proiroty comapred to the p inside each argument \n",
    "#(e.g. HorizontalFlip(always_apply=False, p=0.5) )\n",
    "#############################################################################################################\n",
    "# def albumentation_aug_light(p=1.0, crop_size_row = 448, crop_size_col = 448):\n",
    "#     return Compose([\n",
    "#         RandomCrop(crop_size_row, crop_size_col, always_apply=True, p=1.0),\n",
    "#         HorizontalFlip(always_apply=False, p=0.5),\n",
    "#         VerticalFlip(always_apply=False, p=0.5),\n",
    "#         RandomRotate90(always_apply=False, p=0.5),\n",
    "#         ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=20, interpolation=1, \n",
    "#                          border_mode=4 , always_apply=False, p=0.1),\n",
    "#     ], p=p, additional_targets={'mask1': 'mask','mask2': 'mask'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e1afa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.626629Z",
     "iopub.status.busy": "2025-10-09T06:26:58.616990Z",
     "iopub.status.idle": "2025-10-09T06:26:58.628265Z",
     "shell.execute_reply": "2025-10-09T06:26:58.628602Z",
     "shell.execute_reply.started": "2025-10-09T06:24:49.813556Z"
    },
    "papermill": {
     "duration": 0.039149,
     "end_time": "2025-10-09T06:26:58.628726",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.589577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluation index (from: https://github.com/vqdang/hover_net/blob/master/src/metrics/stats_utils.py)\n",
    "#############################################################################################################\n",
    "\n",
    "def get_fast_aji(true, pred):\n",
    "    \"\"\"AJI version distributed by MoNuSeg, has no permutation problem but suffered from \n",
    "    over-penalisation similar to DICE2.\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4] \n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no \n",
    "    effect on the result.\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "    #print(len(pred_id_list))\n",
    "    if len(pred_id_list) == 1:\n",
    "        return 0\n",
    "\n",
    "    true_masks = [None,]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [None,]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    # pair of pred that give highest iou for each true, dont care\n",
    "    # about reusing pred instance multiple times\n",
    "    paired_pred = np.argmax(pairwise_iou, axis=1)\n",
    "    pairwise_iou = np.max(pairwise_iou, axis=1)\n",
    "    # exlude those dont have intersection\n",
    "    paired_true = np.nonzero(pairwise_iou > 0.0)[0]\n",
    "    paired_pred = paired_pred[paired_true]\n",
    "    # print(paired_true.shape, paired_pred.shape)\n",
    "    overall_inter = (pairwise_inter[paired_true, paired_pred]).sum()\n",
    "    overall_union = (pairwise_union[paired_true, paired_pred]).sum()\n",
    "\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "\n",
    "    aji_score = overall_inter / overall_union\n",
    "    #print(aji_score)\n",
    "    return aji_score\n",
    "\n",
    "#############################################################################################################\n",
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
    "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
    "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique \n",
    "    (1 prediction instance to 1 GT instance mapping).\n",
    "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
    "    in bipartite graphs) is caculated to find the maximal amount of unique pairing. \n",
    "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
    "    the number of pairs is also maximal.    \n",
    "    \n",
    "    Fast computation requires instance IDs are in contiguous orderding \n",
    "    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand \n",
    "    and `by_size` flag has no effect on the result.\n",
    "    Returns:\n",
    "        [dq, sq, pq]: measurement statistic\n",
    "        [paired_true, paired_pred, unpaired_true, unpaired_pred]: \n",
    "                      pairing information to perform measurement\n",
    "                    \n",
    "    \"\"\"\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "    \n",
    "    if len(pred_id_list) == 1:\n",
    "        return [0, 0, 0], [0,0, 0, 0]\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1  # index is instance id - 1\n",
    "        paired_pred += 1  # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence\n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum\n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "def get_dice_1(true, pred):\n",
    "    \"\"\"Traditional dice.\"\"\"\n",
    "    # cast to binary 1st\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true[true > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "    inter = true * pred\n",
    "    denom = true + pred\n",
    "    dice_score = 2.0 * np.sum(inter) / (np.sum(denom) + 0.0001)\n",
    "    if np.sum(inter)==0 and np.sum(denom)==0:\n",
    "        dice_score = 1 # to handel cases without any nuclei\n",
    "    #print(dice_score)\n",
    "    return dice_score\n",
    "#############################################################################################################\n",
    "def remap_label(pred, by_size=False):\n",
    "    \"\"\"Rename all instance id so that the id is contiguous i.e [0, 1, 2, 3] \n",
    "    not [0, 2, 4, 6]. The ordering of instances (which one comes first) \n",
    "    is preserved unless by_size=True, then the instances will be reordered\n",
    "    so that bigger nucler has smaller ID.\n",
    "    Args:\n",
    "        pred    : the 2d array contain instances where each instances is marked\n",
    "                  by non-zero integer\n",
    "        by_size : renaming with larger nuclei has smaller id (on-top)\n",
    "    \"\"\"\n",
    "    pred_id = list(np.unique(pred))\n",
    "    pred_id.remove(0)\n",
    "    if len(pred_id) == 0:\n",
    "        return pred  # no label\n",
    "    if by_size:\n",
    "        pred_size = []\n",
    "        for inst_id in pred_id:\n",
    "            size = (pred == inst_id).sum()\n",
    "            pred_size.append(size)\n",
    "        # sort the id by size in descending order\n",
    "        pair_list = zip(pred_id, pred_size)\n",
    "        pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
    "        pred_id, pred_size = zip(*pair_list)\n",
    "\n",
    "    new_pred = np.zeros(pred.shape, np.int32)\n",
    "    for idx, inst_id in enumerate(pred_id):\n",
    "        new_pred[pred == inst_id] = idx + 1\n",
    "    return new_pred\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "def pair_coordinates(setA, setB, radius):\n",
    "    \"\"\"Use the Munkres or Kuhn-Munkres algorithm to find the most optimal \n",
    "    unique pairing (largest possible match) when pairing points in set B \n",
    "    against points in set A, using distance as cost function.\n",
    "    Args:\n",
    "        setA, setB: np.array (float32) of size Nx2 contains the of XY coordinate\n",
    "                    of N different points \n",
    "        radius: valid area around a point in setA to consider \n",
    "                a given coordinate in setB a candidate for match\n",
    "    Return:\n",
    "        pairing: pairing is an array of indices\n",
    "        where point at index pairing[0] in set A paired with point\n",
    "        in set B at index pairing[1]\n",
    "        unparedA, unpairedB: remaining poitn in set A and set B unpaired\n",
    "    \"\"\"\n",
    "    # * Euclidean distance as the cost matrix\n",
    "    pair_distance = scipy.spatial.distance.cdist(setA, setB, metric='euclidean')\n",
    "\n",
    "    # * Munkres pairing with scipy library\n",
    "    # the algorithm return (row indices, matched column indices)\n",
    "    # if there is multiple same cost in a row, index of first occurence \n",
    "    # is return, thus the unique pairing is ensured\n",
    "    indicesA, paired_indicesB = linear_sum_assignment(pair_distance)\n",
    "\n",
    "    # extract the paired cost and remove instances \n",
    "    # outside of designated radius\n",
    "    pair_cost = pair_distance[indicesA, paired_indicesB]\n",
    "\n",
    "    pairedA = indicesA[pair_cost <= radius]\n",
    "    pairedB = paired_indicesB[pair_cost <= radius]\n",
    "\n",
    "    pairing = np.concatenate([pairedA[:,None], pairedB[:,None]], axis=-1)\n",
    "    unpairedA = np.delete(np.arange(setA.shape[0]), pairedA)\n",
    "    unpairedB = np.delete(np.arange(setB.shape[0]), pairedB)\n",
    "    return pairing, unpairedA, unpairedB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76ccfdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.658593Z",
     "iopub.status.busy": "2025-10-09T06:26:58.655479Z",
     "iopub.status.idle": "2025-10-09T06:26:58.660721Z",
     "shell.execute_reply": "2025-10-09T06:26:58.661052Z",
     "shell.execute_reply.started": "2025-10-09T06:24:57.044383Z"
    },
    "papermill": {
     "duration": 0.022455,
     "end_time": "2025-10-09T06:26:58.661201",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.638746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data generator related functions\n",
    "def get_id_from_file_path(file_path, indicator):\n",
    "    return file_path.split(os.path.sep)[-1].replace(indicator, '')\n",
    "#############################################################################################################\n",
    "def chunker(seq, seq2, size):\n",
    "    return ([seq[pos:pos + size], seq2[pos:pos + size]] for pos in range(0, len(seq), size))\n",
    "#############################################################################################################\n",
    "def data_gen(list_files, list_files2, batch_size, p , size_row, size_col, distance_unet_flag = 0,\n",
    "             augment= False, BACKBONE_model = None, use_pretrain_flag = 1):\n",
    "    crop_size_row = size_row\n",
    "    crop_size_col = size_col\n",
    "    aug = albumentation_aug(p, crop_size_row, crop_size_col)\n",
    "\n",
    "    while True:\n",
    "        for batch in chunker(list_files,list_files2, batch_size):\n",
    "            X = []\n",
    "            Y = []\n",
    "\n",
    "            for count in range(len(batch[0])):\n",
    "                x = cv2.imread(batch[0][count])\n",
    "                x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "                x_mask = cv2.imread(batch[1][count], cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                x_mask_temp = np.zeros((x_mask.shape[0], x_mask.shape[1]))\n",
    "                x_mask_temp[x_mask == 255] = 1\n",
    "                \n",
    "\n",
    "                if distance_unet_flag == False:\n",
    "                    if augment:\n",
    "                        augmented = aug(image= x, mask= x_mask_temp)\n",
    "                        x = augmented['image']\n",
    "                        if use_pretrain_flag == 1:\n",
    "                            x = preprocess_input(x)\n",
    "                        x_mask_temp = augmented['mask']\n",
    "                        x = x/255\n",
    "                    else:\n",
    "                        x = x/255    \n",
    "                    X.append(x)\n",
    "                    Y.append(x_mask_temp)\n",
    "                else:\n",
    "                    if augment:\n",
    "                        augmented = aug(image=x, mask=x_mask)\n",
    "                        x = augmented['image']\n",
    "                        if use_pretrain_flag == 1:\n",
    "                            x = preprocess_input(x)\n",
    "                        x_mask = augmented['mask']\n",
    "                        x = x/255\n",
    "                    else:\n",
    "                        x = x/255  \n",
    "                        \n",
    "                    X.append(x)\n",
    "                    x_mask = (x_mask - np.min(x_mask))/ (np.max(x_mask) - np.min(x_mask) + 0.0000001)\n",
    "                    Y.append(x_mask)\n",
    "\n",
    "                del x_mask\n",
    "                del x_mask_temp\n",
    "                del x\n",
    "            Y = np.expand_dims(np.array(Y), axis=3)\n",
    "            Y = np.array(Y)\n",
    "            yield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2ab04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:26:58.715934Z",
     "iopub.status.busy": "2025-10-09T06:26:58.714795Z",
     "iopub.status.idle": "2025-10-09T08:45:27.809875Z",
     "shell.execute_reply": "2025-10-09T08:45:27.802769Z"
    },
    "papermill": {
     "duration": 8309.138913,
     "end_time": "2025-10-09T08:45:27.810011",
     "exception": false,
     "start_time": "2025-10-09T06:26:58.671098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 30s 591ms/step - loss: -0.0345 - dice_coef: 0.2399 - val_loss: -0.0821 - val_dice_coef: 0.2734\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.27339, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 464ms/step - loss: -0.1213 - dice_coef: 0.3300 - val_loss: -0.2458 - val_dice_coef: 0.4119\n",
      "\n",
      "Epoch 00002: val_dice_coef improved from 0.27339 to 0.41192, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.2037 - dice_coef: 0.3979 - val_loss: -0.2836 - val_dice_coef: 0.4806\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.41192 to 0.48062, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.2532 - dice_coef: 0.4508 - val_loss: -0.3403 - val_dice_coef: 0.5117\n",
      "\n",
      "Epoch 00004: val_dice_coef improved from 0.48062 to 0.51169, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.2411 - dice_coef: 0.4349 - val_loss: -0.3886 - val_dice_coef: 0.5533\n",
      "\n",
      "Epoch 00005: val_dice_coef improved from 0.51169 to 0.55328, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.2670 - dice_coef: 0.4493 - val_loss: -0.2312 - val_dice_coef: 0.4310\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve from 0.55328\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.3212 - dice_coef: 0.5045 - val_loss: -0.1923 - val_dice_coef: 0.4079\n",
      "\n",
      "Epoch 00007: val_dice_coef did not improve from 0.55328\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.3569 - dice_coef: 0.5363 - val_loss: -0.3184 - val_dice_coef: 0.4807\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve from 0.55328\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 449ms/step - loss: -0.3462 - dice_coef: 0.5323 - val_loss: -0.3022 - val_dice_coef: 0.4782\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve from 0.55328\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.3713 - dice_coef: 0.5495 - val_loss: -0.3684 - val_dice_coef: 0.5177\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve from 0.55328\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.4458 - dice_coef: 0.6014 - val_loss: -0.4818 - val_dice_coef: 0.6291\n",
      "\n",
      "Epoch 00011: val_dice_coef improved from 0.55328 to 0.62907, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.4961 - dice_coef: 0.6414 - val_loss: -0.5709 - val_dice_coef: 0.7090\n",
      "\n",
      "Epoch 00012: val_dice_coef improved from 0.62907 to 0.70902, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.5018 - dice_coef: 0.6431 - val_loss: -0.5844 - val_dice_coef: 0.7172\n",
      "\n",
      "Epoch 00013: val_dice_coef improved from 0.70902 to 0.71719, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 451ms/step - loss: -0.5061 - dice_coef: 0.6514 - val_loss: -0.6068 - val_dice_coef: 0.7142\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve from 0.71719\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.5542 - dice_coef: 0.6845 - val_loss: -0.3960 - val_dice_coef: 0.5589\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve from 0.71719\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 19s 585ms/step - loss: -0.5568 - dice_coef: 0.6879 - val_loss: -0.6304 - val_dice_coef: 0.7266\n",
      "\n",
      "Epoch 00016: val_dice_coef improved from 0.71719 to 0.72662, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.5696 - dice_coef: 0.6951 - val_loss: -0.5079 - val_dice_coef: 0.6517\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve from 0.72662\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 488ms/step - loss: -0.5620 - dice_coef: 0.6899 - val_loss: -0.5911 - val_dice_coef: 0.7091\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve from 0.72662\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 538ms/step - loss: -0.5939 - dice_coef: 0.7111 - val_loss: -0.5570 - val_dice_coef: 0.6932\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve from 0.72662\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.5850 - dice_coef: 0.7078 - val_loss: -0.6170 - val_dice_coef: 0.7354\n",
      "\n",
      "Epoch 00020: val_dice_coef improved from 0.72662 to 0.73539, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.6068 - dice_coef: 0.7218 - val_loss: -0.6604 - val_dice_coef: 0.7698\n",
      "\n",
      "Epoch 00021: val_dice_coef improved from 0.73539 to 0.76978, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 483ms/step - loss: -0.6311 - dice_coef: 0.7395 - val_loss: -0.6994 - val_dice_coef: 0.8009\n",
      "\n",
      "Epoch 00022: val_dice_coef improved from 0.76978 to 0.80092, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.6437 - dice_coef: 0.7477 - val_loss: -0.6872 - val_dice_coef: 0.7827\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve from 0.80092\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.6428 - dice_coef: 0.7500 - val_loss: -0.6342 - val_dice_coef: 0.7347\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve from 0.80092\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.6547 - dice_coef: 0.7558 - val_loss: -0.7128 - val_dice_coef: 0.7972\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve from 0.80092\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.6594 - dice_coef: 0.7602 - val_loss: -0.6124 - val_dice_coef: 0.7359\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve from 0.80092\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 461ms/step - loss: -0.6650 - dice_coef: 0.7648 - val_loss: -0.6710 - val_dice_coef: 0.7680\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve from 0.80092\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.6509 - dice_coef: 0.7535 - val_loss: -0.6140 - val_dice_coef: 0.7309\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve from 0.80092\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.6731 - dice_coef: 0.7696 - val_loss: -0.6466 - val_dice_coef: 0.7593\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve from 0.80092\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.6746 - dice_coef: 0.7709 - val_loss: -0.6915 - val_dice_coef: 0.7939\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve from 0.80092\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.6766 - dice_coef: 0.7730 - val_loss: -0.7370 - val_dice_coef: 0.8291\n",
      "\n",
      "Epoch 00031: val_dice_coef improved from 0.80092 to 0.82906, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 451ms/step - loss: -0.6891 - dice_coef: 0.7817 - val_loss: -0.7101 - val_dice_coef: 0.7996\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve from 0.82906\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.6923 - dice_coef: 0.7825 - val_loss: -0.6949 - val_dice_coef: 0.7809\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve from 0.82906\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.6820 - dice_coef: 0.7758 - val_loss: -0.7312 - val_dice_coef: 0.8082\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve from 0.82906\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.6903 - dice_coef: 0.7817 - val_loss: -0.6707 - val_dice_coef: 0.7745\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve from 0.82906\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.6944 - dice_coef: 0.7852 - val_loss: -0.6581 - val_dice_coef: 0.7676\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve from 0.82906\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 461ms/step - loss: -0.6945 - dice_coef: 0.7852 - val_loss: -0.6616 - val_dice_coef: 0.7687\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve from 0.82906\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7021 - dice_coef: 0.7898 - val_loss: -0.6685 - val_dice_coef: 0.7803\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve from 0.82906\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 17s 516ms/step - loss: -0.7017 - dice_coef: 0.7898 - val_loss: -0.7002 - val_dice_coef: 0.8025\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve from 0.82906\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 499ms/step - loss: -0.6962 - dice_coef: 0.7861 - val_loss: -0.7311 - val_dice_coef: 0.8269\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve from 0.82906\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 515ms/step - loss: -0.7056 - dice_coef: 0.7915 - val_loss: -0.7332 - val_dice_coef: 0.8132\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve from 0.82906\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.7106 - dice_coef: 0.7948 - val_loss: -0.7027 - val_dice_coef: 0.7904\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve from 0.82906\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.7133 - dice_coef: 0.7986 - val_loss: -0.7434 - val_dice_coef: 0.8189\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve from 0.82906\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 470ms/step - loss: -0.7158 - dice_coef: 0.8002 - val_loss: -0.6943 - val_dice_coef: 0.7918\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve from 0.82906\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 506ms/step - loss: -0.7143 - dice_coef: 0.7983 - val_loss: -0.6957 - val_dice_coef: 0.7901\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve from 0.82906\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 530ms/step - loss: -0.7110 - dice_coef: 0.7961 - val_loss: -0.6547 - val_dice_coef: 0.7656\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve from 0.82906\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 531ms/step - loss: -0.7137 - dice_coef: 0.7976 - val_loss: -0.6811 - val_dice_coef: 0.7838\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve from 0.82906\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 510ms/step - loss: -0.7160 - dice_coef: 0.7999 - val_loss: -0.7183 - val_dice_coef: 0.8119\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve from 0.82906\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 476ms/step - loss: -0.7192 - dice_coef: 0.8018 - val_loss: -0.7584 - val_dice_coef: 0.8433\n",
      "\n",
      "Epoch 00049: val_dice_coef improved from 0.82906 to 0.84326, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 477ms/step - loss: -0.7162 - dice_coef: 0.7996 - val_loss: -0.7311 - val_dice_coef: 0.8146\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve from 0.84326\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 484ms/step - loss: -0.7173 - dice_coef: 0.8005 - val_loss: -0.6992 - val_dice_coef: 0.7869\n",
      "\n",
      "Epoch 00051: val_dice_coef did not improve from 0.84326\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 484ms/step - loss: -0.7159 - dice_coef: 0.7995 - val_loss: -0.7418 - val_dice_coef: 0.8190\n",
      "\n",
      "Epoch 00052: val_dice_coef did not improve from 0.84326\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 476ms/step - loss: -0.7243 - dice_coef: 0.8042 - val_loss: -0.7036 - val_dice_coef: 0.7997\n",
      "\n",
      "Epoch 00053: val_dice_coef did not improve from 0.84326\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 478ms/step - loss: -0.7199 - dice_coef: 0.8023 - val_loss: -0.7222 - val_dice_coef: 0.8068\n",
      "\n",
      "Epoch 00054: val_dice_coef did not improve from 0.84326\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 477ms/step - loss: -0.7233 - dice_coef: 0.8046 - val_loss: -0.6785 - val_dice_coef: 0.7838\n",
      "\n",
      "Epoch 00055: val_dice_coef did not improve from 0.84326\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 484ms/step - loss: -0.7240 - dice_coef: 0.8059 - val_loss: -0.6852 - val_dice_coef: 0.7934\n",
      "\n",
      "Epoch 00056: val_dice_coef did not improve from 0.84326\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 485ms/step - loss: -0.7250 - dice_coef: 0.8054 - val_loss: -0.7247 - val_dice_coef: 0.8184\n",
      "\n",
      "Epoch 00057: val_dice_coef did not improve from 0.84326\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 490ms/step - loss: -0.7265 - dice_coef: 0.8075 - val_loss: -0.7673 - val_dice_coef: 0.8494\n",
      "\n",
      "Epoch 00058: val_dice_coef improved from 0.84326 to 0.84938, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 484ms/step - loss: -0.7252 - dice_coef: 0.8064 - val_loss: -0.7325 - val_dice_coef: 0.8133\n",
      "\n",
      "Epoch 00059: val_dice_coef did not improve from 0.84938\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 485ms/step - loss: -0.7219 - dice_coef: 0.8046 - val_loss: -0.6962 - val_dice_coef: 0.7872\n",
      "\n",
      "Epoch 00060: val_dice_coef did not improve from 0.84938\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.7280 - dice_coef: 0.8085 - val_loss: -0.7517 - val_dice_coef: 0.8273\n",
      "\n",
      "Epoch 00061: val_dice_coef did not improve from 0.84938\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 18s 541ms/step - loss: -0.7308 - dice_coef: 0.8097 - val_loss: -0.7136 - val_dice_coef: 0.8083\n",
      "\n",
      "Epoch 00062: val_dice_coef did not improve from 0.84938\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.7318 - dice_coef: 0.8098 - val_loss: -0.6961 - val_dice_coef: 0.7945\n",
      "\n",
      "Epoch 00063: val_dice_coef did not improve from 0.84938\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 481ms/step - loss: -0.7315 - dice_coef: 0.8104 - val_loss: -0.6859 - val_dice_coef: 0.7908\n",
      "\n",
      "Epoch 00064: val_dice_coef did not improve from 0.84938\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 476ms/step - loss: -0.7318 - dice_coef: 0.8106 - val_loss: -0.6938 - val_dice_coef: 0.7988\n",
      "\n",
      "Epoch 00065: val_dice_coef did not improve from 0.84938\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 521ms/step - loss: -0.7335 - dice_coef: 0.8122 - val_loss: -0.7215 - val_dice_coef: 0.8191\n",
      "\n",
      "Epoch 00066: val_dice_coef did not improve from 0.84938\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 490ms/step - loss: -0.7330 - dice_coef: 0.8106 - val_loss: -0.7703 - val_dice_coef: 0.8529\n",
      "\n",
      "Epoch 00067: val_dice_coef improved from 0.84938 to 0.85294, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.7306 - dice_coef: 0.8102 - val_loss: -0.7380 - val_dice_coef: 0.8203\n",
      "\n",
      "Epoch 00068: val_dice_coef did not improve from 0.85294\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.7351 - dice_coef: 0.8123 - val_loss: -0.7275 - val_dice_coef: 0.8067\n",
      "\n",
      "Epoch 00069: val_dice_coef did not improve from 0.85294\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 494ms/step - loss: -0.7351 - dice_coef: 0.8137 - val_loss: -0.7580 - val_dice_coef: 0.8326\n",
      "\n",
      "Epoch 00070: val_dice_coef did not improve from 0.85294\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.7327 - dice_coef: 0.8116 - val_loss: -0.7194 - val_dice_coef: 0.8105\n",
      "\n",
      "Epoch 00071: val_dice_coef did not improve from 0.85294\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.7333 - dice_coef: 0.8115 - val_loss: -0.7293 - val_dice_coef: 0.8131\n",
      "\n",
      "Epoch 00072: val_dice_coef did not improve from 0.85294\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.7350 - dice_coef: 0.8130 - val_loss: -0.6889 - val_dice_coef: 0.7899\n",
      "\n",
      "Epoch 00073: val_dice_coef did not improve from 0.85294\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 537ms/step - loss: -0.7326 - dice_coef: 0.8110 - val_loss: -0.6997 - val_dice_coef: 0.8010\n",
      "\n",
      "Epoch 00074: val_dice_coef did not improve from 0.85294\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 455ms/step - loss: -0.7368 - dice_coef: 0.8134 - val_loss: -0.7290 - val_dice_coef: 0.8222\n",
      "\n",
      "Epoch 00075: val_dice_coef did not improve from 0.85294\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.7365 - dice_coef: 0.8136 - val_loss: -0.7726 - val_dice_coef: 0.8537\n",
      "\n",
      "Epoch 00076: val_dice_coef improved from 0.85294 to 0.85366, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 485ms/step - loss: -0.7339 - dice_coef: 0.8129 - val_loss: -0.7345 - val_dice_coef: 0.8162\n",
      "\n",
      "Epoch 00077: val_dice_coef did not improve from 0.85366\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 19s 577ms/step - loss: -0.7339 - dice_coef: 0.8131 - val_loss: -0.7011 - val_dice_coef: 0.7906\n",
      "\n",
      "Epoch 00078: val_dice_coef did not improve from 0.85366\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 454ms/step - loss: -0.7363 - dice_coef: 0.8138 - val_loss: -0.7528 - val_dice_coef: 0.8273\n",
      "\n",
      "Epoch 00079: val_dice_coef did not improve from 0.85366\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.7373 - dice_coef: 0.8155 - val_loss: -0.7255 - val_dice_coef: 0.8128\n",
      "\n",
      "Epoch 00080: val_dice_coef did not improve from 0.85366\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 447ms/step - loss: -0.7405 - dice_coef: 0.8164 - val_loss: -0.7284 - val_dice_coef: 0.8126\n",
      "\n",
      "Epoch 00081: val_dice_coef did not improve from 0.85366\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 461ms/step - loss: -0.7398 - dice_coef: 0.8168 - val_loss: -0.6925 - val_dice_coef: 0.7920\n",
      "\n",
      "Epoch 00082: val_dice_coef did not improve from 0.85366\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 455ms/step - loss: -0.7402 - dice_coef: 0.8159 - val_loss: -0.7061 - val_dice_coef: 0.8040\n",
      "\n",
      "Epoch 00083: val_dice_coef did not improve from 0.85366\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.7396 - dice_coef: 0.8149 - val_loss: -0.7285 - val_dice_coef: 0.8216\n",
      "\n",
      "Epoch 00084: val_dice_coef did not improve from 0.85366\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 453ms/step - loss: -0.7409 - dice_coef: 0.8168 - val_loss: -0.7726 - val_dice_coef: 0.8537\n",
      "\n",
      "Epoch 00085: val_dice_coef improved from 0.85366 to 0.85374, saving model to /kaggle/working/output_model/unet_1.h5\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.7375 - dice_coef: 0.8149 - val_loss: -0.7446 - val_dice_coef: 0.8233\n",
      "\n",
      "Epoch 00086: val_dice_coef did not improve from 0.85374\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 454ms/step - loss: -0.7404 - dice_coef: 0.8159 - val_loss: -0.7159 - val_dice_coef: 0.7999\n",
      "\n",
      "Epoch 00087: val_dice_coef did not improve from 0.85374\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.7400 - dice_coef: 0.8164 - val_loss: -0.7508 - val_dice_coef: 0.8284\n",
      "\n",
      "Epoch 00088: val_dice_coef did not improve from 0.85374\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.7410 - dice_coef: 0.8167 - val_loss: -0.7325 - val_dice_coef: 0.8197\n",
      "\n",
      "Epoch 00089: val_dice_coef did not improve from 0.85374\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 451ms/step - loss: -0.7420 - dice_coef: 0.8179 - val_loss: -0.7248 - val_dice_coef: 0.8111\n",
      "\n",
      "Epoch 00090: val_dice_coef did not improve from 0.85374\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 455ms/step - loss: -0.7416 - dice_coef: 0.8170 - val_loss: -0.6863 - val_dice_coef: 0.7907\n",
      "\n",
      "Epoch 00091: val_dice_coef did not improve from 0.85374\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.7420 - dice_coef: 0.8181 - val_loss: -0.7037 - val_dice_coef: 0.8039\n",
      "\n",
      "Epoch 00092: val_dice_coef did not improve from 0.85374\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.7412 - dice_coef: 0.8174 - val_loss: -0.7233 - val_dice_coef: 0.8197\n",
      "\n",
      "Epoch 00093: val_dice_coef did not improve from 0.85374\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.7421 - dice_coef: 0.8182 - val_loss: -0.7674 - val_dice_coef: 0.8522\n",
      "\n",
      "Epoch 00094: val_dice_coef did not improve from 0.85374\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 449ms/step - loss: -0.7396 - dice_coef: 0.8170 - val_loss: -0.7323 - val_dice_coef: 0.8161\n",
      "\n",
      "Epoch 00095: val_dice_coef did not improve from 0.85374\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.7423 - dice_coef: 0.8178 - val_loss: -0.7162 - val_dice_coef: 0.8010\n",
      "\n",
      "Epoch 00096: val_dice_coef did not improve from 0.85374\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.7430 - dice_coef: 0.8181 - val_loss: -0.7554 - val_dice_coef: 0.8317\n",
      "\n",
      "Epoch 00097: val_dice_coef did not improve from 0.85374\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.7420 - dice_coef: 0.8179 - val_loss: -0.7271 - val_dice_coef: 0.8177\n",
      "\n",
      "Epoch 00098: val_dice_coef did not improve from 0.85374\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 446ms/step - loss: -0.7397 - dice_coef: 0.8158 - val_loss: -0.7246 - val_dice_coef: 0.8111\n",
      "\n",
      "Epoch 00099: val_dice_coef did not improve from 0.85374\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7465 - dice_coef: 0.8214 - val_loss: -0.6895 - val_dice_coef: 0.7928\n",
      "\n",
      "Epoch 00100: val_dice_coef did not improve from 0.85374\n",
      "133/133 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:13<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold1: 79.26\n",
      "average AJI pure Unet for fold1: 40.37\n",
      "average PQ pure Unet for fold1: 40.34\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold1: 79.26\n",
      "average AJI Unet watershed for fold1: 46.94\n",
      "average PQ Unet watershed for fold1: 38.14\n",
      "==========\n",
      "average Dice Unet watershed wo vague for fold1: 80.42\n",
      "average AJI Unet watershed wo vague for fold1: 48.44\n",
      "average PQ Unet watershed wo vague for fold1: 39.10\n",
      "==========\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 20s 560ms/step - loss: 0.0195 - dice_coef: 0.2244 - val_loss: -0.0439 - val_dice_coef: 0.2702\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.27020, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 537ms/step - loss: -0.0995 - dice_coef: 0.2861 - val_loss: -0.1464 - val_dice_coef: 0.2804\n",
      "\n",
      "Epoch 00002: val_dice_coef improved from 0.27020 to 0.28037, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 482ms/step - loss: -0.2190 - dice_coef: 0.4066 - val_loss: -0.3741 - val_dice_coef: 0.5425\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.28037 to 0.54248, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.2540 - dice_coef: 0.4614 - val_loss: -0.3645 - val_dice_coef: 0.4937\n",
      "\n",
      "Epoch 00004: val_dice_coef did not improve from 0.54248\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.2906 - dice_coef: 0.4882 - val_loss: -0.4340 - val_dice_coef: 0.5364\n",
      "\n",
      "Epoch 00005: val_dice_coef did not improve from 0.54248\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.2757 - dice_coef: 0.4821 - val_loss: -0.2696 - val_dice_coef: 0.4585\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve from 0.54248\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.3162 - dice_coef: 0.5063 - val_loss: -0.4330 - val_dice_coef: 0.5850\n",
      "\n",
      "Epoch 00007: val_dice_coef improved from 0.54248 to 0.58495, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.3475 - dice_coef: 0.5350 - val_loss: -0.3620 - val_dice_coef: 0.5423\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve from 0.58495\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.3587 - dice_coef: 0.5434 - val_loss: -0.3977 - val_dice_coef: 0.5317\n",
      "\n",
      "Epoch 00009: val_dice_coef did not improve from 0.58495\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.3525 - dice_coef: 0.5461 - val_loss: -0.2825 - val_dice_coef: 0.4801\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve from 0.58495\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.2845 - dice_coef: 0.4799 - val_loss: -0.2516 - val_dice_coef: 0.4005\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve from 0.58495\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.3711 - dice_coef: 0.5534 - val_loss: -0.5259 - val_dice_coef: 0.6667\n",
      "\n",
      "Epoch 00012: val_dice_coef improved from 0.58495 to 0.66668, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.4064 - dice_coef: 0.5806 - val_loss: -0.4377 - val_dice_coef: 0.5525\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve from 0.66668\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.4468 - dice_coef: 0.6104 - val_loss: -0.5724 - val_dice_coef: 0.6611\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve from 0.66668\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 486ms/step - loss: -0.4595 - dice_coef: 0.6277 - val_loss: -0.4372 - val_dice_coef: 0.5668\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve from 0.66668\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 532ms/step - loss: -0.4544 - dice_coef: 0.6161 - val_loss: -0.4474 - val_dice_coef: 0.6027\n",
      "\n",
      "Epoch 00016: val_dice_coef did not improve from 0.66668\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 19s 584ms/step - loss: -0.4944 - dice_coef: 0.6445 - val_loss: -0.5335 - val_dice_coef: 0.6712\n",
      "\n",
      "Epoch 00017: val_dice_coef improved from 0.66668 to 0.67115, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 20s 622ms/step - loss: -0.5038 - dice_coef: 0.6547 - val_loss: -0.4987 - val_dice_coef: 0.6321\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve from 0.67115\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 18s 569ms/step - loss: -0.5302 - dice_coef: 0.6704 - val_loss: -0.6008 - val_dice_coef: 0.7332\n",
      "\n",
      "Epoch 00019: val_dice_coef improved from 0.67115 to 0.73321, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 498ms/step - loss: -0.5431 - dice_coef: 0.6824 - val_loss: -0.5440 - val_dice_coef: 0.6381\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve from 0.73321\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.5621 - dice_coef: 0.6936 - val_loss: -0.6157 - val_dice_coef: 0.7357\n",
      "\n",
      "Epoch 00021: val_dice_coef improved from 0.73321 to 0.73566, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.5673 - dice_coef: 0.6995 - val_loss: -0.5612 - val_dice_coef: 0.6592\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve from 0.73566\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.5792 - dice_coef: 0.7074 - val_loss: -0.5901 - val_dice_coef: 0.6871\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve from 0.73566\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.5886 - dice_coef: 0.7140 - val_loss: -0.6071 - val_dice_coef: 0.7080\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve from 0.73566\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.5943 - dice_coef: 0.7161 - val_loss: -0.5079 - val_dice_coef: 0.6583\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve from 0.73566\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.5938 - dice_coef: 0.7158 - val_loss: -0.6384 - val_dice_coef: 0.7362\n",
      "\n",
      "Epoch 00026: val_dice_coef improved from 0.73566 to 0.73617, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.6034 - dice_coef: 0.7248 - val_loss: -0.5798 - val_dice_coef: 0.6985\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve from 0.73617\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 495ms/step - loss: -0.5865 - dice_coef: 0.7127 - val_loss: -0.6050 - val_dice_coef: 0.7422\n",
      "\n",
      "Epoch 00028: val_dice_coef improved from 0.73617 to 0.74222, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.6045 - dice_coef: 0.7245 - val_loss: -0.5816 - val_dice_coef: 0.6729\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve from 0.74222\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.6213 - dice_coef: 0.7366 - val_loss: -0.6358 - val_dice_coef: 0.7574\n",
      "\n",
      "Epoch 00030: val_dice_coef improved from 0.74222 to 0.75743, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.6061 - dice_coef: 0.7254 - val_loss: -0.5708 - val_dice_coef: 0.6743\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve from 0.75743\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.6121 - dice_coef: 0.7293 - val_loss: -0.5685 - val_dice_coef: 0.6807\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve from 0.75743\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 482ms/step - loss: -0.6219 - dice_coef: 0.7358 - val_loss: -0.6429 - val_dice_coef: 0.7359\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve from 0.75743\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.6108 - dice_coef: 0.7296 - val_loss: -0.5605 - val_dice_coef: 0.6909\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve from 0.75743\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.6174 - dice_coef: 0.7301 - val_loss: -0.6491 - val_dice_coef: 0.7525\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve from 0.75743\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.6331 - dice_coef: 0.7434 - val_loss: -0.6662 - val_dice_coef: 0.7579\n",
      "\n",
      "Epoch 00036: val_dice_coef improved from 0.75743 to 0.75785, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.6339 - dice_coef: 0.7436 - val_loss: -0.6374 - val_dice_coef: 0.7690\n",
      "\n",
      "Epoch 00037: val_dice_coef improved from 0.75785 to 0.76899, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.6390 - dice_coef: 0.7476 - val_loss: -0.6250 - val_dice_coef: 0.7131\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve from 0.76899\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.6274 - dice_coef: 0.7395 - val_loss: -0.6555 - val_dice_coef: 0.7691\n",
      "\n",
      "Epoch 00039: val_dice_coef improved from 0.76899 to 0.76913, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 478ms/step - loss: -0.6362 - dice_coef: 0.7470 - val_loss: -0.6026 - val_dice_coef: 0.7014\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve from 0.76913\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 449ms/step - loss: -0.6502 - dice_coef: 0.7556 - val_loss: -0.6364 - val_dice_coef: 0.7247\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve from 0.76913\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.6534 - dice_coef: 0.7565 - val_loss: -0.6563 - val_dice_coef: 0.7465\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve from 0.76913\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.6583 - dice_coef: 0.7598 - val_loss: -0.6188 - val_dice_coef: 0.7404\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve from 0.76913\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.6559 - dice_coef: 0.7603 - val_loss: -0.6979 - val_dice_coef: 0.7830\n",
      "\n",
      "Epoch 00044: val_dice_coef improved from 0.76913 to 0.78295, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.6651 - dice_coef: 0.7663 - val_loss: -0.6981 - val_dice_coef: 0.7832\n",
      "\n",
      "Epoch 00045: val_dice_coef improved from 0.78295 to 0.78322, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.6649 - dice_coef: 0.7652 - val_loss: -0.6742 - val_dice_coef: 0.7890\n",
      "\n",
      "Epoch 00046: val_dice_coef improved from 0.78322 to 0.78902, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 470ms/step - loss: -0.6678 - dice_coef: 0.7671 - val_loss: -0.6364 - val_dice_coef: 0.7199\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve from 0.78902\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 18s 553ms/step - loss: -0.6691 - dice_coef: 0.7694 - val_loss: -0.6840 - val_dice_coef: 0.7898\n",
      "\n",
      "Epoch 00048: val_dice_coef improved from 0.78902 to 0.78979, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 19s 584ms/step - loss: -0.6689 - dice_coef: 0.7682 - val_loss: -0.6463 - val_dice_coef: 0.7298\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve from 0.78979\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.6677 - dice_coef: 0.7679 - val_loss: -0.6267 - val_dice_coef: 0.7187\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve from 0.78979\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.6690 - dice_coef: 0.7672 - val_loss: -0.6675 - val_dice_coef: 0.7576\n",
      "\n",
      "Epoch 00051: val_dice_coef did not improve from 0.78979\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 520ms/step - loss: -0.6642 - dice_coef: 0.7651 - val_loss: -0.6342 - val_dice_coef: 0.7511\n",
      "\n",
      "Epoch 00052: val_dice_coef did not improve from 0.78979\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 21s 647ms/step - loss: -0.6723 - dice_coef: 0.7703 - val_loss: -0.7103 - val_dice_coef: 0.7929\n",
      "\n",
      "Epoch 00053: val_dice_coef improved from 0.78979 to 0.79293, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 509ms/step - loss: -0.6784 - dice_coef: 0.7758 - val_loss: -0.7044 - val_dice_coef: 0.7864\n",
      "\n",
      "Epoch 00054: val_dice_coef did not improve from 0.79293\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.6782 - dice_coef: 0.7746 - val_loss: -0.6841 - val_dice_coef: 0.7975\n",
      "\n",
      "Epoch 00055: val_dice_coef improved from 0.79293 to 0.79752, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 19s 571ms/step - loss: -0.6840 - dice_coef: 0.7796 - val_loss: -0.6397 - val_dice_coef: 0.7215\n",
      "\n",
      "Epoch 00056: val_dice_coef did not improve from 0.79752\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 23s 716ms/step - loss: -0.6731 - dice_coef: 0.7727 - val_loss: -0.7048 - val_dice_coef: 0.7998\n",
      "\n",
      "Epoch 00057: val_dice_coef improved from 0.79752 to 0.79977, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 484ms/step - loss: -0.6801 - dice_coef: 0.7757 - val_loss: -0.6501 - val_dice_coef: 0.7311\n",
      "\n",
      "Epoch 00058: val_dice_coef did not improve from 0.79977\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 501ms/step - loss: -0.6845 - dice_coef: 0.7788 - val_loss: -0.6456 - val_dice_coef: 0.7312\n",
      "\n",
      "Epoch 00059: val_dice_coef did not improve from 0.79977\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 517ms/step - loss: -0.6795 - dice_coef: 0.7758 - val_loss: -0.6683 - val_dice_coef: 0.7613\n",
      "\n",
      "Epoch 00060: val_dice_coef did not improve from 0.79977\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 19s 596ms/step - loss: -0.6840 - dice_coef: 0.7789 - val_loss: -0.6402 - val_dice_coef: 0.7551\n",
      "\n",
      "Epoch 00061: val_dice_coef did not improve from 0.79977\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 482ms/step - loss: -0.6858 - dice_coef: 0.7805 - val_loss: -0.7143 - val_dice_coef: 0.7952\n",
      "\n",
      "Epoch 00062: val_dice_coef did not improve from 0.79977\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 477ms/step - loss: -0.6854 - dice_coef: 0.7787 - val_loss: -0.7032 - val_dice_coef: 0.7869\n",
      "\n",
      "Epoch 00063: val_dice_coef did not improve from 0.79977\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 488ms/step - loss: -0.6842 - dice_coef: 0.7798 - val_loss: -0.6894 - val_dice_coef: 0.8000\n",
      "\n",
      "Epoch 00064: val_dice_coef improved from 0.79977 to 0.79998, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 491ms/step - loss: -0.6887 - dice_coef: 0.7823 - val_loss: -0.6336 - val_dice_coef: 0.7184\n",
      "\n",
      "Epoch 00065: val_dice_coef did not improve from 0.79998\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 486ms/step - loss: -0.6874 - dice_coef: 0.7812 - val_loss: -0.7098 - val_dice_coef: 0.8061\n",
      "\n",
      "Epoch 00066: val_dice_coef improved from 0.79998 to 0.80610, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 499ms/step - loss: -0.6870 - dice_coef: 0.7808 - val_loss: -0.6530 - val_dice_coef: 0.7375\n",
      "\n",
      "Epoch 00067: val_dice_coef did not improve from 0.80610\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 18s 545ms/step - loss: -0.6850 - dice_coef: 0.7805 - val_loss: -0.6540 - val_dice_coef: 0.7395\n",
      "\n",
      "Epoch 00068: val_dice_coef did not improve from 0.80610\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 19s 588ms/step - loss: -0.6861 - dice_coef: 0.7779 - val_loss: -0.6752 - val_dice_coef: 0.7664\n",
      "\n",
      "Epoch 00069: val_dice_coef did not improve from 0.80610\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 19s 578ms/step - loss: -0.6885 - dice_coef: 0.7826 - val_loss: -0.6663 - val_dice_coef: 0.7719\n",
      "\n",
      "Epoch 00070: val_dice_coef did not improve from 0.80610\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 21s 648ms/step - loss: -0.6901 - dice_coef: 0.7828 - val_loss: -0.7259 - val_dice_coef: 0.8017\n",
      "\n",
      "Epoch 00071: val_dice_coef did not improve from 0.80610\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 18s 557ms/step - loss: -0.6907 - dice_coef: 0.7827 - val_loss: -0.7149 - val_dice_coef: 0.7947\n",
      "\n",
      "Epoch 00072: val_dice_coef did not improve from 0.80610\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 529ms/step - loss: -0.6909 - dice_coef: 0.7835 - val_loss: -0.7012 - val_dice_coef: 0.8073\n",
      "\n",
      "Epoch 00073: val_dice_coef improved from 0.80610 to 0.80730, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 534ms/step - loss: -0.6983 - dice_coef: 0.7891 - val_loss: -0.6502 - val_dice_coef: 0.7277\n",
      "\n",
      "Epoch 00074: val_dice_coef did not improve from 0.80730\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.6920 - dice_coef: 0.7850 - val_loss: -0.7135 - val_dice_coef: 0.8061\n",
      "\n",
      "Epoch 00075: val_dice_coef did not improve from 0.80730\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.6957 - dice_coef: 0.7864 - val_loss: -0.6708 - val_dice_coef: 0.7464\n",
      "\n",
      "Epoch 00076: val_dice_coef did not improve from 0.80730\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.6907 - dice_coef: 0.7838 - val_loss: -0.6697 - val_dice_coef: 0.7478\n",
      "\n",
      "Epoch 00077: val_dice_coef did not improve from 0.80730\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.6966 - dice_coef: 0.7877 - val_loss: -0.6812 - val_dice_coef: 0.7702\n",
      "\n",
      "Epoch 00078: val_dice_coef did not improve from 0.80730\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.6937 - dice_coef: 0.7856 - val_loss: -0.6680 - val_dice_coef: 0.7736\n",
      "\n",
      "Epoch 00079: val_dice_coef did not improve from 0.80730\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.6928 - dice_coef: 0.7842 - val_loss: -0.7179 - val_dice_coef: 0.7987\n",
      "\n",
      "Epoch 00080: val_dice_coef did not improve from 0.80730\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 455ms/step - loss: -0.7009 - dice_coef: 0.7909 - val_loss: -0.7138 - val_dice_coef: 0.7942\n",
      "\n",
      "Epoch 00081: val_dice_coef did not improve from 0.80730\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.6986 - dice_coef: 0.7894 - val_loss: -0.7012 - val_dice_coef: 0.8069\n",
      "\n",
      "Epoch 00082: val_dice_coef did not improve from 0.80730\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.6998 - dice_coef: 0.7896 - val_loss: -0.6471 - val_dice_coef: 0.7262\n",
      "\n",
      "Epoch 00083: val_dice_coef did not improve from 0.80730\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7023 - dice_coef: 0.7910 - val_loss: -0.7215 - val_dice_coef: 0.8127\n",
      "\n",
      "Epoch 00084: val_dice_coef improved from 0.80730 to 0.81267, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.7057 - dice_coef: 0.7930 - val_loss: -0.6699 - val_dice_coef: 0.7490\n",
      "\n",
      "Epoch 00085: val_dice_coef did not improve from 0.81267\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.7015 - dice_coef: 0.7912 - val_loss: -0.6725 - val_dice_coef: 0.7521\n",
      "\n",
      "Epoch 00086: val_dice_coef did not improve from 0.81267\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.7031 - dice_coef: 0.7916 - val_loss: -0.6850 - val_dice_coef: 0.7714\n",
      "\n",
      "Epoch 00087: val_dice_coef did not improve from 0.81267\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 461ms/step - loss: -0.6964 - dice_coef: 0.7878 - val_loss: -0.6745 - val_dice_coef: 0.7779\n",
      "\n",
      "Epoch 00088: val_dice_coef did not improve from 0.81267\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.7004 - dice_coef: 0.7904 - val_loss: -0.7313 - val_dice_coef: 0.8061\n",
      "\n",
      "Epoch 00089: val_dice_coef did not improve from 0.81267\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.7008 - dice_coef: 0.7899 - val_loss: -0.7200 - val_dice_coef: 0.7979\n",
      "\n",
      "Epoch 00090: val_dice_coef did not improve from 0.81267\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 17s 513ms/step - loss: -0.7031 - dice_coef: 0.7930 - val_loss: -0.7016 - val_dice_coef: 0.8092\n",
      "\n",
      "Epoch 00091: val_dice_coef did not improve from 0.81267\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 501ms/step - loss: -0.7022 - dice_coef: 0.7917 - val_loss: -0.6485 - val_dice_coef: 0.7270\n",
      "\n",
      "Epoch 00092: val_dice_coef did not improve from 0.81267\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 482ms/step - loss: -0.7049 - dice_coef: 0.7922 - val_loss: -0.7233 - val_dice_coef: 0.8140\n",
      "\n",
      "Epoch 00093: val_dice_coef improved from 0.81267 to 0.81396, saving model to /kaggle/working/output_model/unet_2.h5\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.7029 - dice_coef: 0.7920 - val_loss: -0.6673 - val_dice_coef: 0.7474\n",
      "\n",
      "Epoch 00094: val_dice_coef did not improve from 0.81396\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.7024 - dice_coef: 0.7914 - val_loss: -0.6584 - val_dice_coef: 0.7443\n",
      "\n",
      "Epoch 00095: val_dice_coef did not improve from 0.81396\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.7079 - dice_coef: 0.7949 - val_loss: -0.6836 - val_dice_coef: 0.7715\n",
      "\n",
      "Epoch 00096: val_dice_coef did not improve from 0.81396\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 501ms/step - loss: -0.7044 - dice_coef: 0.7924 - val_loss: -0.6771 - val_dice_coef: 0.7812\n",
      "\n",
      "Epoch 00097: val_dice_coef did not improve from 0.81396\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.7017 - dice_coef: 0.7915 - val_loss: -0.7311 - val_dice_coef: 0.8072\n",
      "\n",
      "Epoch 00098: val_dice_coef did not improve from 0.81396\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.6977 - dice_coef: 0.7887 - val_loss: -0.7199 - val_dice_coef: 0.7986\n",
      "\n",
      "Epoch 00099: val_dice_coef did not improve from 0.81396\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.7025 - dice_coef: 0.7918 - val_loss: -0.7019 - val_dice_coef: 0.8084\n",
      "\n",
      "Epoch 00100: val_dice_coef did not improve from 0.81396\n",
      "133/133 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:59<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold2: 75.47\n",
      "average AJI pure Unet for fold2: 36.70\n",
      "average PQ pure Unet for fold2: 35.84\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold2: 75.47\n",
      "average AJI Unet watershed for fold2: 44.35\n",
      "average PQ Unet watershed for fold2: 34.16\n",
      "==========\n",
      "average Dice Unet watershed wo vague for fold2: 76.42\n",
      "average AJI Unet watershed wo vague for fold2: 45.29\n",
      "average PQ Unet watershed wo vague for fold2: 35.25\n",
      "==========\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 487ms/step - loss: -0.0200 - dice_coef: 0.2469 - val_loss: -0.1473 - val_dice_coef: 0.3018\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.30183, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.0795 - dice_coef: 0.2954 - val_loss: -0.1571 - val_dice_coef: 0.3355\n",
      "\n",
      "Epoch 00002: val_dice_coef improved from 0.30183 to 0.33549, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.1668 - dice_coef: 0.3525 - val_loss: -0.1553 - val_dice_coef: 0.3505\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.33549 to 0.35052, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 461ms/step - loss: -0.2010 - dice_coef: 0.3750 - val_loss: -0.0948 - val_dice_coef: 0.2509\n",
      "\n",
      "Epoch 00004: val_dice_coef did not improve from 0.35052\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 490ms/step - loss: -0.2660 - dice_coef: 0.4631 - val_loss: -0.3163 - val_dice_coef: 0.4896\n",
      "\n",
      "Epoch 00005: val_dice_coef improved from 0.35052 to 0.48962, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 513ms/step - loss: -0.2569 - dice_coef: 0.4636 - val_loss: -0.3874 - val_dice_coef: 0.5136\n",
      "\n",
      "Epoch 00006: val_dice_coef improved from 0.48962 to 0.51356, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.3102 - dice_coef: 0.4950 - val_loss: -0.4118 - val_dice_coef: 0.5252\n",
      "\n",
      "Epoch 00007: val_dice_coef improved from 0.51356 to 0.52525, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.3565 - dice_coef: 0.5330 - val_loss: -0.2301 - val_dice_coef: 0.4563\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve from 0.52525\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.3819 - dice_coef: 0.5654 - val_loss: -0.4693 - val_dice_coef: 0.5962\n",
      "\n",
      "Epoch 00009: val_dice_coef improved from 0.52525 to 0.59616, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.4336 - dice_coef: 0.5961 - val_loss: -0.4285 - val_dice_coef: 0.5752\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve from 0.59616\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 19s 581ms/step - loss: -0.4475 - dice_coef: 0.6113 - val_loss: -0.5113 - val_dice_coef: 0.6415\n",
      "\n",
      "Epoch 00011: val_dice_coef improved from 0.59616 to 0.64147, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 20s 630ms/step - loss: -0.4701 - dice_coef: 0.6277 - val_loss: -0.4423 - val_dice_coef: 0.6054\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve from 0.64147\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 512ms/step - loss: -0.4791 - dice_coef: 0.6330 - val_loss: -0.5405 - val_dice_coef: 0.6231\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve from 0.64147\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.5069 - dice_coef: 0.6539 - val_loss: -0.4479 - val_dice_coef: 0.6091\n",
      "\n",
      "Epoch 00014: val_dice_coef did not improve from 0.64147\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.5071 - dice_coef: 0.6545 - val_loss: -0.5377 - val_dice_coef: 0.6661\n",
      "\n",
      "Epoch 00015: val_dice_coef improved from 0.64147 to 0.66610, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.5139 - dice_coef: 0.6566 - val_loss: -0.6535 - val_dice_coef: 0.7242\n",
      "\n",
      "Epoch 00016: val_dice_coef improved from 0.66610 to 0.72424, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.5285 - dice_coef: 0.6677 - val_loss: -0.4689 - val_dice_coef: 0.6314\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve from 0.72424\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 443ms/step - loss: -0.5338 - dice_coef: 0.6734 - val_loss: -0.6263 - val_dice_coef: 0.7261\n",
      "\n",
      "Epoch 00018: val_dice_coef improved from 0.72424 to 0.72611, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.5572 - dice_coef: 0.6891 - val_loss: -0.5887 - val_dice_coef: 0.6847\n",
      "\n",
      "Epoch 00019: val_dice_coef did not improve from 0.72611\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.5665 - dice_coef: 0.6962 - val_loss: -0.6191 - val_dice_coef: 0.7315\n",
      "\n",
      "Epoch 00020: val_dice_coef improved from 0.72611 to 0.73151, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.5798 - dice_coef: 0.7056 - val_loss: -0.5715 - val_dice_coef: 0.7027\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve from 0.73151\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.5865 - dice_coef: 0.7103 - val_loss: -0.6352 - val_dice_coef: 0.7034\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve from 0.73151\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.5912 - dice_coef: 0.7144 - val_loss: -0.6379 - val_dice_coef: 0.7438\n",
      "\n",
      "Epoch 00023: val_dice_coef improved from 0.73151 to 0.74380, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 504ms/step - loss: -0.5994 - dice_coef: 0.7191 - val_loss: -0.6446 - val_dice_coef: 0.7457\n",
      "\n",
      "Epoch 00024: val_dice_coef improved from 0.74380 to 0.74565, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 497ms/step - loss: -0.5920 - dice_coef: 0.7140 - val_loss: -0.6846 - val_dice_coef: 0.7550\n",
      "\n",
      "Epoch 00025: val_dice_coef improved from 0.74565 to 0.75503, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 20s 631ms/step - loss: -0.6125 - dice_coef: 0.7285 - val_loss: -0.5986 - val_dice_coef: 0.7233\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve from 0.75503\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 23s 719ms/step - loss: -0.6100 - dice_coef: 0.7270 - val_loss: -0.6616 - val_dice_coef: 0.7514\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve from 0.75503\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 22s 671ms/step - loss: -0.6099 - dice_coef: 0.7271 - val_loss: -0.6218 - val_dice_coef: 0.7190\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve from 0.75503\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 26s 793ms/step - loss: -0.6080 - dice_coef: 0.7267 - val_loss: -0.6599 - val_dice_coef: 0.7665\n",
      "\n",
      "Epoch 00029: val_dice_coef improved from 0.75503 to 0.76648, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 23s 721ms/step - loss: -0.6158 - dice_coef: 0.7307 - val_loss: -0.6169 - val_dice_coef: 0.7409\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve from 0.76648\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 23s 706ms/step - loss: -0.6132 - dice_coef: 0.7283 - val_loss: -0.6400 - val_dice_coef: 0.7145\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve from 0.76648\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 22s 673ms/step - loss: -0.6169 - dice_coef: 0.7321 - val_loss: -0.4906 - val_dice_coef: 0.6597\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve from 0.76648\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 21s 643ms/step - loss: -0.6222 - dice_coef: 0.7346 - val_loss: -0.6369 - val_dice_coef: 0.7431\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve from 0.76648\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 495ms/step - loss: -0.6247 - dice_coef: 0.7365 - val_loss: -0.6898 - val_dice_coef: 0.7637\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve from 0.76648\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 18s 554ms/step - loss: -0.6295 - dice_coef: 0.7393 - val_loss: -0.6136 - val_dice_coef: 0.7334\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve from 0.76648\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 19s 590ms/step - loss: -0.6367 - dice_coef: 0.7466 - val_loss: -0.6818 - val_dice_coef: 0.7686\n",
      "\n",
      "Epoch 00036: val_dice_coef improved from 0.76648 to 0.76862, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 19s 577ms/step - loss: -0.6359 - dice_coef: 0.7457 - val_loss: -0.6608 - val_dice_coef: 0.7476\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve from 0.76862\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.6491 - dice_coef: 0.7541 - val_loss: -0.6741 - val_dice_coef: 0.7766\n",
      "\n",
      "Epoch 00038: val_dice_coef improved from 0.76862 to 0.77660, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.6512 - dice_coef: 0.7556 - val_loss: -0.6794 - val_dice_coef: 0.7785\n",
      "\n",
      "Epoch 00039: val_dice_coef improved from 0.77660 to 0.77850, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.6551 - dice_coef: 0.7599 - val_loss: -0.6877 - val_dice_coef: 0.7496\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve from 0.77850\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.6617 - dice_coef: 0.7626 - val_loss: -0.7186 - val_dice_coef: 0.8040\n",
      "\n",
      "Epoch 00041: val_dice_coef improved from 0.77850 to 0.80402, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.6684 - dice_coef: 0.7686 - val_loss: -0.7306 - val_dice_coef: 0.8069\n",
      "\n",
      "Epoch 00042: val_dice_coef improved from 0.80402 to 0.80686, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.6643 - dice_coef: 0.7654 - val_loss: -0.7247 - val_dice_coef: 0.7873\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve from 0.80686\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.6757 - dice_coef: 0.7730 - val_loss: -0.6571 - val_dice_coef: 0.7638\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve from 0.80686\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.6683 - dice_coef: 0.7671 - val_loss: -0.7013 - val_dice_coef: 0.7830\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve from 0.80686\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 512ms/step - loss: -0.6684 - dice_coef: 0.7671 - val_loss: -0.6931 - val_dice_coef: 0.7714\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve from 0.80686\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 534ms/step - loss: -0.6811 - dice_coef: 0.7765 - val_loss: -0.7088 - val_dice_coef: 0.7976\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve from 0.80686\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 523ms/step - loss: -0.6807 - dice_coef: 0.7759 - val_loss: -0.7014 - val_dice_coef: 0.7935\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve from 0.80686\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 513ms/step - loss: -0.6800 - dice_coef: 0.7773 - val_loss: -0.7259 - val_dice_coef: 0.7780\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve from 0.80686\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 453ms/step - loss: -0.6808 - dice_coef: 0.7766 - val_loss: -0.7588 - val_dice_coef: 0.8291\n",
      "\n",
      "Epoch 00050: val_dice_coef improved from 0.80686 to 0.82911, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.6863 - dice_coef: 0.7797 - val_loss: -0.7462 - val_dice_coef: 0.8187\n",
      "\n",
      "Epoch 00051: val_dice_coef did not improve from 0.82911\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 501ms/step - loss: -0.6854 - dice_coef: 0.7784 - val_loss: -0.7330 - val_dice_coef: 0.7945\n",
      "\n",
      "Epoch 00052: val_dice_coef did not improve from 0.82911\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 20s 621ms/step - loss: -0.6877 - dice_coef: 0.7816 - val_loss: -0.6945 - val_dice_coef: 0.7865\n",
      "\n",
      "Epoch 00053: val_dice_coef did not improve from 0.82911\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 21s 635ms/step - loss: -0.6916 - dice_coef: 0.7840 - val_loss: -0.7100 - val_dice_coef: 0.7887\n",
      "\n",
      "Epoch 00054: val_dice_coef did not improve from 0.82911\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 21s 662ms/step - loss: -0.6908 - dice_coef: 0.7829 - val_loss: -0.6921 - val_dice_coef: 0.7714\n",
      "\n",
      "Epoch 00055: val_dice_coef did not improve from 0.82911\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 20s 630ms/step - loss: -0.6873 - dice_coef: 0.7816 - val_loss: -0.7113 - val_dice_coef: 0.7979\n",
      "\n",
      "Epoch 00056: val_dice_coef did not improve from 0.82911\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 20s 612ms/step - loss: -0.6756 - dice_coef: 0.7719 - val_loss: -0.6870 - val_dice_coef: 0.7871\n",
      "\n",
      "Epoch 00057: val_dice_coef did not improve from 0.82911\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 19s 575ms/step - loss: -0.6858 - dice_coef: 0.7803 - val_loss: -0.7079 - val_dice_coef: 0.7664\n",
      "\n",
      "Epoch 00058: val_dice_coef did not improve from 0.82911\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 19s 581ms/step - loss: -0.6912 - dice_coef: 0.7827 - val_loss: -0.7310 - val_dice_coef: 0.8118\n",
      "\n",
      "Epoch 00059: val_dice_coef did not improve from 0.82911\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 18s 566ms/step - loss: -0.6878 - dice_coef: 0.7817 - val_loss: -0.7450 - val_dice_coef: 0.8201\n",
      "\n",
      "Epoch 00060: val_dice_coef did not improve from 0.82911\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 18s 551ms/step - loss: -0.6921 - dice_coef: 0.7826 - val_loss: -0.7377 - val_dice_coef: 0.8011\n",
      "\n",
      "Epoch 00061: val_dice_coef did not improve from 0.82911\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 536ms/step - loss: -0.6971 - dice_coef: 0.7868 - val_loss: -0.7052 - val_dice_coef: 0.7984\n",
      "\n",
      "Epoch 00062: val_dice_coef did not improve from 0.82911\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.6980 - dice_coef: 0.7888 - val_loss: -0.7188 - val_dice_coef: 0.7966\n",
      "\n",
      "Epoch 00063: val_dice_coef did not improve from 0.82911\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.7047 - dice_coef: 0.7929 - val_loss: -0.7128 - val_dice_coef: 0.7890\n",
      "\n",
      "Epoch 00064: val_dice_coef did not improve from 0.82911\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 528ms/step - loss: -0.7009 - dice_coef: 0.7902 - val_loss: -0.7259 - val_dice_coef: 0.8123\n",
      "\n",
      "Epoch 00065: val_dice_coef did not improve from 0.82911\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.7050 - dice_coef: 0.7927 - val_loss: -0.7174 - val_dice_coef: 0.8069\n",
      "\n",
      "Epoch 00066: val_dice_coef did not improve from 0.82911\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 538ms/step - loss: -0.7046 - dice_coef: 0.7933 - val_loss: -0.7253 - val_dice_coef: 0.7813\n",
      "\n",
      "Epoch 00067: val_dice_coef did not improve from 0.82911\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 440ms/step - loss: -0.7041 - dice_coef: 0.7920 - val_loss: -0.7550 - val_dice_coef: 0.8293\n",
      "\n",
      "Epoch 00068: val_dice_coef improved from 0.82911 to 0.82931, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.7052 - dice_coef: 0.7928 - val_loss: -0.7531 - val_dice_coef: 0.8252\n",
      "\n",
      "Epoch 00069: val_dice_coef did not improve from 0.82931\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.6999 - dice_coef: 0.7898 - val_loss: -0.7361 - val_dice_coef: 0.7986\n",
      "\n",
      "Epoch 00070: val_dice_coef did not improve from 0.82931\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.7026 - dice_coef: 0.7916 - val_loss: -0.6900 - val_dice_coef: 0.7863\n",
      "\n",
      "Epoch 00071: val_dice_coef did not improve from 0.82931\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 444ms/step - loss: -0.6983 - dice_coef: 0.7879 - val_loss: -0.7243 - val_dice_coef: 0.7996\n",
      "\n",
      "Epoch 00072: val_dice_coef did not improve from 0.82931\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.7095 - dice_coef: 0.7965 - val_loss: -0.7145 - val_dice_coef: 0.7875\n",
      "\n",
      "Epoch 00073: val_dice_coef did not improve from 0.82931\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 448ms/step - loss: -0.7076 - dice_coef: 0.7950 - val_loss: -0.7313 - val_dice_coef: 0.8136\n",
      "\n",
      "Epoch 00074: val_dice_coef did not improve from 0.82931\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.7060 - dice_coef: 0.7940 - val_loss: -0.7177 - val_dice_coef: 0.8050\n",
      "\n",
      "Epoch 00075: val_dice_coef did not improve from 0.82931\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.7051 - dice_coef: 0.7926 - val_loss: -0.7272 - val_dice_coef: 0.7815\n",
      "\n",
      "Epoch 00076: val_dice_coef did not improve from 0.82931\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7129 - dice_coef: 0.7992 - val_loss: -0.7595 - val_dice_coef: 0.8314\n",
      "\n",
      "Epoch 00077: val_dice_coef improved from 0.82931 to 0.83144, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.7054 - dice_coef: 0.7931 - val_loss: -0.7580 - val_dice_coef: 0.8285\n",
      "\n",
      "Epoch 00078: val_dice_coef did not improve from 0.83144\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.7038 - dice_coef: 0.7926 - val_loss: -0.7504 - val_dice_coef: 0.8067\n",
      "\n",
      "Epoch 00079: val_dice_coef did not improve from 0.83144\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.7091 - dice_coef: 0.7952 - val_loss: -0.7171 - val_dice_coef: 0.8035\n",
      "\n",
      "Epoch 00080: val_dice_coef did not improve from 0.83144\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 450ms/step - loss: -0.7084 - dice_coef: 0.7949 - val_loss: -0.7239 - val_dice_coef: 0.8007\n",
      "\n",
      "Epoch 00081: val_dice_coef did not improve from 0.83144\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.7107 - dice_coef: 0.7962 - val_loss: -0.7207 - val_dice_coef: 0.7941\n",
      "\n",
      "Epoch 00082: val_dice_coef did not improve from 0.83144\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7111 - dice_coef: 0.7976 - val_loss: -0.7319 - val_dice_coef: 0.8149\n",
      "\n",
      "Epoch 00083: val_dice_coef did not improve from 0.83144\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.7112 - dice_coef: 0.7970 - val_loss: -0.7274 - val_dice_coef: 0.8131\n",
      "\n",
      "Epoch 00084: val_dice_coef did not improve from 0.83144\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7130 - dice_coef: 0.7991 - val_loss: -0.7398 - val_dice_coef: 0.7923\n",
      "\n",
      "Epoch 00085: val_dice_coef did not improve from 0.83144\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 470ms/step - loss: -0.7126 - dice_coef: 0.7976 - val_loss: -0.7771 - val_dice_coef: 0.8438\n",
      "\n",
      "Epoch 00086: val_dice_coef improved from 0.83144 to 0.84377, saving model to /kaggle/working/output_model/unet_3.h5\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.7132 - dice_coef: 0.7984 - val_loss: -0.7581 - val_dice_coef: 0.8299\n",
      "\n",
      "Epoch 00087: val_dice_coef did not improve from 0.84377\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 461ms/step - loss: -0.7125 - dice_coef: 0.7986 - val_loss: -0.7525 - val_dice_coef: 0.8109\n",
      "\n",
      "Epoch 00088: val_dice_coef did not improve from 0.84377\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7111 - dice_coef: 0.7967 - val_loss: -0.7217 - val_dice_coef: 0.8091\n",
      "\n",
      "Epoch 00089: val_dice_coef did not improve from 0.84377\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 14s 441ms/step - loss: -0.7125 - dice_coef: 0.7983 - val_loss: -0.7207 - val_dice_coef: 0.7994\n",
      "\n",
      "Epoch 00090: val_dice_coef did not improve from 0.84377\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.7156 - dice_coef: 0.7995 - val_loss: -0.7157 - val_dice_coef: 0.7914\n",
      "\n",
      "Epoch 00091: val_dice_coef did not improve from 0.84377\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.7134 - dice_coef: 0.7985 - val_loss: -0.7308 - val_dice_coef: 0.8146\n",
      "\n",
      "Epoch 00092: val_dice_coef did not improve from 0.84377\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 467ms/step - loss: -0.7142 - dice_coef: 0.7985 - val_loss: -0.7269 - val_dice_coef: 0.8135\n",
      "\n",
      "Epoch 00093: val_dice_coef did not improve from 0.84377\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.7148 - dice_coef: 0.7998 - val_loss: -0.7269 - val_dice_coef: 0.7826\n",
      "\n",
      "Epoch 00094: val_dice_coef did not improve from 0.84377\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.7158 - dice_coef: 0.7995 - val_loss: -0.7671 - val_dice_coef: 0.8377\n",
      "\n",
      "Epoch 00095: val_dice_coef did not improve from 0.84377\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 454ms/step - loss: -0.7100 - dice_coef: 0.7969 - val_loss: -0.7606 - val_dice_coef: 0.8307\n",
      "\n",
      "Epoch 00096: val_dice_coef did not improve from 0.84377\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.7147 - dice_coef: 0.7997 - val_loss: -0.7508 - val_dice_coef: 0.8104\n",
      "\n",
      "Epoch 00097: val_dice_coef did not improve from 0.84377\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.7115 - dice_coef: 0.7963 - val_loss: -0.6997 - val_dice_coef: 0.7945\n",
      "\n",
      "Epoch 00098: val_dice_coef did not improve from 0.84377\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 450ms/step - loss: -0.7125 - dice_coef: 0.7983 - val_loss: -0.7337 - val_dice_coef: 0.8079\n",
      "\n",
      "Epoch 00099: val_dice_coef did not improve from 0.84377\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 450ms/step - loss: -0.7183 - dice_coef: 0.8016 - val_loss: -0.7145 - val_dice_coef: 0.7901\n",
      "\n",
      "Epoch 00100: val_dice_coef did not improve from 0.84377\n",
      "133/133 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:56<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold3: 78.24\n",
      "average AJI pure Unet for fold3: 43.77\n",
      "average PQ pure Unet for fold3: 42.02\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold3: 78.24\n",
      "average AJI Unet watershed for fold3: 48.80\n",
      "average PQ Unet watershed for fold3: 39.31\n",
      "==========\n",
      "average Dice Unet watershed wo vague for fold3: 79.01\n",
      "average AJI Unet watershed wo vague for fold3: 50.34\n",
      "average PQ Unet watershed wo vague for fold3: 40.55\n",
      "==========\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 18s 484ms/step - loss: -0.0339 - dice_coef: 0.2479 - val_loss: -0.2103 - val_dice_coef: 0.3587\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.35870, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 479ms/step - loss: -0.1642 - dice_coef: 0.3666 - val_loss: -0.0704 - val_dice_coef: 0.3228\n",
      "\n",
      "Epoch 00002: val_dice_coef did not improve from 0.35870\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.2324 - dice_coef: 0.4258 - val_loss: -0.3078 - val_dice_coef: 0.4566\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.35870 to 0.45660, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.2601 - dice_coef: 0.4637 - val_loss: -0.3672 - val_dice_coef: 0.5121\n",
      "\n",
      "Epoch 00004: val_dice_coef improved from 0.45660 to 0.51211, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 456ms/step - loss: -0.2993 - dice_coef: 0.4808 - val_loss: -0.1933 - val_dice_coef: 0.5238\n",
      "\n",
      "Epoch 00005: val_dice_coef improved from 0.51211 to 0.52383, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.2977 - dice_coef: 0.4976 - val_loss: -0.2667 - val_dice_coef: 0.4049\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve from 0.52383\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.3645 - dice_coef: 0.5455 - val_loss: -0.4589 - val_dice_coef: 0.6104\n",
      "\n",
      "Epoch 00007: val_dice_coef improved from 0.52383 to 0.61042, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 493ms/step - loss: -0.4008 - dice_coef: 0.5756 - val_loss: -0.4188 - val_dice_coef: 0.5713\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve from 0.61042\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 486ms/step - loss: -0.4555 - dice_coef: 0.6183 - val_loss: -0.4985 - val_dice_coef: 0.6137\n",
      "\n",
      "Epoch 00009: val_dice_coef improved from 0.61042 to 0.61366, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 21s 641ms/step - loss: -0.4299 - dice_coef: 0.5966 - val_loss: -0.5578 - val_dice_coef: 0.6628\n",
      "\n",
      "Epoch 00010: val_dice_coef improved from 0.61366 to 0.66283, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 18s 570ms/step - loss: -0.4693 - dice_coef: 0.6260 - val_loss: -0.4969 - val_dice_coef: 0.6292\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve from 0.66283\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 18s 539ms/step - loss: -0.4908 - dice_coef: 0.6464 - val_loss: -0.5209 - val_dice_coef: 0.6037\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve from 0.66283\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 499ms/step - loss: -0.4990 - dice_coef: 0.6470 - val_loss: -0.5246 - val_dice_coef: 0.6412\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve from 0.66283\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.5296 - dice_coef: 0.6692 - val_loss: -0.5386 - val_dice_coef: 0.6919\n",
      "\n",
      "Epoch 00014: val_dice_coef improved from 0.66283 to 0.69192, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 484ms/step - loss: -0.5372 - dice_coef: 0.6768 - val_loss: -0.4007 - val_dice_coef: 0.5472\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve from 0.69192\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 16s 478ms/step - loss: -0.5580 - dice_coef: 0.6896 - val_loss: -0.6140 - val_dice_coef: 0.7335\n",
      "\n",
      "Epoch 00016: val_dice_coef improved from 0.69192 to 0.73355, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 537ms/step - loss: -0.5422 - dice_coef: 0.6825 - val_loss: -0.4547 - val_dice_coef: 0.5880\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve from 0.73355\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.5398 - dice_coef: 0.6771 - val_loss: -0.5818 - val_dice_coef: 0.6880\n",
      "\n",
      "Epoch 00018: val_dice_coef did not improve from 0.73355\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.5692 - dice_coef: 0.6998 - val_loss: -0.6677 - val_dice_coef: 0.7567\n",
      "\n",
      "Epoch 00019: val_dice_coef improved from 0.73355 to 0.75670, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.5840 - dice_coef: 0.7094 - val_loss: -0.5648 - val_dice_coef: 0.7054\n",
      "\n",
      "Epoch 00020: val_dice_coef did not improve from 0.75670\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.5918 - dice_coef: 0.7139 - val_loss: -0.6478 - val_dice_coef: 0.7204\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve from 0.75670\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.5922 - dice_coef: 0.7172 - val_loss: -0.6338 - val_dice_coef: 0.7289\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve from 0.75670\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.6056 - dice_coef: 0.7269 - val_loss: -0.5297 - val_dice_coef: 0.6980\n",
      "\n",
      "Epoch 00023: val_dice_coef did not improve from 0.75670\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.6262 - dice_coef: 0.7411 - val_loss: -0.5252 - val_dice_coef: 0.6563\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve from 0.75670\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.6176 - dice_coef: 0.7362 - val_loss: -0.6562 - val_dice_coef: 0.7658\n",
      "\n",
      "Epoch 00025: val_dice_coef improved from 0.75670 to 0.76581, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.6310 - dice_coef: 0.7439 - val_loss: -0.5799 - val_dice_coef: 0.6975\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve from 0.76581\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.6520 - dice_coef: 0.7577 - val_loss: -0.6782 - val_dice_coef: 0.7609\n",
      "\n",
      "Epoch 00027: val_dice_coef did not improve from 0.76581\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.6524 - dice_coef: 0.7595 - val_loss: -0.7167 - val_dice_coef: 0.7922\n",
      "\n",
      "Epoch 00028: val_dice_coef improved from 0.76581 to 0.79217, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.6554 - dice_coef: 0.7608 - val_loss: -0.6371 - val_dice_coef: 0.7484\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve from 0.79217\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.6579 - dice_coef: 0.7614 - val_loss: -0.7239 - val_dice_coef: 0.7845\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve from 0.79217\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 465ms/step - loss: -0.6610 - dice_coef: 0.7642 - val_loss: -0.6997 - val_dice_coef: 0.7819\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve from 0.79217\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.6687 - dice_coef: 0.7704 - val_loss: -0.6048 - val_dice_coef: 0.7435\n",
      "\n",
      "Epoch 00032: val_dice_coef did not improve from 0.79217\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.6763 - dice_coef: 0.7739 - val_loss: -0.6077 - val_dice_coef: 0.7066\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve from 0.79217\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.6733 - dice_coef: 0.7717 - val_loss: -0.6926 - val_dice_coef: 0.7917\n",
      "\n",
      "Epoch 00034: val_dice_coef did not improve from 0.79217\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 17s 515ms/step - loss: -0.6662 - dice_coef: 0.7670 - val_loss: -0.6857 - val_dice_coef: 0.7719\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve from 0.79217\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.6870 - dice_coef: 0.7818 - val_loss: -0.7045 - val_dice_coef: 0.7842\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve from 0.79217\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 470ms/step - loss: -0.6942 - dice_coef: 0.7861 - val_loss: -0.7547 - val_dice_coef: 0.8222\n",
      "\n",
      "Epoch 00037: val_dice_coef improved from 0.79217 to 0.82223, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 476ms/step - loss: -0.6961 - dice_coef: 0.7876 - val_loss: -0.6724 - val_dice_coef: 0.7766\n",
      "\n",
      "Epoch 00038: val_dice_coef did not improve from 0.82223\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.6869 - dice_coef: 0.7817 - val_loss: -0.7271 - val_dice_coef: 0.7890\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve from 0.82223\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 16s 481ms/step - loss: -0.6965 - dice_coef: 0.7884 - val_loss: -0.7217 - val_dice_coef: 0.7953\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve from 0.82223\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 466ms/step - loss: -0.7022 - dice_coef: 0.7928 - val_loss: -0.6608 - val_dice_coef: 0.7847\n",
      "\n",
      "Epoch 00041: val_dice_coef did not improve from 0.82223\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.7073 - dice_coef: 0.7953 - val_loss: -0.7264 - val_dice_coef: 0.7946\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve from 0.82223\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 475ms/step - loss: -0.7102 - dice_coef: 0.7982 - val_loss: -0.7188 - val_dice_coef: 0.8079\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve from 0.82223\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 488ms/step - loss: -0.7057 - dice_coef: 0.7940 - val_loss: -0.7178 - val_dice_coef: 0.7926\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve from 0.82223\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.7061 - dice_coef: 0.7953 - val_loss: -0.7234 - val_dice_coef: 0.7938\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve from 0.82223\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.7109 - dice_coef: 0.7984 - val_loss: -0.7578 - val_dice_coef: 0.8250\n",
      "\n",
      "Epoch 00046: val_dice_coef improved from 0.82223 to 0.82497, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 476ms/step - loss: -0.7152 - dice_coef: 0.8003 - val_loss: -0.7122 - val_dice_coef: 0.7988\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve from 0.82497\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 532ms/step - loss: -0.7189 - dice_coef: 0.8036 - val_loss: -0.7310 - val_dice_coef: 0.7934\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve from 0.82497\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 491ms/step - loss: -0.7055 - dice_coef: 0.7951 - val_loss: -0.7359 - val_dice_coef: 0.8072\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve from 0.82497\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 515ms/step - loss: -0.7155 - dice_coef: 0.8014 - val_loss: -0.6655 - val_dice_coef: 0.7927\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve from 0.82497\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 508ms/step - loss: -0.7148 - dice_coef: 0.8011 - val_loss: -0.7286 - val_dice_coef: 0.7964\n",
      "\n",
      "Epoch 00051: val_dice_coef did not improve from 0.82497\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 496ms/step - loss: -0.7093 - dice_coef: 0.7971 - val_loss: -0.7079 - val_dice_coef: 0.8053\n",
      "\n",
      "Epoch 00052: val_dice_coef did not improve from 0.82497\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 488ms/step - loss: -0.7165 - dice_coef: 0.8016 - val_loss: -0.7187 - val_dice_coef: 0.7990\n",
      "\n",
      "Epoch 00053: val_dice_coef did not improve from 0.82497\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.7140 - dice_coef: 0.7992 - val_loss: -0.7124 - val_dice_coef: 0.7930\n",
      "\n",
      "Epoch 00054: val_dice_coef did not improve from 0.82497\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 494ms/step - loss: -0.7233 - dice_coef: 0.8064 - val_loss: -0.7609 - val_dice_coef: 0.8290\n",
      "\n",
      "Epoch 00055: val_dice_coef improved from 0.82497 to 0.82896, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 486ms/step - loss: -0.7177 - dice_coef: 0.8035 - val_loss: -0.7131 - val_dice_coef: 0.8008\n",
      "\n",
      "Epoch 00056: val_dice_coef did not improve from 0.82896\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 497ms/step - loss: -0.7219 - dice_coef: 0.8060 - val_loss: -0.7451 - val_dice_coef: 0.8035\n",
      "\n",
      "Epoch 00057: val_dice_coef did not improve from 0.82896\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 483ms/step - loss: -0.7165 - dice_coef: 0.8022 - val_loss: -0.7322 - val_dice_coef: 0.8055\n",
      "\n",
      "Epoch 00058: val_dice_coef did not improve from 0.82896\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 507ms/step - loss: -0.7214 - dice_coef: 0.8059 - val_loss: -0.6676 - val_dice_coef: 0.7901\n",
      "\n",
      "Epoch 00059: val_dice_coef did not improve from 0.82896\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 495ms/step - loss: -0.7126 - dice_coef: 0.7996 - val_loss: -0.7255 - val_dice_coef: 0.7918\n",
      "\n",
      "Epoch 00060: val_dice_coef did not improve from 0.82896\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 503ms/step - loss: -0.7258 - dice_coef: 0.8087 - val_loss: -0.7220 - val_dice_coef: 0.8109\n",
      "\n",
      "Epoch 00061: val_dice_coef did not improve from 0.82896\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 499ms/step - loss: -0.7262 - dice_coef: 0.8083 - val_loss: -0.7253 - val_dice_coef: 0.8009\n",
      "\n",
      "Epoch 00062: val_dice_coef did not improve from 0.82896\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 511ms/step - loss: -0.7234 - dice_coef: 0.8073 - val_loss: -0.7241 - val_dice_coef: 0.7978\n",
      "\n",
      "Epoch 00063: val_dice_coef did not improve from 0.82896\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 514ms/step - loss: -0.7216 - dice_coef: 0.8048 - val_loss: -0.7563 - val_dice_coef: 0.8248\n",
      "\n",
      "Epoch 00064: val_dice_coef did not improve from 0.82896\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 515ms/step - loss: -0.7220 - dice_coef: 0.8062 - val_loss: -0.7154 - val_dice_coef: 0.8019\n",
      "\n",
      "Epoch 00065: val_dice_coef did not improve from 0.82896\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 500ms/step - loss: -0.7267 - dice_coef: 0.8100 - val_loss: -0.7326 - val_dice_coef: 0.7945\n",
      "\n",
      "Epoch 00066: val_dice_coef did not improve from 0.82896\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 520ms/step - loss: -0.7251 - dice_coef: 0.8071 - val_loss: -0.7426 - val_dice_coef: 0.8130\n",
      "\n",
      "Epoch 00067: val_dice_coef did not improve from 0.82896\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 501ms/step - loss: -0.7250 - dice_coef: 0.8077 - val_loss: -0.6756 - val_dice_coef: 0.7958\n",
      "\n",
      "Epoch 00068: val_dice_coef did not improve from 0.82896\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 530ms/step - loss: -0.7274 - dice_coef: 0.8086 - val_loss: -0.7393 - val_dice_coef: 0.8023\n",
      "\n",
      "Epoch 00069: val_dice_coef did not improve from 0.82896\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 17s 514ms/step - loss: -0.7294 - dice_coef: 0.8107 - val_loss: -0.7255 - val_dice_coef: 0.8146\n",
      "\n",
      "Epoch 00070: val_dice_coef did not improve from 0.82896\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 507ms/step - loss: -0.7294 - dice_coef: 0.8099 - val_loss: -0.7340 - val_dice_coef: 0.8045\n",
      "\n",
      "Epoch 00071: val_dice_coef did not improve from 0.82896\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.7261 - dice_coef: 0.8080 - val_loss: -0.7337 - val_dice_coef: 0.8032\n",
      "\n",
      "Epoch 00072: val_dice_coef did not improve from 0.82896\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.7293 - dice_coef: 0.8111 - val_loss: -0.7674 - val_dice_coef: 0.8321\n",
      "\n",
      "Epoch 00073: val_dice_coef improved from 0.82896 to 0.83207, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 479ms/step - loss: -0.7266 - dice_coef: 0.8085 - val_loss: -0.7241 - val_dice_coef: 0.8085\n",
      "\n",
      "Epoch 00074: val_dice_coef did not improve from 0.83207\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 498ms/step - loss: -0.7268 - dice_coef: 0.8091 - val_loss: -0.7540 - val_dice_coef: 0.8101\n",
      "\n",
      "Epoch 00075: val_dice_coef did not improve from 0.83207\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 469ms/step - loss: -0.7290 - dice_coef: 0.8107 - val_loss: -0.7416 - val_dice_coef: 0.8114\n",
      "\n",
      "Epoch 00076: val_dice_coef did not improve from 0.83207\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 471ms/step - loss: -0.7303 - dice_coef: 0.8118 - val_loss: -0.6863 - val_dice_coef: 0.8027\n",
      "\n",
      "Epoch 00077: val_dice_coef did not improve from 0.83207\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.7324 - dice_coef: 0.8120 - val_loss: -0.7436 - val_dice_coef: 0.8069\n",
      "\n",
      "Epoch 00078: val_dice_coef did not improve from 0.83207\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 480ms/step - loss: -0.7294 - dice_coef: 0.8114 - val_loss: -0.7173 - val_dice_coef: 0.8105\n",
      "\n",
      "Epoch 00079: val_dice_coef did not improve from 0.83207\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.7331 - dice_coef: 0.8135 - val_loss: -0.7276 - val_dice_coef: 0.8043\n",
      "\n",
      "Epoch 00080: val_dice_coef did not improve from 0.83207\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.7344 - dice_coef: 0.8138 - val_loss: -0.7388 - val_dice_coef: 0.8094\n",
      "\n",
      "Epoch 00081: val_dice_coef did not improve from 0.83207\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 500ms/step - loss: -0.7362 - dice_coef: 0.8153 - val_loss: -0.7624 - val_dice_coef: 0.8315\n",
      "\n",
      "Epoch 00082: val_dice_coef did not improve from 0.83207\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 488ms/step - loss: -0.7305 - dice_coef: 0.8118 - val_loss: -0.7297 - val_dice_coef: 0.8133\n",
      "\n",
      "Epoch 00083: val_dice_coef did not improve from 0.83207\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 499ms/step - loss: -0.7350 - dice_coef: 0.8146 - val_loss: -0.7449 - val_dice_coef: 0.8046\n",
      "\n",
      "Epoch 00084: val_dice_coef did not improve from 0.83207\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 468ms/step - loss: -0.7353 - dice_coef: 0.8142 - val_loss: -0.7442 - val_dice_coef: 0.8170\n",
      "\n",
      "Epoch 00085: val_dice_coef did not improve from 0.83207\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 473ms/step - loss: -0.7345 - dice_coef: 0.8148 - val_loss: -0.6831 - val_dice_coef: 0.8033\n",
      "\n",
      "Epoch 00086: val_dice_coef did not improve from 0.83207\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.7344 - dice_coef: 0.8132 - val_loss: -0.7456 - val_dice_coef: 0.8082\n",
      "\n",
      "Epoch 00087: val_dice_coef did not improve from 0.83207\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 486ms/step - loss: -0.7365 - dice_coef: 0.8144 - val_loss: -0.7334 - val_dice_coef: 0.8208\n",
      "\n",
      "Epoch 00088: val_dice_coef did not improve from 0.83207\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 491ms/step - loss: -0.7371 - dice_coef: 0.8154 - val_loss: -0.7375 - val_dice_coef: 0.8091\n",
      "\n",
      "Epoch 00089: val_dice_coef did not improve from 0.83207\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 481ms/step - loss: -0.7327 - dice_coef: 0.8133 - val_loss: -0.7355 - val_dice_coef: 0.8057\n",
      "\n",
      "Epoch 00090: val_dice_coef did not improve from 0.83207\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 470ms/step - loss: -0.7325 - dice_coef: 0.8129 - val_loss: -0.7707 - val_dice_coef: 0.8349\n",
      "\n",
      "Epoch 00091: val_dice_coef improved from 0.83207 to 0.83492, saving model to /kaggle/working/output_model/unet_4.h5\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.7335 - dice_coef: 0.8140 - val_loss: -0.7276 - val_dice_coef: 0.8115\n",
      "\n",
      "Epoch 00092: val_dice_coef did not improve from 0.83492\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 482ms/step - loss: -0.7366 - dice_coef: 0.8156 - val_loss: -0.7525 - val_dice_coef: 0.8090\n",
      "\n",
      "Epoch 00093: val_dice_coef did not improve from 0.83492\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.7382 - dice_coef: 0.8167 - val_loss: -0.7429 - val_dice_coef: 0.8142\n",
      "\n",
      "Epoch 00094: val_dice_coef did not improve from 0.83492\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 474ms/step - loss: -0.7378 - dice_coef: 0.8167 - val_loss: -0.6763 - val_dice_coef: 0.7991\n",
      "\n",
      "Epoch 00095: val_dice_coef did not improve from 0.83492\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.7368 - dice_coef: 0.8160 - val_loss: -0.7485 - val_dice_coef: 0.8100\n",
      "\n",
      "Epoch 00096: val_dice_coef did not improve from 0.83492\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 16s 482ms/step - loss: -0.7360 - dice_coef: 0.8152 - val_loss: -0.7254 - val_dice_coef: 0.8153\n",
      "\n",
      "Epoch 00097: val_dice_coef did not improve from 0.83492\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.7378 - dice_coef: 0.8163 - val_loss: -0.7342 - val_dice_coef: 0.8068\n",
      "\n",
      "Epoch 00098: val_dice_coef did not improve from 0.83492\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.7388 - dice_coef: 0.8173 - val_loss: -0.7309 - val_dice_coef: 0.8036\n",
      "\n",
      "Epoch 00099: val_dice_coef did not improve from 0.83492\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 15s 464ms/step - loss: -0.7388 - dice_coef: 0.8174 - val_loss: -0.7650 - val_dice_coef: 0.8320\n",
      "\n",
      "Epoch 00100: val_dice_coef did not improve from 0.83492\n",
      "133/133 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:02<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold4: 77.30\n",
      "average AJI pure Unet for fold4: 40.21\n",
      "average PQ pure Unet for fold4: 39.69\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold4: 77.30\n",
      "average AJI Unet watershed for fold4: 45.19\n",
      "average PQ Unet watershed for fold4: 36.13\n",
      "==========\n",
      "average Dice Unet watershed wo vague for fold4: 78.52\n",
      "average AJI Unet watershed wo vague for fold4: 47.21\n",
      "average PQ Unet watershed wo vague for fold4: 38.22\n",
      "==========\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 481ms/step - loss: -0.0154 - dice_coef: 0.2411 - val_loss: -0.1417 - val_dice_coef: 0.3122\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.31216, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 477ms/step - loss: -0.1685 - dice_coef: 0.3555 - val_loss: -0.1587 - val_dice_coef: 0.3980\n",
      "\n",
      "Epoch 00002: val_dice_coef improved from 0.31216 to 0.39797, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 445ms/step - loss: -0.2437 - dice_coef: 0.4405 - val_loss: -0.1559 - val_dice_coef: 0.4184\n",
      "\n",
      "Epoch 00003: val_dice_coef improved from 0.39797 to 0.41839, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 436ms/step - loss: -0.2885 - dice_coef: 0.4767 - val_loss: -0.2415 - val_dice_coef: 0.4042\n",
      "\n",
      "Epoch 00004: val_dice_coef did not improve from 0.41839\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.3529 - dice_coef: 0.5392 - val_loss: -0.3591 - val_dice_coef: 0.5501\n",
      "\n",
      "Epoch 00005: val_dice_coef improved from 0.41839 to 0.55010, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 449ms/step - loss: -0.3488 - dice_coef: 0.5290 - val_loss: -0.3162 - val_dice_coef: 0.4783\n",
      "\n",
      "Epoch 00006: val_dice_coef did not improve from 0.55010\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 450ms/step - loss: -0.3713 - dice_coef: 0.5379 - val_loss: -0.5071 - val_dice_coef: 0.6250\n",
      "\n",
      "Epoch 00007: val_dice_coef improved from 0.55010 to 0.62502, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 453ms/step - loss: -0.3800 - dice_coef: 0.5501 - val_loss: -0.4294 - val_dice_coef: 0.5667\n",
      "\n",
      "Epoch 00008: val_dice_coef did not improve from 0.62502\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 437ms/step - loss: -0.4114 - dice_coef: 0.5802 - val_loss: -0.5188 - val_dice_coef: 0.6567\n",
      "\n",
      "Epoch 00009: val_dice_coef improved from 0.62502 to 0.65671, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 438ms/step - loss: -0.4300 - dice_coef: 0.5878 - val_loss: -0.4984 - val_dice_coef: 0.6253\n",
      "\n",
      "Epoch 00010: val_dice_coef did not improve from 0.65671\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 17s 521ms/step - loss: -0.4374 - dice_coef: 0.6032 - val_loss: -0.4297 - val_dice_coef: 0.6030\n",
      "\n",
      "Epoch 00011: val_dice_coef did not improve from 0.65671\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 440ms/step - loss: -0.4618 - dice_coef: 0.6135 - val_loss: -0.4202 - val_dice_coef: 0.5655\n",
      "\n",
      "Epoch 00012: val_dice_coef did not improve from 0.65671\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 15s 457ms/step - loss: -0.4883 - dice_coef: 0.6335 - val_loss: -0.5098 - val_dice_coef: 0.6231\n",
      "\n",
      "Epoch 00013: val_dice_coef did not improve from 0.65671\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 439ms/step - loss: -0.5186 - dice_coef: 0.6615 - val_loss: -0.5456 - val_dice_coef: 0.6655\n",
      "\n",
      "Epoch 00014: val_dice_coef improved from 0.65671 to 0.66550, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 433ms/step - loss: -0.5339 - dice_coef: 0.6703 - val_loss: -0.5310 - val_dice_coef: 0.6400\n",
      "\n",
      "Epoch 00015: val_dice_coef did not improve from 0.66550\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 432ms/step - loss: -0.5192 - dice_coef: 0.6517 - val_loss: -0.5701 - val_dice_coef: 0.6755\n",
      "\n",
      "Epoch 00016: val_dice_coef improved from 0.66550 to 0.67552, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 444ms/step - loss: -0.5656 - dice_coef: 0.6926 - val_loss: -0.5208 - val_dice_coef: 0.6548\n",
      "\n",
      "Epoch 00017: val_dice_coef did not improve from 0.67552\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 425ms/step - loss: -0.5595 - dice_coef: 0.6882 - val_loss: -0.5785 - val_dice_coef: 0.7122\n",
      "\n",
      "Epoch 00018: val_dice_coef improved from 0.67552 to 0.71224, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 443ms/step - loss: -0.5874 - dice_coef: 0.7095 - val_loss: -0.6218 - val_dice_coef: 0.7289\n",
      "\n",
      "Epoch 00019: val_dice_coef improved from 0.71224 to 0.72888, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "33/33 [==============================] - 14s 440ms/step - loss: -0.5925 - dice_coef: 0.7108 - val_loss: -0.6124 - val_dice_coef: 0.7399\n",
      "\n",
      "Epoch 00020: val_dice_coef improved from 0.72888 to 0.73990, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 427ms/step - loss: -0.5927 - dice_coef: 0.7112 - val_loss: -0.5763 - val_dice_coef: 0.6892\n",
      "\n",
      "Epoch 00021: val_dice_coef did not improve from 0.73990\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 472ms/step - loss: -0.6097 - dice_coef: 0.7253 - val_loss: -0.6432 - val_dice_coef: 0.7263\n",
      "\n",
      "Epoch 00022: val_dice_coef did not improve from 0.73990\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 418ms/step - loss: -0.6268 - dice_coef: 0.7367 - val_loss: -0.6677 - val_dice_coef: 0.7697\n",
      "\n",
      "Epoch 00023: val_dice_coef improved from 0.73990 to 0.76965, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 429ms/step - loss: -0.6250 - dice_coef: 0.7340 - val_loss: -0.6256 - val_dice_coef: 0.7180\n",
      "\n",
      "Epoch 00024: val_dice_coef did not improve from 0.76965\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.6349 - dice_coef: 0.7430 - val_loss: -0.6527 - val_dice_coef: 0.7484\n",
      "\n",
      "Epoch 00025: val_dice_coef did not improve from 0.76965\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 432ms/step - loss: -0.6317 - dice_coef: 0.7406 - val_loss: -0.6328 - val_dice_coef: 0.7364\n",
      "\n",
      "Epoch 00026: val_dice_coef did not improve from 0.76965\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 447ms/step - loss: -0.6166 - dice_coef: 0.7279 - val_loss: -0.6622 - val_dice_coef: 0.7755\n",
      "\n",
      "Epoch 00027: val_dice_coef improved from 0.76965 to 0.77545, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 426ms/step - loss: -0.6472 - dice_coef: 0.7511 - val_loss: -0.6479 - val_dice_coef: 0.7501\n",
      "\n",
      "Epoch 00028: val_dice_coef did not improve from 0.77545\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 462ms/step - loss: -0.6550 - dice_coef: 0.7576 - val_loss: -0.6342 - val_dice_coef: 0.7545\n",
      "\n",
      "Epoch 00029: val_dice_coef did not improve from 0.77545\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 445ms/step - loss: -0.6529 - dice_coef: 0.7534 - val_loss: -0.6715 - val_dice_coef: 0.7547\n",
      "\n",
      "Epoch 00030: val_dice_coef did not improve from 0.77545\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 432ms/step - loss: -0.6412 - dice_coef: 0.7468 - val_loss: -0.6664 - val_dice_coef: 0.7532\n",
      "\n",
      "Epoch 00031: val_dice_coef did not improve from 0.77545\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 441ms/step - loss: -0.6517 - dice_coef: 0.7554 - val_loss: -0.6693 - val_dice_coef: 0.7829\n",
      "\n",
      "Epoch 00032: val_dice_coef improved from 0.77545 to 0.78293, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 435ms/step - loss: -0.6662 - dice_coef: 0.7663 - val_loss: -0.6804 - val_dice_coef: 0.7649\n",
      "\n",
      "Epoch 00033: val_dice_coef did not improve from 0.78293\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 447ms/step - loss: -0.6714 - dice_coef: 0.7690 - val_loss: -0.6963 - val_dice_coef: 0.7842\n",
      "\n",
      "Epoch 00034: val_dice_coef improved from 0.78293 to 0.78425, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 444ms/step - loss: -0.6606 - dice_coef: 0.7608 - val_loss: -0.6646 - val_dice_coef: 0.7624\n",
      "\n",
      "Epoch 00035: val_dice_coef did not improve from 0.78425\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 455ms/step - loss: -0.6661 - dice_coef: 0.7656 - val_loss: -0.6046 - val_dice_coef: 0.7530\n",
      "\n",
      "Epoch 00036: val_dice_coef did not improve from 0.78425\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 453ms/step - loss: -0.6704 - dice_coef: 0.7690 - val_loss: -0.6663 - val_dice_coef: 0.7745\n",
      "\n",
      "Epoch 00037: val_dice_coef did not improve from 0.78425\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 432ms/step - loss: -0.6801 - dice_coef: 0.7757 - val_loss: -0.6779 - val_dice_coef: 0.7862\n",
      "\n",
      "Epoch 00038: val_dice_coef improved from 0.78425 to 0.78618, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.6845 - dice_coef: 0.7794 - val_loss: -0.6890 - val_dice_coef: 0.7796\n",
      "\n",
      "Epoch 00039: val_dice_coef did not improve from 0.78618\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005.\n",
      "33/33 [==============================] - 14s 437ms/step - loss: -0.6861 - dice_coef: 0.7803 - val_loss: -0.6971 - val_dice_coef: 0.7777\n",
      "\n",
      "Epoch 00040: val_dice_coef did not improve from 0.78618\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 434ms/step - loss: -0.6931 - dice_coef: 0.7851 - val_loss: -0.7611 - val_dice_coef: 0.8385\n",
      "\n",
      "Epoch 00041: val_dice_coef improved from 0.78618 to 0.83851, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 446ms/step - loss: -0.6986 - dice_coef: 0.7883 - val_loss: -0.6966 - val_dice_coef: 0.7802\n",
      "\n",
      "Epoch 00042: val_dice_coef did not improve from 0.83851\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.6957 - dice_coef: 0.7857 - val_loss: -0.7164 - val_dice_coef: 0.7971\n",
      "\n",
      "Epoch 00043: val_dice_coef did not improve from 0.83851\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 459ms/step - loss: -0.6995 - dice_coef: 0.7899 - val_loss: -0.6980 - val_dice_coef: 0.7843\n",
      "\n",
      "Epoch 00044: val_dice_coef did not improve from 0.83851\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 419ms/step - loss: -0.6958 - dice_coef: 0.7865 - val_loss: -0.7190 - val_dice_coef: 0.8167\n",
      "\n",
      "Epoch 00045: val_dice_coef did not improve from 0.83851\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.6948 - dice_coef: 0.7847 - val_loss: -0.7018 - val_dice_coef: 0.7877\n",
      "\n",
      "Epoch 00046: val_dice_coef did not improve from 0.83851\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 444ms/step - loss: -0.7066 - dice_coef: 0.7947 - val_loss: -0.6929 - val_dice_coef: 0.7927\n",
      "\n",
      "Epoch 00047: val_dice_coef did not improve from 0.83851\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 425ms/step - loss: -0.7003 - dice_coef: 0.7901 - val_loss: -0.7127 - val_dice_coef: 0.7886\n",
      "\n",
      "Epoch 00048: val_dice_coef did not improve from 0.83851\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.7020 - dice_coef: 0.7912 - val_loss: -0.7117 - val_dice_coef: 0.7823\n",
      "\n",
      "Epoch 00049: val_dice_coef did not improve from 0.83851\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 428ms/step - loss: -0.7027 - dice_coef: 0.7911 - val_loss: -0.7648 - val_dice_coef: 0.8382\n",
      "\n",
      "Epoch 00050: val_dice_coef did not improve from 0.83851\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.7041 - dice_coef: 0.7923 - val_loss: -0.7086 - val_dice_coef: 0.7852\n",
      "\n",
      "Epoch 00051: val_dice_coef did not improve from 0.83851\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 460ms/step - loss: -0.7033 - dice_coef: 0.7912 - val_loss: -0.7178 - val_dice_coef: 0.8013\n",
      "\n",
      "Epoch 00052: val_dice_coef did not improve from 0.83851\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 17s 509ms/step - loss: -0.7065 - dice_coef: 0.7945 - val_loss: -0.7068 - val_dice_coef: 0.7935\n",
      "\n",
      "Epoch 00053: val_dice_coef did not improve from 0.83851\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 432ms/step - loss: -0.6981 - dice_coef: 0.7835 - val_loss: -0.7296 - val_dice_coef: 0.8214\n",
      "\n",
      "Epoch 00054: val_dice_coef did not improve from 0.83851\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 452ms/step - loss: -0.7050 - dice_coef: 0.7932 - val_loss: -0.7095 - val_dice_coef: 0.7951\n",
      "\n",
      "Epoch 00055: val_dice_coef did not improve from 0.83851\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 487ms/step - loss: -0.7079 - dice_coef: 0.7940 - val_loss: -0.6990 - val_dice_coef: 0.7979\n",
      "\n",
      "Epoch 00056: val_dice_coef did not improve from 0.83851\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 16s 503ms/step - loss: -0.7077 - dice_coef: 0.7950 - val_loss: -0.7165 - val_dice_coef: 0.7949\n",
      "\n",
      "Epoch 00057: val_dice_coef did not improve from 0.83851\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 15s 458ms/step - loss: -0.7085 - dice_coef: 0.7946 - val_loss: -0.7279 - val_dice_coef: 0.7967\n",
      "\n",
      "Epoch 00058: val_dice_coef did not improve from 0.83851\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 418ms/step - loss: -0.7128 - dice_coef: 0.7981 - val_loss: -0.7392 - val_dice_coef: 0.8271\n",
      "\n",
      "Epoch 00059: val_dice_coef did not improve from 0.83851\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00025.\n",
      "33/33 [==============================] - 14s 437ms/step - loss: -0.7140 - dice_coef: 0.7999 - val_loss: -0.7211 - val_dice_coef: 0.7958\n",
      "\n",
      "Epoch 00060: val_dice_coef did not improve from 0.83851\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 437ms/step - loss: -0.7147 - dice_coef: 0.7987 - val_loss: -0.7266 - val_dice_coef: 0.8079\n",
      "\n",
      "Epoch 00061: val_dice_coef did not improve from 0.83851\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 431ms/step - loss: -0.7154 - dice_coef: 0.7995 - val_loss: -0.7193 - val_dice_coef: 0.8037\n",
      "\n",
      "Epoch 00062: val_dice_coef did not improve from 0.83851\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 442ms/step - loss: -0.7204 - dice_coef: 0.8032 - val_loss: -0.7335 - val_dice_coef: 0.8299\n",
      "\n",
      "Epoch 00063: val_dice_coef did not improve from 0.83851\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 433ms/step - loss: -0.7192 - dice_coef: 0.8033 - val_loss: -0.7208 - val_dice_coef: 0.8067\n",
      "\n",
      "Epoch 00064: val_dice_coef did not improve from 0.83851\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 454ms/step - loss: -0.7214 - dice_coef: 0.8035 - val_loss: -0.7039 - val_dice_coef: 0.8059\n",
      "\n",
      "Epoch 00065: val_dice_coef did not improve from 0.83851\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 447ms/step - loss: -0.7215 - dice_coef: 0.8042 - val_loss: -0.7445 - val_dice_coef: 0.8151\n",
      "\n",
      "Epoch 00066: val_dice_coef did not improve from 0.83851\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 433ms/step - loss: -0.7202 - dice_coef: 0.8034 - val_loss: -0.7321 - val_dice_coef: 0.8013\n",
      "\n",
      "Epoch 00067: val_dice_coef did not improve from 0.83851\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 463ms/step - loss: -0.7210 - dice_coef: 0.8045 - val_loss: -0.7520 - val_dice_coef: 0.8356\n",
      "\n",
      "Epoch 00068: val_dice_coef did not improve from 0.83851\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 477ms/step - loss: -0.7204 - dice_coef: 0.8029 - val_loss: -0.7344 - val_dice_coef: 0.8044\n",
      "\n",
      "Epoch 00069: val_dice_coef did not improve from 0.83851\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 489ms/step - loss: -0.7195 - dice_coef: 0.8027 - val_loss: -0.7403 - val_dice_coef: 0.8170\n",
      "\n",
      "Epoch 00070: val_dice_coef did not improve from 0.83851\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 446ms/step - loss: -0.7236 - dice_coef: 0.8060 - val_loss: -0.7221 - val_dice_coef: 0.8049\n",
      "\n",
      "Epoch 00071: val_dice_coef did not improve from 0.83851\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 437ms/step - loss: -0.7226 - dice_coef: 0.8043 - val_loss: -0.7352 - val_dice_coef: 0.8308\n",
      "\n",
      "Epoch 00072: val_dice_coef did not improve from 0.83851\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 442ms/step - loss: -0.7241 - dice_coef: 0.8070 - val_loss: -0.7259 - val_dice_coef: 0.8087\n",
      "\n",
      "Epoch 00073: val_dice_coef did not improve from 0.83851\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 441ms/step - loss: -0.7223 - dice_coef: 0.8050 - val_loss: -0.7054 - val_dice_coef: 0.8050\n",
      "\n",
      "Epoch 00074: val_dice_coef did not improve from 0.83851\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 438ms/step - loss: -0.7253 - dice_coef: 0.8072 - val_loss: -0.7528 - val_dice_coef: 0.8202\n",
      "\n",
      "Epoch 00075: val_dice_coef did not improve from 0.83851\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 447ms/step - loss: -0.7245 - dice_coef: 0.8065 - val_loss: -0.7138 - val_dice_coef: 0.7883\n",
      "\n",
      "Epoch 00076: val_dice_coef did not improve from 0.83851\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 14s 434ms/step - loss: -0.7264 - dice_coef: 0.8074 - val_loss: -0.7788 - val_dice_coef: 0.8513\n",
      "\n",
      "Epoch 00077: val_dice_coef improved from 0.83851 to 0.85132, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 447ms/step - loss: -0.7247 - dice_coef: 0.8070 - val_loss: -0.7300 - val_dice_coef: 0.8011\n",
      "\n",
      "Epoch 00078: val_dice_coef did not improve from 0.85132\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 15s 455ms/step - loss: -0.7277 - dice_coef: 0.8087 - val_loss: -0.7446 - val_dice_coef: 0.8193\n",
      "\n",
      "Epoch 00079: val_dice_coef did not improve from 0.85132\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.000125.\n",
      "33/33 [==============================] - 16s 497ms/step - loss: -0.7258 - dice_coef: 0.8072 - val_loss: -0.7243 - val_dice_coef: 0.8045\n",
      "\n",
      "Epoch 00080: val_dice_coef did not improve from 0.85132\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 14s 416ms/step - loss: -0.7267 - dice_coef: 0.8081 - val_loss: -0.7403 - val_dice_coef: 0.8335\n",
      "\n",
      "Epoch 00081: val_dice_coef did not improve from 0.85132\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 20s 622ms/step - loss: -0.7234 - dice_coef: 0.8050 - val_loss: -0.7337 - val_dice_coef: 0.8138\n",
      "\n",
      "Epoch 00082: val_dice_coef did not improve from 0.85132\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 20s 625ms/step - loss: -0.7287 - dice_coef: 0.8096 - val_loss: -0.7143 - val_dice_coef: 0.8111\n",
      "\n",
      "Epoch 00083: val_dice_coef did not improve from 0.85132\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 576ms/step - loss: -0.7277 - dice_coef: 0.8081 - val_loss: -0.7571 - val_dice_coef: 0.8225\n",
      "\n",
      "Epoch 00084: val_dice_coef did not improve from 0.85132\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 21s 649ms/step - loss: -0.7280 - dice_coef: 0.8082 - val_loss: -0.7158 - val_dice_coef: 0.7919\n",
      "\n",
      "Epoch 00085: val_dice_coef did not improve from 0.85132\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 586ms/step - loss: -0.7319 - dice_coef: 0.8112 - val_loss: -0.7896 - val_dice_coef: 0.8601\n",
      "\n",
      "Epoch 00086: val_dice_coef improved from 0.85132 to 0.86007, saving model to /kaggle/working/output_model/unet_5.h5\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 21s 637ms/step - loss: -0.7295 - dice_coef: 0.8104 - val_loss: -0.7249 - val_dice_coef: 0.8018\n",
      "\n",
      "Epoch 00087: val_dice_coef did not improve from 0.86007\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 589ms/step - loss: -0.7298 - dice_coef: 0.8096 - val_loss: -0.7445 - val_dice_coef: 0.8210\n",
      "\n",
      "Epoch 00088: val_dice_coef did not improve from 0.86007\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 571ms/step - loss: -0.7315 - dice_coef: 0.8108 - val_loss: -0.7204 - val_dice_coef: 0.8065\n",
      "\n",
      "Epoch 00089: val_dice_coef did not improve from 0.86007\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 591ms/step - loss: -0.7323 - dice_coef: 0.8116 - val_loss: -0.7418 - val_dice_coef: 0.8347\n",
      "\n",
      "Epoch 00090: val_dice_coef did not improve from 0.86007\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 21s 641ms/step - loss: -0.7319 - dice_coef: 0.8114 - val_loss: -0.7349 - val_dice_coef: 0.8161\n",
      "\n",
      "Epoch 00091: val_dice_coef did not improve from 0.86007\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 598ms/step - loss: -0.7306 - dice_coef: 0.8096 - val_loss: -0.7184 - val_dice_coef: 0.8150\n",
      "\n",
      "Epoch 00092: val_dice_coef did not improve from 0.86007\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 18s 557ms/step - loss: -0.7296 - dice_coef: 0.8098 - val_loss: -0.7598 - val_dice_coef: 0.8257\n",
      "\n",
      "Epoch 00093: val_dice_coef did not improve from 0.86007\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 19s 591ms/step - loss: -0.7326 - dice_coef: 0.8121 - val_loss: -0.7266 - val_dice_coef: 0.7982\n",
      "\n",
      "Epoch 00094: val_dice_coef did not improve from 0.86007\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 17s 525ms/step - loss: -0.7294 - dice_coef: 0.8093 - val_loss: -0.7709 - val_dice_coef: 0.8483\n",
      "\n",
      "Epoch 00095: val_dice_coef did not improve from 0.86007\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 18s 540ms/step - loss: -0.7323 - dice_coef: 0.8112 - val_loss: -0.7422 - val_dice_coef: 0.8116\n",
      "\n",
      "Epoch 00096: val_dice_coef did not improve from 0.86007\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 14s 441ms/step - loss: -0.7346 - dice_coef: 0.8136 - val_loss: -0.7433 - val_dice_coef: 0.8205\n",
      "\n",
      "Epoch 00097: val_dice_coef did not improve from 0.86007\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 18s 540ms/step - loss: -0.7330 - dice_coef: 0.8124 - val_loss: -0.7295 - val_dice_coef: 0.8112\n",
      "\n",
      "Epoch 00098: val_dice_coef did not improve from 0.86007\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 17s 526ms/step - loss: -0.7354 - dice_coef: 0.8134 - val_loss: -0.7414 - val_dice_coef: 0.8359\n",
      "\n",
      "Epoch 00099: val_dice_coef did not improve from 0.86007\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 6.25e-05.\n",
      "33/33 [==============================] - 18s 543ms/step - loss: -0.7340 - dice_coef: 0.8122 - val_loss: -0.7365 - val_dice_coef: 0.8171\n",
      "\n",
      "Epoch 00100: val_dice_coef did not improve from 0.86007\n",
      "133/133 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [01:03<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold5: 80.12\n",
      "average AJI pure Unet for fold5: 41.89\n",
      "average PQ pure Unet for fold5: 41.08\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold5: 80.12\n",
      "average AJI Unet watershed for fold5: 47.71\n",
      "average PQ Unet watershed for fold5: 38.45\n",
      "==========\n",
      "average Dice Unet watershed wo vague for fold5: 80.50\n",
      "average AJI Unet watershed wo vague for fold5: 48.82\n",
      "average PQ Unet watershed wo vague for fold5: 39.29\n",
      "==========\n",
      "  fold num  dice unet  dice unet watershed  dice unet whatershed wo vague\n",
      "0    fold1  79.258900            79.259669                      80.422377\n",
      "1    fold2  75.469342            75.471430                      76.423813\n",
      "2    fold3  78.236050            78.236412                      79.010563\n",
      "3    fold4  77.301335            77.304757                      78.518833\n",
      "4    fold5  80.117941            80.118011                      80.499432\n",
      "============================================================\n",
      "  fold num   AJI unet  AJI unet watershed  AJI unet whatershed wo vague\n",
      "0    fold1  40.372496           46.936730                     48.437906\n",
      "1    fold2  36.700539           44.346094                     45.285126\n",
      "2    fold3  43.769115           48.801826                     50.336507\n",
      "3    fold4  40.209703           45.193877                     47.206462\n",
      "4    fold5  41.886396           47.708692                     48.819021\n",
      "============================================================\n",
      "  fold num    PQ unet  PQ unet watershed  PQ unet whatershed wo vague\n",
      "0    fold1  40.340797          38.139151                    39.099192\n",
      "1    fold2  35.840666          34.155269                    35.249827\n",
      "2    fold3  42.015533          39.312007                    40.552397\n",
      "3    fold4  39.686421          36.125950                    38.217428\n",
      "4    fold5  41.080864          38.447435                    39.288450\n",
      "============================================================\n",
      "==========\n",
      "total training time (all 5 folds): 138.47 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# main training loop (for all k fold cross-validation)\n",
    "kf = KFold(n_splits= opts['k_fold'],random_state= opts['random_seed_num'],shuffle=True)\n",
    "kf.get_n_splits(img_path)\n",
    "\n",
    "start_time = time.time()\n",
    "dice_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "AJI_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "PQ_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "\n",
    "dice_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "AJI_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "PQ_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "dice_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "AJI_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "PQ_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "dice_mean = []\n",
    "aji_mean = []\n",
    "pq_mean = []\n",
    "                   \n",
    "dice_watershed_mean = []\n",
    "aji_watershed_mean = []\n",
    "pq_watershed_mean = []\n",
    "                   \n",
    "dice_watershed_wovague_mean = []\n",
    "aji_watershed_wovague_mean = []\n",
    "pq_watershed_wovague_mean = []\n",
    "\n",
    "current_fold = 1\n",
    "\n",
    "for idx, [train_index,  test_index] in enumerate(kf.split(img_path)):\n",
    "    shuffle(train_index)\n",
    "    shuffle(test_index)\n",
    "\n",
    "    train_img   = [img_path[name] for name in train_index]\n",
    "    train_mask  = [binary_mask_path[name] for name in train_index]\n",
    "    train_dis   = [distance_mask_path[name] for name in train_index]\n",
    "    train_label = [label_mask_path[name] for name in train_index]\n",
    "    \n",
    "    test_img   = [img_path[name] for name in test_index]\n",
    "    test_mask  = [binary_mask_path[name] for name in test_index]\n",
    "    test_dis   = [distance_mask_path[name] for name in test_index]\n",
    "    test_label = [label_mask_path[name] for name in test_index]\n",
    "    test_vague = [vague_mask_path[name] for name in test_index]\n",
    "    \n",
    "    #creating validation set\n",
    "    validation_set_img = []\n",
    "    validation_set_label = []\n",
    "    #validation_DIS = []\n",
    "    validation_set_vague = []\n",
    "    for counter in range(len(test_img)):\n",
    "        val_img = cv2.imread(test_img[counter])\n",
    "        val_img = cv2.cvtColor(val_img, cv2.COLOR_BGR2RGB)\n",
    "        val_img = val_img/255\n",
    "        val_label = cv2.imread(test_label[counter], -1) # cv2.IMREAD_UNCHANGED: \n",
    "        #It specifies to load an image as such including alpha channel. \n",
    "        #Alternatively, we can pass integer value -1 for this flag.\n",
    "        val_vague = cv2.imread(test_vague[counter], -1)\n",
    "        \n",
    "        validation_set_img.append(val_img)\n",
    "        validation_set_label.append(val_label)\n",
    "        validation_set_vague.append(val_vague)\n",
    "        \n",
    "    validation_set_img = np.array(validation_set_img)\n",
    "    validation_set_label = np.array(validation_set_label)\n",
    "    validation_set_vague = np.array(validation_set_vague)\n",
    "    \n",
    "    model_path = opts['model_save_path'] + 'unet_{}.h5'.format(current_fold)\n",
    "    logger = CSVLogger(opts['model_save_path']+ 'unet_{}.log'.format(current_fold))\n",
    "    LR_drop = step_decay_schedule(initial_lr= opts['init_LR'], \n",
    "                              decay_factor = opts['LR_decay_factor'], \n",
    "                              epochs_drop = opts['LR_drop_after_nth_epoch'])\n",
    "    model_raw = shallow_unet(opts['number_of_channel'], opts['init_LR'])\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_dice_coef', verbose=1,\n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "    history = model_raw.fit_generator(data_gen(train_img,\n",
    "                                                 train_mask,\n",
    "                                                 opts['batch_size'],\n",
    "                                                 1,\n",
    "                                                 opts['crop_size'], opts['crop_size'],\n",
    "                                                 distance_unet_flag=0,\n",
    "                                                 augment=True,\n",
    "                                                 BACKBONE_model= '',\n",
    "                                                 use_pretrain_flag= False),\n",
    "                                      validation_data=data_gen(test_img,\n",
    "                                                               test_mask,\n",
    "                                                               opts['batch_size'],\n",
    "                                                               1,\n",
    "                                                               opts['crop_size'], opts['crop_size'],\n",
    "                                                               distance_unet_flag=0,\n",
    "                                                               augment= False,\n",
    "                                                               BACKBONE_model= '',\n",
    "                                                               use_pretrain_flag= False),\n",
    "                                      validation_steps=1,\n",
    "                                      epochs=opts['epoch_num'], verbose=1,\n",
    "                                      callbacks=[checkpoint, logger, LR_drop],\n",
    "                                      steps_per_epoch=(len(train_img) // opts['batch_size']) // opts['quick_run'])\n",
    "    \n",
    "    model_raw.load_weights(opts['model_save_path'] + 'unet_{}.h5'.format(current_fold))\n",
    "\n",
    "    ## predication on validation set\n",
    "    pred_val = model_raw.predict(validation_set_img, verbose=1, batch_size=1)\n",
    "    pred_val_t = (pred_val > opts['treshold']).astype(np.uint8)\n",
    "\n",
    "    output_watershed_tot_fold = []\n",
    "    output_watershed_tot_fold_wo_vague = []\n",
    "    validation_set_label_tot_fold_wo_vague = []\n",
    "    for val_len in tqdm.tqdm(range(len(pred_val))):\n",
    "        # with watershed post processing\n",
    "        local_maxi = peak_local_max(np.squeeze(pred_val[val_len]), indices=False,\n",
    "                                    exclude_border=False, footprint=np.ones((15, 15)))\n",
    "        marker = ndi.label(local_maxi)[0]\n",
    "        output_watershed = watershed(-np.squeeze(pred_val[val_len]), marker,mask = np.squeeze(pred_val_t[[val_len]]))\n",
    "        output_watershed[np.squeeze(pred_val_t[[val_len]])==0] = 0\n",
    "        output_watershed = remove_small_objects(output_watershed, min_size=50, connectivity=2)#remove small objects\n",
    "        \n",
    "        \n",
    "        \n",
    "        # without post processing \n",
    "        output_raw_0 = np.squeeze(pred_val_t[val_len])\n",
    "        output_raw = skimage.morphology.label(output_raw_0)\n",
    "        output_raw = remove_small_objects(output_raw, min_size=50, connectivity=2) #remove small objects\n",
    "\n",
    "        \n",
    "        output_watershed = remap_label(output_watershed)\n",
    "        validation_set_label[val_len] = remap_label(validation_set_label[val_len])\n",
    "        output_raw = remap_label(output_raw)\n",
    "        \n",
    "        test_name = get_id_from_file_path(test_img[val_len],'.png' )\n",
    "        \n",
    "        imsave(opts['result_save_path']+'validation/watershed_unet/{}.png'.format(test_name),\n",
    "               output_watershed.astype(np.uint16))\n",
    "        imsave(opts['result_save_path']+'validation/unet/{}.png'.format(test_name),output_raw.astype(np.uint16))\n",
    "\n",
    "\n",
    "        \n",
    "        dice_unet[current_fold-1, val_len]= get_dice_1(validation_set_label[val_len], output_raw)\n",
    "        AJI_unet[current_fold-1, val_len] = get_fast_aji(validation_set_label[val_len], output_raw)\n",
    "        PQ_unet[current_fold-1, val_len] = get_fast_pq(validation_set_label[val_len], output_raw)[0][2]\n",
    "        \n",
    "        \n",
    "        dice_unet_watershed[current_fold-1, val_len]= get_dice_1(validation_set_label[val_len],output_watershed)\n",
    "        AJI_unet_watershed[current_fold-1, val_len] = get_fast_aji(validation_set_label[val_len], output_watershed)\n",
    "        PQ_unet_watershed[current_fold-1, val_len]  = get_fast_pq(validation_set_label[val_len], output_watershed)[0][2]\n",
    "        ###################################################################\n",
    "        \n",
    "        #\n",
    "        output_watershed_wo_vague = np.copy(output_watershed)\n",
    "        output_watershed_wo_vague[validation_set_vague[val_len] == 255] = 0\n",
    "        output_watershed_wo_vague = remove_small_objects(output_watershed_wo_vague, min_size=50, connectivity=2) \n",
    "        \n",
    "        validation_set_label_wo_vague = np.copy(validation_set_label[val_len])\n",
    "        validation_set_label_wo_vague[validation_set_vague[val_len] == 255] = 0\n",
    "        validation_set_label_wo_vague = remove_small_objects(validation_set_label_wo_vague, min_size=50, connectivity=2)\n",
    "        \n",
    "        output_watershed_wo_vague = remap_label(output_watershed_wo_vague)\n",
    "        validation_set_label_wo_vague = remap_label(validation_set_label_wo_vague)\n",
    "        \n",
    "        \n",
    "        \n",
    "        dice_unet_watershed_without_vague[current_fold-1, val_len]= get_dice_1(\n",
    "            validation_set_label_wo_vague,output_watershed_wo_vague)\n",
    "        AJI_unet_watershed_without_vague[current_fold-1, val_len] = get_fast_aji(\n",
    "            validation_set_label_wo_vague,output_watershed_wo_vague)\n",
    "        PQ_unet_watershed_without_vague[current_fold-1, val_len]  = get_fast_pq(\n",
    "            validation_set_label_wo_vague,output_watershed_wo_vague)[0][2]\n",
    "\n",
    "        output_watershed_tot_fold.append(output_watershed)\n",
    "        output_watershed_tot_fold_wo_vague.append(output_watershed_wo_vague)\n",
    "        validation_set_label_tot_fold_wo_vague.append(validation_set_label_wo_vague)\n",
    "    \n",
    "    print('==========')    \n",
    "    print('average dice pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(dice_unet[current_fold-1, :]*100)))\n",
    "    print('average AJI pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(AJI_unet[current_fold-1, :]*100)))\n",
    "    print('average PQ pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(PQ_unet[current_fold-1, :]*100)))\n",
    "    dice_mean.append(np.mean(dice_unet[current_fold-1, :]*100))\n",
    "    aji_mean.append(np.mean(AJI_unet[current_fold-1, :]*100))\n",
    "    pq_mean.append(np.mean(PQ_unet[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "    \n",
    "    print('==========')    \n",
    "    print('average Dice Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                   np.mean(dice_unet_watershed[current_fold-1, :]*100)))\n",
    "    print('average AJI Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                  np.mean(AJI_unet_watershed[current_fold-1, :]*100)))\n",
    "    print('average PQ Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                 np.mean(PQ_unet_watershed[current_fold-1, :]*100)))\n",
    "    dice_watershed_mean.append(np.mean(dice_unet_watershed[current_fold-1, :]*100))\n",
    "    aji_watershed_mean.append(np.mean(AJI_unet_watershed[current_fold-1, :]*100))\n",
    "    pq_watershed_mean.append(np.mean(PQ_unet_watershed[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "       \n",
    "    print('average Dice Unet watershed wo vague for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                   np.mean(dice_unet_watershed_without_vague[current_fold-1, :]*100)))\n",
    "    print('average AJI Unet watershed wo vague for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                  np.mean(AJI_unet_watershed_without_vague[current_fold-1, :]*100)))\n",
    "    print('average PQ Unet watershed wo vague for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                 np.mean(PQ_unet_watershed_without_vague[current_fold-1, :]*100)))\n",
    "    dice_watershed_wovague_mean.append(np.mean(dice_unet_watershed_without_vague[current_fold-1, :]*100))\n",
    "    aji_watershed_wovague_mean.append(np.mean(AJI_unet_watershed_without_vague[current_fold-1, :]*100))\n",
    "    pq_watershed_wovague_mean.append(np.mean(PQ_unet_watershed_without_vague[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "    \n",
    "     \n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    current_fold = current_fold + 1\n",
    "#     if idx ==0:\n",
    "#         break \n",
    "\n",
    "fold_names = ['fold1', 'fold2','fold3','fold4','fold5']\n",
    "df_dice = pd.DataFrame({'fold num':fold_names, 'dice unet':dice_mean,'dice unet watershed':dice_watershed_mean,\n",
    "                   'dice unet whatershed wo vague':dice_watershed_wovague_mean})\n",
    "\n",
    "df_aji = pd.DataFrame({'fold num':fold_names, 'AJI unet':aji_mean,'AJI unet watershed':aji_watershed_mean,\n",
    "                   'AJI unet whatershed wo vague':aji_watershed_wovague_mean})\n",
    "\n",
    "df_pq = pd.DataFrame({'fold num':fold_names, 'PQ unet':pq_mean,'PQ unet watershed':pq_watershed_mean,\n",
    "                   'PQ unet whatershed wo vague':pq_watershed_wovague_mean})\n",
    "\n",
    "df_dice.to_csv('/kaggle/working/dice.csv', index=False)\n",
    "df_aji.to_csv('/kaggle/working/aji.csv', index=False)\n",
    "df_pq.to_csv('/kaggle/working/pq.csv', index=False)\n",
    "\n",
    "print(df_dice.head())\n",
    "print('============================================================')\n",
    "print(df_aji.head())\n",
    "print('============================================================')\n",
    "print(df_pq.head())\n",
    "print('============================================================')\n",
    "\n",
    "\n",
    "finish_time = time.time() \n",
    "print('==========') \n",
    "print('total training time (all 5 folds): {:.2f} minutes'.format((finish_time- start_time)/60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017713bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T08:45:34.999780Z",
     "iopub.status.busy": "2025-10-09T08:45:34.999274Z",
     "iopub.status.idle": "2025-10-09T08:45:37.187190Z",
     "shell.execute_reply": "2025-10-09T08:45:37.187563Z"
    },
    "papermill": {
     "duration": 5.813761,
     "end_time": "2025-10-09T08:45:37.187716",
     "exception": false,
     "start_time": "2025-10-09T08:45:31.373955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x4320 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x4320 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x4320 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x4320 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing random images and results from the last fold\n",
    "for i in range(4):\n",
    "    rand_num  = np.random.randint(len(validation_set_img))\n",
    "    plt.figure(figsize= (10,60))\n",
    "    plt.subplot(1,6,1)\n",
    "    plt.imshow(validation_set_img[rand_num])\n",
    "    plt.title(get_id_from_file_path(test_img[rand_num], '.png'))\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,6,2)\n",
    "    plt.imshow(validation_set_label[rand_num])\n",
    "    plt.title('GT')\n",
    "    \n",
    "    plt.subplot(1,6,3)\n",
    "    plt.imshow(validation_set_vague[rand_num])\n",
    "    plt.title('GT vague')\n",
    "    \n",
    "    plt.subplot(1,6,4)\n",
    "    plt.imshow(output_watershed_tot_fold[rand_num])\n",
    "    plt.title('labeled \\n prediction')\n",
    "    \n",
    "    plt.subplot(1,6,5)\n",
    "    plt.imshow(output_watershed_tot_fold_wo_vague[rand_num])\n",
    "    plt.title('labeled prediction \\n (wo vague)')\n",
    "    \n",
    "#     plt.subplot(1,6,6)\n",
    "#     plt.imshow(validation_set_label_tot_fold_wo_vague[rand_num])\n",
    "#     plt.title('GT wo vague')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445066c",
   "metadata": {
    "papermill": {
     "duration": 3.567218,
     "end_time": "2025-10-09T08:45:44.331902",
     "exception": false,
     "start_time": "2025-10-09T08:45:40.764684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1911713,
     "sourceId": 5909621,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30158,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8347.078669,
   "end_time": "2025-10-09T08:45:50.997439",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-09T06:26:43.918770",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
