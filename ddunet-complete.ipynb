{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4203f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:29.185965Z",
     "iopub.status.busy": "2025-11-06T13:34:29.185715Z",
     "iopub.status.idle": "2025-11-06T13:34:29.192507Z",
     "shell.execute_reply": "2025-11-06T13:34:29.191795Z"
    },
    "papermill": {
     "duration": 0.014488,
     "end_time": "2025-11-06T13:34:29.193699",
     "exception": false,
     "start_time": "2025-11-06T13:34:29.179211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## disabeling warning msg\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import sys\n",
    "sys.stdout.flush() # resolving tqdm problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb138d2c",
   "metadata": {
    "papermill": {
     "duration": 0.00436,
     "end_time": "2025-11-06T13:34:29.202605",
     "exception": false,
     "start_time": "2025-11-06T13:34:29.198245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0825c227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:29.212029Z",
     "iopub.status.busy": "2025-11-06T13:34:29.211475Z",
     "iopub.status.idle": "2025-11-06T13:34:44.394790Z",
     "shell.execute_reply": "2025-11-06T13:34:44.394101Z"
    },
    "papermill": {
     "duration": 15.189354,
     "end_time": "2025-11-06T13:34:44.396144",
     "exception": false,
     "start_time": "2025-11-06T13:34:29.206790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762436071.020692      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762436071.073305      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636e0672",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.407709Z",
     "iopub.status.busy": "2025-11-06T13:34:44.406957Z",
     "iopub.status.idle": "2025-11-06T13:34:44.412555Z",
     "shell.execute_reply": "2025-11-06T13:34:44.411908Z"
    },
    "papermill": {
     "duration": 0.012499,
     "end_time": "2025-11-06T13:34:44.413756",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.401257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "#####################################################################################\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
    "#####################################################################################################################\n",
    "def mse_score(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a33f0b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.424290Z",
     "iopub.status.busy": "2025-11-06T13:34:44.423998Z",
     "iopub.status.idle": "2025-11-06T13:34:44.439964Z",
     "shell.execute_reply": "2025-11-06T13:34:44.439382Z"
    },
    "papermill": {
     "duration": 0.022693,
     "end_time": "2025-11-06T13:34:44.441052",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.418359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dual_decoder_unet_binary(IMG_CHANNELS, LearnRate):\n",
    "    inputs = Input((None, None, IMG_CHANNELS))\n",
    "    #encoder\n",
    "    s = Lambda(lambda x: x / 255)(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.1)(c5)\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    ## decoder for dis unet\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs1 = Conv2D(1, (1, 1), activation='linear', name='output_dis')(c9)\n",
    "\n",
    "\n",
    "    ## decoder for segmentation unet\n",
    "    u6_seg = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6_seg = concatenate([u6_seg, c4])\n",
    "    c6_seg = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6_seg)\n",
    "    c6_seg = Dropout(0.2)(c6_seg)\n",
    "    c6_seg = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6_seg)\n",
    "\n",
    "    u7_seg = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6_seg)\n",
    "    u7_seg = concatenate([u7_seg, c3])\n",
    "    c7_seg = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7_seg)\n",
    "    c7_seg = Dropout(0.2)(c7_seg)\n",
    "    c7_seg = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7_seg)\n",
    "\n",
    "    u8_seg = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7_seg)\n",
    "    u8_seg = concatenate([u8_seg, c2])\n",
    "    c8_seg = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8_seg)\n",
    "    c8_seg = Dropout(0.1)(c8_seg)\n",
    "    c8_seg = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8_seg)\n",
    "\n",
    "    u9_seg = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8_seg)\n",
    "    u9_seg = concatenate([u9_seg, c1], axis=3)\n",
    "    c9_seg = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9_seg)\n",
    "    c9_seg = Dropout(0.1)(c9_seg)\n",
    "    c9_seg = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9_seg)\n",
    "\n",
    "    outputs2 = Conv2D(1, (1, 1), activation='sigmoid', name='output_seg')(c9_seg)\n",
    "\n",
    "    model_dual_path = models.Model(inputs=[inputs], outputs=[outputs1, outputs2])\n",
    "    model_dual_path.compile(optimizer=Adam(learning_rate=LearnRate),\n",
    "                            loss={'output_dis': 'mean_squared_error', 'output_seg': bce_dice_loss},\n",
    "                            loss_weights=  {'output_dis': 1.0, 'output_seg': 1.0},\n",
    "                            metrics={'output_seg':dice_coef, 'output_dis':mse_score})\n",
    "    # model_dual_path.summary()\n",
    "    return model_dual_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c1280f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.451722Z",
     "iopub.status.busy": "2025-11-06T13:34:44.451422Z",
     "iopub.status.idle": "2025-11-06T13:34:44.469905Z",
     "shell.execute_reply": "2025-11-06T13:34:44.469209Z"
    },
    "papermill": {
     "duration": 0.02518,
     "end_time": "2025-11-06T13:34:44.470963",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.445783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fast_aji(true, pred):\n",
    "    \"\"\"AJI version distributed by MoNuSeg, has no permutation problem but suffered from \n",
    "    over-penalisation similar to DICE2.\n",
    "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4] \n",
    "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no \n",
    "    effect on the result.\n",
    "    \"\"\"\n",
    "    true = np.copy(true)  # ? do we need this\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "    #print(len(pred_id_list))\n",
    "    if len(pred_id_list) == 1:\n",
    "        return 0\n",
    "\n",
    "    true_masks = [None,]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [None,]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_inter = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "    pairwise_union = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
    "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
    "\n",
    "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
    "    # pair of pred that give highest iou for each true, dont care\n",
    "    # about reusing pred instance multiple times\n",
    "    paired_pred = np.argmax(pairwise_iou, axis=1)\n",
    "    pairwise_iou = np.max(pairwise_iou, axis=1)\n",
    "    # exlude those dont have intersection\n",
    "    paired_true = np.nonzero(pairwise_iou > 0.0)[0]\n",
    "    paired_pred = paired_pred[paired_true]\n",
    "    # print(paired_true.shape, paired_pred.shape)\n",
    "    overall_inter = (pairwise_inter[paired_true, paired_pred]).sum()\n",
    "    overall_union = (pairwise_union[paired_true, paired_pred]).sum()\n",
    "\n",
    "    paired_true = list(paired_true + 1)  # index to instance ID\n",
    "    paired_pred = list(paired_pred + 1)\n",
    "    # add all unpaired GT and Prediction into the union\n",
    "    unpaired_true = np.array(\n",
    "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    )\n",
    "    unpaired_pred = np.array(\n",
    "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    )\n",
    "    for true_id in unpaired_true:\n",
    "        overall_union += true_masks[true_id].sum()\n",
    "    for pred_id in unpaired_pred:\n",
    "        overall_union += pred_masks[pred_id].sum()\n",
    "\n",
    "    aji_score = overall_inter / overall_union\n",
    "    #print(aji_score)\n",
    "    return aji_score\n",
    "\n",
    "#############################################################################################################\n",
    "def get_fast_pq(true, pred, match_iou=0.5):\n",
    "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
    "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
    "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique \n",
    "    (1 prediction instance to 1 GT instance mapping).\n",
    "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
    "    in bipartite graphs) is caculated to find the maximal amount of unique pairing. \n",
    "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
    "    the number of pairs is also maximal.    \n",
    "    \n",
    "    Fast computation requires instance IDs are in contiguous orderding \n",
    "    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand \n",
    "    and `by_size` flag has no effect on the result.\n",
    "    Returns:\n",
    "        [dq, sq, pq]: measurement statistic\n",
    "        [paired_true, paired_pred, unpaired_true, unpaired_pred]: \n",
    "                      pairing information to perform measurement\n",
    "                    \n",
    "    \"\"\"\n",
    "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
    "\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true_id_list = list(np.unique(true))\n",
    "    pred_id_list = list(np.unique(pred))\n",
    "    \n",
    "    if len(pred_id_list) == 1:\n",
    "        return [0, 0, 0], [0,0, 0, 0]\n",
    "\n",
    "    true_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for t in true_id_list[1:]:\n",
    "        t_mask = np.array(true == t, np.uint8)\n",
    "        true_masks.append(t_mask)\n",
    "\n",
    "    pred_masks = [\n",
    "        None,\n",
    "    ]\n",
    "    for p in pred_id_list[1:]:\n",
    "        p_mask = np.array(pred == p, np.uint8)\n",
    "        pred_masks.append(p_mask)\n",
    "\n",
    "    # prefill with value\n",
    "    pairwise_iou = np.zeros(\n",
    "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
    "    )\n",
    "\n",
    "    # caching pairwise iou\n",
    "    for true_id in true_id_list[1:]:  # 0-th is background\n",
    "        t_mask = true_masks[true_id]\n",
    "        pred_true_overlap = pred[t_mask > 0]\n",
    "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
    "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
    "        for pred_id in pred_true_overlap_id:\n",
    "            if pred_id == 0:  # ignore\n",
    "                continue  # overlaping background\n",
    "            p_mask = pred_masks[pred_id]\n",
    "            total = (t_mask + p_mask).sum()\n",
    "            inter = (t_mask * p_mask).sum()\n",
    "            iou = inter / (total - inter)\n",
    "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
    "    #\n",
    "    if match_iou >= 0.5:\n",
    "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
    "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
    "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "        paired_true += 1  # index is instance id - 1\n",
    "        paired_pred += 1  # hence return back to original\n",
    "    else:  # * Exhaustive maximal unique pairing\n",
    "        #### Munkres pairing with scipy library\n",
    "        # the algorithm return (row indices, matched column indices)\n",
    "        # if there is multiple same cost in a row, index of first occurence\n",
    "        # is return, thus the unique pairing is ensure\n",
    "        # inverse pair to get high IoU as minimum\n",
    "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
    "        ### extract the paired cost and remove invalid pair\n",
    "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
    "\n",
    "        # now select those above threshold level\n",
    "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
    "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
    "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
    "        paired_iou = paired_iou[paired_iou > match_iou]\n",
    "\n",
    "    # get the actual FP and FN\n",
    "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
    "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
    "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
    "\n",
    "    #\n",
    "    tp = len(paired_true)\n",
    "    fp = len(unpaired_pred)\n",
    "    fn = len(unpaired_true)\n",
    "    # get the F1-score i.e DQ\n",
    "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
    "    # get the SQ, no paired has 0 iou so not impact\n",
    "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
    "\n",
    "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "def get_dice_1(true, pred):\n",
    "    \"\"\"Traditional dice.\"\"\"\n",
    "    # cast to binary 1st\n",
    "    true = np.copy(true)\n",
    "    pred = np.copy(pred)\n",
    "    true[true > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "    inter = true * pred\n",
    "    denom = true + pred\n",
    "    dice_score = 2.0 * np.sum(inter) / (np.sum(denom) + 0.0001)\n",
    "    if np.sum(inter)==0 and np.sum(denom)==0:\n",
    "        dice_score = 1 # to handel cases without any nuclei\n",
    "    #print(dice_score)\n",
    "    return dice_score\n",
    "#############################################################################################################\n",
    "def remap_label(pred, by_size=False):\n",
    "    \"\"\"Rename all instance id so that the id is contiguous i.e [0, 1, 2, 3] \n",
    "    not [0, 2, 4, 6]. The ordering of instances (which one comes first) \n",
    "    is preserved unless by_size=True, then the instances will be reordered\n",
    "    so that bigger nucler has smaller ID.\n",
    "    Args:\n",
    "        pred    : the 2d array contain instances where each instances is marked\n",
    "                  by non-zero integer\n",
    "        by_size : renaming with larger nuclei has smaller id (on-top)\n",
    "    \"\"\"\n",
    "    pred_id = list(np.unique(pred))\n",
    "    pred_id.remove(0)\n",
    "    if len(pred_id) == 0:\n",
    "        return pred  # no label\n",
    "    if by_size:\n",
    "        pred_size = []\n",
    "        for inst_id in pred_id:\n",
    "            size = (pred == inst_id).sum()\n",
    "            pred_size.append(size)\n",
    "        # sort the id by size in descending order\n",
    "        pair_list = zip(pred_id, pred_size)\n",
    "        pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
    "        pred_id, pred_size = zip(*pair_list)\n",
    "\n",
    "    new_pred = np.zeros(pred.shape, np.int32)\n",
    "    for idx, inst_id in enumerate(pred_id):\n",
    "        new_pred[pred == inst_id] = idx + 1\n",
    "    return new_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a098e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.480843Z",
     "iopub.status.busy": "2025-11-06T13:34:44.480569Z",
     "iopub.status.idle": "2025-11-06T13:34:44.483666Z",
     "shell.execute_reply": "2025-11-06T13:34:44.483031Z"
    },
    "papermill": {
     "duration": 0.00948,
     "end_time": "2025-11-06T13:34:44.484765",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.475285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = dual_decoder_unet_binary(3,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2192fdac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.495687Z",
     "iopub.status.busy": "2025-11-06T13:34:44.495438Z",
     "iopub.status.idle": "2025-11-06T13:34:44.498984Z",
     "shell.execute_reply": "2025-11-06T13:34:44.498028Z"
    },
    "papermill": {
     "duration": 0.010927,
     "end_time": "2025-11-06T13:34:44.500684",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.489757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99687e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.511613Z",
     "iopub.status.busy": "2025-11-06T13:34:44.511379Z",
     "iopub.status.idle": "2025-11-06T13:34:44.516068Z",
     "shell.execute_reply": "2025-11-06T13:34:44.515498Z"
    },
    "papermill": {
     "duration": 0.011183,
     "end_time": "2025-11-06T13:34:44.517049",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.505866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set all hyper parameters\n",
    "opts = {}\n",
    "opts['number_of_channel'] = 3                   \n",
    "opts['treshold'] = 0.5                          \n",
    "opts['epoch_num'] = 120             \n",
    "opts['quick_run'] = 1   \n",
    "opts['batch_size'] = 8                         \n",
    "opts['random_seed_num'] = 19   \n",
    "opts['k_fold'] = 2                          \n",
    "opts['save_val_results'] = 1         \n",
    "opts['init_LR'] = 0.001                         \n",
    "opts['LR_decay_factor'] = 0.5                   \n",
    "opts['LR_drop_after_nth_epoch'] = 20            \n",
    "opts['crop_size'] = 512   \n",
    "## output directories\n",
    "opts['result_save_path'] ='/kaggle/working/prediction_image/'\n",
    "opts['model_save_path'] ='/kaggle/working/output_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b024bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.526436Z",
     "iopub.status.busy": "2025-11-06T13:34:44.526246Z",
     "iopub.status.idle": "2025-11-06T13:34:44.529942Z",
     "shell.execute_reply": "2025-11-06T13:34:44.529430Z"
    },
    "papermill": {
     "duration": 0.009423,
     "end_time": "2025-11-06T13:34:44.530935",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.521512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.1, epochs_drop=20):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/epochs_drop))\n",
    "    \n",
    "    return LearningRateScheduler(schedule, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33472d",
   "metadata": {
    "papermill": {
     "duration": 0.00431,
     "end_time": "2025-11-06T13:34:44.539532",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.535222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9a2280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.549246Z",
     "iopub.status.busy": "2025-11-06T13:34:44.549036Z",
     "iopub.status.idle": "2025-11-06T13:34:44.592276Z",
     "shell.execute_reply": "2025-11-06T13:34:44.591612Z"
    },
    "papermill": {
     "duration": 0.049608,
     "end_time": "2025-11-06T13:34:44.593513",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.543905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mouse muscle_tibia',\n",
       " 'mouse liver',\n",
       " 'human liver',\n",
       " 'human umbilical cord',\n",
       " 'mouse thymus',\n",
       " 'human lung',\n",
       " 'human epiglottis',\n",
       " 'human spleen',\n",
       " 'mouse fat (white and brown)_subscapula',\n",
       " 'human cardia',\n",
       " 'human salivory gland',\n",
       " 'human melanoma',\n",
       " 'human kidney',\n",
       " 'human pylorus',\n",
       " 'human jejunum',\n",
       " 'human testis',\n",
       " 'mouse spleen',\n",
       " 'human tongue',\n",
       " 'human cerebellum',\n",
       " 'human oesophagus',\n",
       " 'mouse heart',\n",
       " 'human pancreas',\n",
       " 'human brain',\n",
       " 'human muscle',\n",
       " 'human placenta',\n",
       " 'human bladder',\n",
       " 'mouse kidney',\n",
       " 'human tonsile',\n",
       " 'human rectum',\n",
       " 'mouse femur',\n",
       " 'human peritoneum']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '../input/nuinsseg/'\n",
    "organ_names = [ name for name in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, name)) ]\n",
    "organ_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75168570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:44.603636Z",
     "iopub.status.busy": "2025-11-06T13:34:44.603366Z",
     "iopub.status.idle": "2025-11-06T13:34:45.826166Z",
     "shell.execute_reply": "2025-11-06T13:34:45.825531Z"
    },
    "papermill": {
     "duration": 1.229146,
     "end_time": "2025-11-06T13:34:45.827445",
     "exception": false,
     "start_time": "2025-11-06T13:34:44.598299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "img_path = glob('{}*{}'.format('../input/nuinsseg/*/tissue images/', 'png'))\n",
    "binary_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/mask binary/', 'png'))\n",
    "distance_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/distance maps/', 'png'))\n",
    "label_mask_path = glob('{}*{}'.format('../input/nuinsseg/*/label masks modify/', 'tif'))\n",
    "vague_mask_path =  glob('{}*{}'.format('../input/nuinsseg/*/vague areas/mask binary/', 'png'))\n",
    "\n",
    "\n",
    "img_path.sort()\n",
    "binary_mask_path.sort()\n",
    "distance_mask_path.sort()\n",
    "label_mask_path.sort()\n",
    "vague_mask_path.sort()\n",
    "\n",
    "\n",
    "# create folders to save the best models and images (if needed) for each fold\n",
    "if not os.path.exists('/kaggle/working/prediction_image/'):\n",
    "    os.makedirs('/kaggle/working/prediction_image/')\n",
    "if not os.path.exists('/kaggle/working/output_model/'):\n",
    "    os.makedirs('/kaggle/working/output_model/')    \n",
    "if not os.path.exists(opts['result_save_path']+ 'validation/unet'):\n",
    "    os.makedirs(opts['result_save_path'] + 'validation/unet')\n",
    "if not os.path.exists(opts['result_save_path']+ 'validation/watershed_unet'):\n",
    "    os.makedirs(opts['result_save_path'] + 'validation/watershed_unet')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4645f335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:45.847367Z",
     "iopub.status.busy": "2025-11-06T13:34:45.847102Z",
     "iopub.status.idle": "2025-11-06T13:34:45.852196Z",
     "shell.execute_reply": "2025-11-06T13:34:45.851385Z"
    },
    "papermill": {
     "duration": 0.013657,
     "end_time": "2025-11-06T13:34:45.853302",
     "exception": false,
     "start_time": "2025-11-06T13:34:45.839645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image path: ../input/nuinsseg/human tonsile/tissue images/human_tonsile_10.png\n",
      " binary mask path: ../input/nuinsseg/human tonsile/mask binary/human_tonsile_10.png\n",
      " distance mask path: ../input/nuinsseg/human tonsile/distance maps/human_tonsile_10.png\n",
      " label mask path: ../input/nuinsseg/human tonsile/label masks modify/human_tonsile_10.tif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random check\n",
    "import numpy as np\n",
    "import random\n",
    "rand_num = np.random.randint(len(img_path))\n",
    "print('image path: {}\\n'.format(img_path[rand_num]),\n",
    "      'binary mask path: {}\\n'.format(binary_mask_path[rand_num]),\n",
    "      'distance mask path: {}\\n'.format(distance_mask_path[rand_num]),\n",
    "      'label mask path: {}\\n'.format(label_mask_path[rand_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7ab5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:45.863045Z",
     "iopub.status.busy": "2025-11-06T13:34:45.862851Z",
     "iopub.status.idle": "2025-11-06T13:34:50.867711Z",
     "shell.execute_reply": "2025-11-06T13:34:50.866931Z"
    },
    "papermill": {
     "duration": 5.011294,
     "end_time": "2025-11-06T13:34:50.869106",
     "exception": false,
     "start_time": "2025-11-06T13:34:45.857812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmentation function\n",
    "import albumentations \n",
    "def albumentation_aug(p=1.0, crop_size_row = 448, crop_size_col = 448 ):\n",
    "    return albumentations.Compose([\n",
    "        albumentations.RandomCrop(crop_size_row, crop_size_col, always_apply=True, p=1),\n",
    "        albumentations.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "        albumentations.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, brightness_by_max=True, p=0.4),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.1),\n",
    "        albumentations.HorizontalFlip(always_apply=False, p=0.5),\n",
    "        albumentations.VerticalFlip(always_apply=False, p=0.5),\n",
    "        albumentations.RandomRotate90(p=0.5),\n",
    "        albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=20, interpolation=1, \n",
    "                         border_mode=4, always_apply=False, p=0.1),\n",
    "\n",
    "    ], p=p)\n",
    "\n",
    "# aug =albumentation_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5d686",
   "metadata": {
    "papermill": {
     "duration": 0.004492,
     "end_time": "2025-11-06T13:34:50.879923",
     "exception": false,
     "start_time": "2025-11-06T13:34:50.875431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37cece4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:50.890519Z",
     "iopub.status.busy": "2025-11-06T13:34:50.889747Z",
     "iopub.status.idle": "2025-11-06T13:34:50.895217Z",
     "shell.execute_reply": "2025-11-06T13:34:50.894625Z"
    },
    "papermill": {
     "duration": 0.011958,
     "end_time": "2025-11-06T13:34:50.896399",
     "exception": false,
     "start_time": "2025-11-06T13:34:50.884441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import cv2\n",
    "from keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94af5153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:50.907557Z",
     "iopub.status.busy": "2025-11-06T13:34:50.907087Z",
     "iopub.status.idle": "2025-11-06T13:34:51.020952Z",
     "shell.execute_reply": "2025-11-06T13:34:51.019996Z"
    },
    "papermill": {
     "duration": 0.121492,
     "end_time": "2025-11-06T13:34:51.022702",
     "exception": false,
     "start_time": "2025-11-06T13:34:50.901210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "kf = KFold(n_splits= opts['k_fold'],random_state= opts['random_seed_num'],shuffle=True)\n",
    "kf.get_n_splits(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca92e84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:51.036963Z",
     "iopub.status.busy": "2025-11-06T13:34:51.036737Z",
     "iopub.status.idle": "2025-11-06T13:34:51.042343Z",
     "shell.execute_reply": "2025-11-06T13:34:51.041775Z"
    },
    "papermill": {
     "duration": 0.012418,
     "end_time": "2025-11-06T13:34:51.043345",
     "exception": false,
     "start_time": "2025-11-06T13:34:51.030927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Make sure you have albumentations installed\n",
    "# import albumentations as A \n",
    "\n",
    "# Helper function to find borders between touching instances\n",
    "def get_touching_borders(instance_mask):\n",
    "    \"\"\"\n",
    "    Finds pixels that represent the border between two touching instances.\n",
    "    \n",
    "    Args:\n",
    "        instance_mask (np.array): A 2D array where each instance is \n",
    "                                  labeled with a unique integer.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: A 2D binary mask (0 or 1) where '1' marks a\n",
    "                  pixel that lies on the border between two instances.\n",
    "    \"\"\"\n",
    "    # Use a 3x3 kernel for dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    \n",
    "    # Get all unique labels (excluding background 0)\n",
    "    labels = np.unique(instance_mask)\n",
    "    labels = labels[labels != 0]\n",
    "    \n",
    "    touching_borders = np.zeros_like(instance_mask, dtype=np.uint8)\n",
    "\n",
    "    for label in labels:\n",
    "        # Create a mask for the current instance\n",
    "        instance = (instance_mask == label).astype(np.uint8)\n",
    "        \n",
    "        # Dilate this instance\n",
    "        dilated_instance = cv2.dilate(instance, kernel, iterations=1)\n",
    "        \n",
    "        # Find where the dilated part overlaps with *other* instances\n",
    "        # (instance_mask > 0) -> any instance\n",
    "        # (instance_mask != label) -> not this instance\n",
    "        other_instances_mask = (instance_mask > 0) & (instance_mask != label)\n",
    "        \n",
    "        # The border is where the dilated part of *this* instance\n",
    "        # touches *another* instance's mask\n",
    "        border = (dilated_instance > 0) & (other_instances_mask > 0)\n",
    "        touching_borders[border] = 1\n",
    "        \n",
    "    return touching_borders\n",
    "\n",
    "# # Simplified chunker for two lists\n",
    "# def chunker(seq, seq2, size):\n",
    "#     return ([seq[pos:pos + size], seq2[pos:pos + size]] for pos in range(0, len(seq), size))\n",
    "\n",
    "def get_id_from_file_path(file_path, indicator):\n",
    "    return file_path.split(os.path.sep)[-1].replace(indicator, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36b719c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:51.053303Z",
     "iopub.status.busy": "2025-11-06T13:34:51.053105Z",
     "iopub.status.idle": "2025-11-06T13:34:51.062269Z",
     "shell.execute_reply": "2025-11-06T13:34:51.061776Z"
    },
    "papermill": {
     "duration": 0.01517,
     "end_time": "2025-11-06T13:34:51.063182",
     "exception": false,
     "start_time": "2025-11-06T13:34:51.048012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Data Generator Needed not to run out of \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "def get_id_from_file_path(file_path, indicator):\n",
    "    return file_path.split(os.path.sep)[-1].replace(indicator, '')\n",
    "    \n",
    "def chunker(seq, seq2, seq3, size):\n",
    "    return ([seq[pos:pos + size], seq2[pos:pos + size], seq3[pos:pos + size]] for pos in range(0, len(seq), size))\n",
    "\n",
    "def data_gen(list_files, list_files2, list_files3, batch_size, p , size_row, size_col, distance_unet_flag = 0,\n",
    "             augment= False, BACKBONE_model = None, use_pretrain_flag = 1):\n",
    "    crop_size_row = size_row\n",
    "    crop_size_col = size_col\n",
    "    aug = albumentation_aug(p, crop_size_row, crop_size_col)\n",
    "    while True:\n",
    "        for batch in chunker(list_files, list_files2, list_files3, batch_size):\n",
    "            Y = []\n",
    "            Y_seg = []\n",
    "            Y_dis = []\n",
    "            X = []\n",
    "            \n",
    "            image_paths = batch[0]\n",
    "            # mask_paths = batch[1]\n",
    "            dis_paths = batch[2] \n",
    "            inst_path = batch[1]\n",
    "\n",
    "            for count in range(len(image_paths)):\n",
    "                # 1. Load Image (X)\n",
    "                x = cv2.imread(image_paths[count])\n",
    "                x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # 2. Load Segmentation Mask (Y_seg) - For output_seg w/o borders\n",
    "                # seg_mask = cv2.imread(mask_paths[count], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "\n",
    "                orig_instance_mask = cv2.imread(inst_path[count], cv2.IMREAD_UNCHANGED)\n",
    "                binary_mask = (orig_instance_mask > 0).astype(np.uint8)\n",
    "                touching_borders = get_touching_borders(orig_instance_mask)\n",
    "                mask_no_borders = binary_mask - touching_borders\n",
    "                seg_mask = cv2.erode(mask_no_borders, erosion_kernel, iterations=1)\n",
    "                \n",
    "                # 3. Load Distance Map (Y_dis) - For output_dis\n",
    "                dis_map = cv2.imread(dis_paths[count], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                if augment:\n",
    "                    augmented = aug(image= x, mask= seg_mask, dis = dis_map)\n",
    "                    x = augmented['image']\n",
    "                    seg_mask = augmented['mask']\n",
    "                    dis_map = augmented['dis']\n",
    "                    \n",
    "                x = x/255.0\n",
    "\n",
    "                # seg_mask = (seg_mask - np.min(seg_mask))/ (np.max(seg_mask) - np.min(seg_mask) + 0.0000001)\n",
    "\n",
    "                # dis_map = dis_map / 255.0\n",
    "                min_dis = np.min(dis_map)\n",
    "                max_dis = np.max(dis_map)\n",
    "                if (max_dis - min_dis) > 0.0000001:\n",
    "                    dis_map = (dis_map - min_dis) / (max_dis - min_dis)\n",
    "                else:\n",
    "                    dis_map = np.zeros_like(dis_map) # Handle case of all-zero mask\n",
    "\n",
    "                x = x.astype(np.float32)\n",
    "                dis_map = dis_map.astype(np.float32)\n",
    "                seg_mask = (seg_mask > 0).astype(np.float32) \n",
    "                # min_dis = np.min(dis_map)\n",
    "                # max_dis = np.max(dis_map)\n",
    "                # dis_map = (dis_map - min_dis) / (max_dis - min_dis + 0.0000001)\n",
    "\n",
    "                X.append(x)\n",
    "                Y_seg.append(seg_mask)\n",
    "                Y_dis.append(dis_map)\n",
    "                \n",
    "                del x, seg_mask, dis_map, orig_instance_mask\n",
    "            X = np.array(X)\n",
    "            Y_seg = np.expand_dims(np.array(Y_seg), axis=-1)\n",
    "            Y_dis = np.expand_dims(np.array(Y_dis), axis=-1)\n",
    "            yield X, {'output_seg': Y_seg, 'output_dis': Y_dis}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75947347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:51.072630Z",
     "iopub.status.busy": "2025-11-06T13:34:51.072411Z",
     "iopub.status.idle": "2025-11-06T13:34:51.076191Z",
     "shell.execute_reply": "2025-11-06T13:34:51.075693Z"
    },
    "papermill": {
     "duration": 0.00955,
     "end_time": "2025-11-06T13:34:51.077114",
     "exception": false,
     "start_time": "2025-11-06T13:34:51.067564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_smoothing(distance_map_array, average_diameter):\n",
    "    \"\"\"\n",
    "    Applies Gaussian smoothing to the predicted distance map.\n",
    "    \n",
    "    Args:\n",
    "        distance_map_array (np.ndarray): The 2D distance map predicted by the UNet head.\n",
    "        average_diameter (float): The average nucleus equivalent diameter (in pixels).\n",
    "                                  \n",
    "    Returns:\n",
    "        np.ndarray: The smoothed distance map, ready for watershed markers extraction.\n",
    "    \"\"\"\n",
    "    # Set the standard deviation (sigma, Ïƒ) for the Gaussian filter.\n",
    "    # Sigma is typically set to the average radius of the object (Diameter / 2).\n",
    "    # This choice ensures the filter smooths the distance peaks for *one* nucleus, \n",
    "    # while generally preserving the boundaries between overlapping nuclei.\n",
    "    GAUSSIAN_SIGMA = average_diameter / 2.0\n",
    "    \n",
    "    # Apply the Gaussian filter. \n",
    "    # truncate=4.0 ensures the kernel covers about 4 standard deviations, making \n",
    "    # the smoothing effective.\n",
    "    smoothed_dis_map = gaussian_filter(\n",
    "        input=distance_map_array, \n",
    "        sigma=GAUSSIAN_SIGMA, \n",
    "        truncate=4.0\n",
    "    )\n",
    "    \n",
    "    return smoothed_dis_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80f44394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:51.086682Z",
     "iopub.status.busy": "2025-11-06T13:34:51.086470Z",
     "iopub.status.idle": "2025-11-06T13:34:51.142536Z",
     "shell.execute_reply": "2025-11-06T13:34:51.141828Z"
    },
    "papermill": {
     "duration": 0.06215,
     "end_time": "2025-11-06T13:34:51.143783",
     "exception": false,
     "start_time": "2025-11-06T13:34:51.081633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from math import sqrt, pi\n",
    "from scipy.ndimage import gaussian_filter # Needed for the next step\n",
    "\n",
    "def calculate_average_nucleus_diameter(binary_mask_array, min_area_threshold=50):\n",
    "    \"\"\"\n",
    "    Calculates the average equivalent nucleus diameter (in pixels) from the \n",
    "    predicted binary semantic mask.\n",
    "    \n",
    "    The diameter is derived from the average nucleus area, assuming a circular shape \n",
    "    (Area = pi * (D/2)^2 => D = 2 * sqrt(Area / pi)).\n",
    "    \n",
    "    Args:\n",
    "        binary_mask_array (np.ndarray): The 2D numpy array of the predicted \n",
    "                                        binary semantic mask (0s and 1s).\n",
    "        min_area_threshold (int): Filters out small regions (noise) that are not nuclei.\n",
    "                                  \n",
    "    Returns:\n",
    "        float: The average nucleus equivalent diameter in pixels.\n",
    "    \"\"\"\n",
    "    # 1. Label connected components to identify individual (or clustered) nuclei\n",
    "    # Use boolean array for skimage.label\n",
    "    labeled_mask = label(binary_mask_array > 0)\n",
    "\n",
    "    # 2. Calculate properties (Area) for each labeled region\n",
    "    props = regionprops(labeled_mask)\n",
    "    all_areas = []\n",
    "\n",
    "    # 3. Collect areas\n",
    "    for prop in props:\n",
    "        if prop.area >= min_area_threshold:\n",
    "            all_areas.append(prop.area)\n",
    "\n",
    "    if not all_areas:\n",
    "        # Fallback to a common size if no objects are detected\n",
    "        return 20.0 \n",
    "\n",
    "    # 4. Calculate average area\n",
    "    average_area = np.mean(all_areas)\n",
    "    \n",
    "    # 5. Convert average area to equivalent diameter (D)\n",
    "    average_diameter_pixels = 2 * sqrt(average_area / pi)\n",
    "    \n",
    "    return average_diameter_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc9ef3c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:51.154181Z",
     "iopub.status.busy": "2025-11-06T13:34:51.153255Z",
     "iopub.status.idle": "2025-11-06T13:34:51.159383Z",
     "shell.execute_reply": "2025-11-06T13:34:51.158714Z"
    },
    "papermill": {
     "duration": 0.01209,
     "end_time": "2025-11-06T13:34:51.160442",
     "exception": false,
     "start_time": "2025-11-06T13:34:51.148352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dice_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# AJI_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# PQ_unet = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "\n",
    "# dice_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# AJI_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# PQ_unet_watershed = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "# dice_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# AJI_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "# PQ_unet_watershed_without_vague = np.zeros([opts['k_fold'],len(img_path)//opts['k_fold']])\n",
    "\n",
    "# Calculate the maximum size required for any fold (using ceiling division)\n",
    "num_folds = opts['k_fold']\n",
    "total_images = len(img_path)\n",
    "max_fold_size = (total_images + num_folds - 1) // num_folds\n",
    "\n",
    "# Initialize all arrays using the calculated maximum fold size\n",
    "dice_unet = np.zeros([num_folds, max_fold_size])\n",
    "AJI_unet = np.zeros([num_folds, max_fold_size])\n",
    "PQ_unet = np.zeros([num_folds, max_fold_size])\n",
    "\n",
    "dice_unet_watershed = np.zeros([num_folds, max_fold_size])\n",
    "AJI_unet_watershed = np.zeros([num_folds, max_fold_size])\n",
    "PQ_unet_watershed = np.zeros([num_folds, max_fold_size])\n",
    "\n",
    "dice_unet_watershed_without_vague = np.zeros([num_folds, max_fold_size])\n",
    "AJI_unet_watershed_without_vague = np.zeros([num_folds, max_fold_size])\n",
    "PQ_unet_watershed_without_vague = np.zeros([num_folds, max_fold_size])\n",
    "\n",
    "dice_mean = []\n",
    "aji_mean = []\n",
    "pq_mean = []\n",
    "                   \n",
    "dice_watershed_mean = []\n",
    "aji_watershed_mean = []\n",
    "pq_watershed_mean = []\n",
    "                   \n",
    "dice_watershed_wovague_mean = []\n",
    "aji_watershed_wovague_mean = []\n",
    "pq_watershed_wovague_mean = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75f96a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:34:51.170223Z",
     "iopub.status.busy": "2025-11-06T13:34:51.170018Z",
     "iopub.status.idle": "2025-11-06T14:48:38.434368Z",
     "shell.execute_reply": "2025-11-06T14:48:38.433555Z"
    },
    "papermill": {
     "duration": 4427.270562,
     "end_time": "2025-11-06T14:48:38.435434",
     "exception": false,
     "start_time": "2025-11-06T13:34:51.164872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762436101.089832      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762436118.179292      62 service.cc:148] XLA service 0x7c3a90003520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762436118.180286      62 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1762436119.790816      62 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1762436142.816833      62 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - loss: 0.0982 - output_dis_loss: 0.0146 - output_dis_mse_score: 0.0146 - output_seg_dice_coef: 0.1914 - output_seg_loss: 0.0836\n",
      "Epoch 1: val_output_seg_dice_coef improved from -inf to 0.19015, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 642ms/step - loss: 0.0971 - output_dis_loss: 0.0146 - output_dis_mse_score: 0.0146 - output_seg_dice_coef: 0.1915 - output_seg_loss: 0.0825 - val_loss: 0.0342 - val_output_dis_loss: 0.0104 - val_output_dis_mse_score: 0.0104 - val_output_seg_dice_coef: 0.1902 - val_output_seg_loss: 0.0238 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1762436172.680513      60 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762436172.914533      60 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.0766 - output_dis_loss: 0.0134 - output_dis_mse_score: 0.0134 - output_seg_dice_coef: 0.2781 - output_seg_loss: -0.0908\n",
      "Epoch 2: val_output_seg_dice_coef improved from 0.19015 to 0.28616, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 410ms/step - loss: -0.0775 - output_dis_loss: 0.0134 - output_dis_mse_score: 0.0134 - output_seg_dice_coef: 0.2788 - output_seg_loss: -0.0917 - val_loss: -0.1413 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.2862 - val_output_seg_loss: -0.1500 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: -0.2041 - output_dis_loss: 0.0109 - output_dis_mse_score: 0.0109 - output_seg_dice_coef: 0.3713 - output_seg_loss: -0.2173\n",
      "Epoch 3: val_output_seg_dice_coef improved from 0.28616 to 0.33012, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.2047 - output_dis_loss: 0.0109 - output_dis_mse_score: 0.0109 - output_seg_dice_coef: 0.3717 - output_seg_loss: -0.2179 - val_loss: -0.2068 - val_output_dis_loss: 0.0070 - val_output_dis_mse_score: 0.0070 - val_output_seg_dice_coef: 0.3301 - val_output_seg_loss: -0.2138 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.2480 - output_dis_loss: 0.0106 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.4086 - output_seg_loss: -0.2584\n",
      "Epoch 4: val_output_seg_dice_coef improved from 0.33012 to 0.42024, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.2482 - output_dis_loss: 0.0105 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.4086 - output_seg_loss: -0.2586 - val_loss: -0.3259 - val_output_dis_loss: 0.0072 - val_output_dis_mse_score: 0.0072 - val_output_seg_dice_coef: 0.4202 - val_output_seg_loss: -0.3331 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: -0.2745 - output_dis_loss: 0.0108 - output_dis_mse_score: 0.0108 - output_seg_dice_coef: 0.4342 - output_seg_loss: -0.2844\n",
      "Epoch 5: val_output_seg_dice_coef improved from 0.42024 to 0.45640, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.2748 - output_dis_loss: 0.0108 - output_dis_mse_score: 0.0107 - output_seg_dice_coef: 0.4343 - output_seg_loss: -0.2846 - val_loss: -0.3663 - val_output_dis_loss: 0.0066 - val_output_dis_mse_score: 0.0066 - val_output_seg_dice_coef: 0.4564 - val_output_seg_loss: -0.3729 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.3645 - output_dis_loss: 0.0100 - output_dis_mse_score: 0.0099 - output_seg_dice_coef: 0.5305 - output_seg_loss: -0.3724\n",
      "Epoch 6: val_output_seg_dice_coef improved from 0.45640 to 0.56491, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.3651 - output_dis_loss: 0.0100 - output_dis_mse_score: 0.0099 - output_seg_dice_coef: 0.5311 - output_seg_loss: -0.3730 - val_loss: -0.4714 - val_output_dis_loss: 0.0061 - val_output_dis_mse_score: 0.0061 - val_output_seg_dice_coef: 0.5649 - val_output_seg_loss: -0.4775 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.3761 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5555 - output_seg_loss: -0.3828\n",
      "Epoch 7: val_output_seg_dice_coef improved from 0.56491 to 0.56915, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.3767 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5557 - output_seg_loss: -0.3834 - val_loss: -0.4731 - val_output_dis_loss: 0.0059 - val_output_dis_mse_score: 0.0059 - val_output_seg_dice_coef: 0.5691 - val_output_seg_loss: -0.4790 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.3971 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.5659 - output_seg_loss: -0.4043\n",
      "Epoch 8: val_output_seg_dice_coef did not improve from 0.56915\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.3975 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0094 - output_seg_dice_coef: 0.5662 - output_seg_loss: -0.4047 - val_loss: -0.4481 - val_output_dis_loss: 0.0059 - val_output_dis_mse_score: 0.0059 - val_output_seg_dice_coef: 0.5584 - val_output_seg_loss: -0.4540 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: -0.4204 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5818 - output_seg_loss: -0.4272\n",
      "Epoch 9: val_output_seg_dice_coef improved from 0.56915 to 0.61295, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 429ms/step - loss: -0.4209 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5821 - output_seg_loss: -0.4277 - val_loss: -0.5278 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.6129 - val_output_seg_loss: -0.5331 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.4479 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6055 - output_seg_loss: -0.4551\n",
      "Epoch 10: val_output_seg_dice_coef did not improve from 0.61295\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.4481 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.6056 - output_seg_loss: -0.4553 - val_loss: -0.4207 - val_output_dis_loss: 0.0061 - val_output_dis_mse_score: 0.0061 - val_output_seg_dice_coef: 0.5307 - val_output_seg_loss: -0.4268 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.4706 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.6195 - output_seg_loss: -0.4752\n",
      "Epoch 11: val_output_seg_dice_coef improved from 0.61295 to 0.61395, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 427ms/step - loss: -0.4708 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.6195 - output_seg_loss: -0.4754 - val_loss: -0.5324 - val_output_dis_loss: 0.0056 - val_output_dis_mse_score: 0.0056 - val_output_seg_dice_coef: 0.6139 - val_output_seg_loss: -0.5380 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.4981 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6381 - output_seg_loss: -0.5045\n",
      "Epoch 12: val_output_seg_dice_coef did not improve from 0.61395\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 407ms/step - loss: -0.4978 - output_dis_loss: 0.0078 - output_dis_mse_score: 0.0078 - output_seg_dice_coef: 0.6379 - output_seg_loss: -0.5043 - val_loss: -0.5093 - val_output_dis_loss: 0.0052 - val_output_dis_mse_score: 0.0052 - val_output_seg_dice_coef: 0.6036 - val_output_seg_loss: -0.5145 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.5044 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6421 - output_seg_loss: -0.5099\n",
      "Epoch 13: val_output_seg_dice_coef improved from 0.61395 to 0.61403, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.5044 - output_dis_loss: 0.0075 - output_dis_mse_score: 0.0074 - output_seg_dice_coef: 0.6420 - output_seg_loss: -0.5099 - val_loss: -0.5300 - val_output_dis_loss: 0.0053 - val_output_dis_mse_score: 0.0053 - val_output_seg_dice_coef: 0.6140 - val_output_seg_loss: -0.5353 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.5135 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6456 - output_seg_loss: -0.5194\n",
      "Epoch 14: val_output_seg_dice_coef improved from 0.61403 to 0.64938, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.5136 - output_dis_loss: 0.0070 - output_dis_mse_score: 0.0070 - output_seg_dice_coef: 0.6458 - output_seg_loss: -0.5195 - val_loss: -0.5705 - val_output_dis_loss: 0.0047 - val_output_dis_mse_score: 0.0047 - val_output_seg_dice_coef: 0.6494 - val_output_seg_loss: -0.5752 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.5294 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6583 - output_seg_loss: -0.5350\n",
      "Epoch 15: val_output_seg_dice_coef did not improve from 0.64938\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 406ms/step - loss: -0.5286 - output_dis_loss: 0.0067 - output_dis_mse_score: 0.0067 - output_seg_dice_coef: 0.6579 - output_seg_loss: -0.5342 - val_loss: -0.4811 - val_output_dis_loss: 0.0056 - val_output_dis_mse_score: 0.0056 - val_output_seg_dice_coef: 0.5788 - val_output_seg_loss: -0.4867 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.5257 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6547 - output_seg_loss: -0.5321\n",
      "Epoch 16: val_output_seg_dice_coef did not improve from 0.64938\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.5256 - output_dis_loss: 0.0068 - output_dis_mse_score: 0.0068 - output_seg_dice_coef: 0.6547 - output_seg_loss: -0.5320 - val_loss: -0.3851 - val_output_dis_loss: 0.0060 - val_output_dis_mse_score: 0.0060 - val_output_seg_dice_coef: 0.4934 - val_output_seg_loss: -0.3911 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.5514 - output_dis_loss: 0.0062 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.6702 - output_seg_loss: -0.5568\n",
      "Epoch 17: val_output_seg_dice_coef improved from 0.64938 to 0.66853, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.5512 - output_dis_loss: 0.0063 - output_dis_mse_score: 0.0062 - output_seg_dice_coef: 0.6702 - output_seg_loss: -0.5567 - val_loss: -0.5926 - val_output_dis_loss: 0.0042 - val_output_dis_mse_score: 0.0042 - val_output_seg_dice_coef: 0.6685 - val_output_seg_loss: -0.5968 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.5640 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.6774 - output_seg_loss: -0.5690\n",
      "Epoch 18: val_output_seg_dice_coef did not improve from 0.66853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.5635 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.6773 - output_seg_loss: -0.5685 - val_loss: -0.5749 - val_output_dis_loss: 0.0048 - val_output_dis_mse_score: 0.0048 - val_output_seg_dice_coef: 0.6477 - val_output_seg_loss: -0.5797 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.5542 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.6668 - output_seg_loss: -0.5599\n",
      "Epoch 19: val_output_seg_dice_coef improved from 0.66853 to 0.68762, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.5543 - output_dis_loss: 0.0060 - output_dis_mse_score: 0.0060 - output_seg_dice_coef: 0.6672 - output_seg_loss: -0.5601 - val_loss: -0.6179 - val_output_dis_loss: 0.0039 - val_output_dis_mse_score: 0.0039 - val_output_seg_dice_coef: 0.6876 - val_output_seg_loss: -0.6218 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.5487 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.6679 - output_seg_loss: -0.5544\n",
      "Epoch 20: val_output_seg_dice_coef improved from 0.68762 to 0.68766, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.5488 - output_dis_loss: 0.0061 - output_dis_mse_score: 0.0061 - output_seg_dice_coef: 0.6682 - output_seg_loss: -0.5545 - val_loss: -0.6187 - val_output_dis_loss: 0.0036 - val_output_dis_mse_score: 0.0036 - val_output_seg_dice_coef: 0.6877 - val_output_seg_loss: -0.6223 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.5970 - output_dis_loss: 0.0055 - output_dis_mse_score: 0.0055 - output_seg_dice_coef: 0.6990 - output_seg_loss: -0.6025\n",
      "Epoch 21: val_output_seg_dice_coef did not improve from 0.68766\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 403ms/step - loss: -0.5971 - output_dis_loss: 0.0055 - output_dis_mse_score: 0.0055 - output_seg_dice_coef: 0.6993 - output_seg_loss: -0.6026 - val_loss: -0.6126 - val_output_dis_loss: 0.0038 - val_output_dis_mse_score: 0.0038 - val_output_seg_dice_coef: 0.6857 - val_output_seg_loss: -0.6164 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.5903 - output_dis_loss: 0.0055 - output_dis_mse_score: 0.0055 - output_seg_dice_coef: 0.6989 - output_seg_loss: -0.5959\n",
      "Epoch 22: val_output_seg_dice_coef improved from 0.68766 to 0.68958, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.5908 - output_dis_loss: 0.0055 - output_dis_mse_score: 0.0055 - output_seg_dice_coef: 0.6994 - output_seg_loss: -0.5964 - val_loss: -0.6172 - val_output_dis_loss: 0.0038 - val_output_dis_mse_score: 0.0038 - val_output_seg_dice_coef: 0.6896 - val_output_seg_loss: -0.6210 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.5973 - output_dis_loss: 0.0052 - output_dis_mse_score: 0.0052 - output_seg_dice_coef: 0.7000 - output_seg_loss: -0.6026\n",
      "Epoch 23: val_output_seg_dice_coef improved from 0.68958 to 0.69184, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.5978 - output_dis_loss: 0.0052 - output_dis_mse_score: 0.0052 - output_seg_dice_coef: 0.7006 - output_seg_loss: -0.6031 - val_loss: -0.6185 - val_output_dis_loss: 0.0038 - val_output_dis_mse_score: 0.0038 - val_output_seg_dice_coef: 0.6918 - val_output_seg_loss: -0.6223 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6014 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7066 - output_seg_loss: -0.6068\n",
      "Epoch 24: val_output_seg_dice_coef did not improve from 0.69184\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 403ms/step - loss: -0.6019 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7071 - output_seg_loss: -0.6073 - val_loss: -0.6146 - val_output_dis_loss: 0.0039 - val_output_dis_mse_score: 0.0039 - val_output_seg_dice_coef: 0.6895 - val_output_seg_loss: -0.6184 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: -0.6078 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7145 - output_seg_loss: -0.6132\n",
      "Epoch 25: val_output_seg_dice_coef did not improve from 0.69184\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 402ms/step - loss: -0.6082 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7148 - output_seg_loss: -0.6137 - val_loss: -0.6084 - val_output_dis_loss: 0.0039 - val_output_dis_mse_score: 0.0039 - val_output_seg_dice_coef: 0.6861 - val_output_seg_loss: -0.6123 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.6164 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7224 - output_seg_loss: -0.6218\n",
      "Epoch 26: val_output_seg_dice_coef did not improve from 0.69184\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 402ms/step - loss: -0.6167 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7227 - output_seg_loss: -0.6221 - val_loss: -0.6123 - val_output_dis_loss: 0.0038 - val_output_dis_mse_score: 0.0038 - val_output_seg_dice_coef: 0.6893 - val_output_seg_loss: -0.6161 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6178 - output_dis_loss: 0.0055 - output_dis_mse_score: 0.0055 - output_seg_dice_coef: 0.7263 - output_seg_loss: -0.6235\n",
      "Epoch 27: val_output_seg_dice_coef did not improve from 0.69184\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 403ms/step - loss: -0.6182 - output_dis_loss: 0.0055 - output_dis_mse_score: 0.0055 - output_seg_dice_coef: 0.7264 - output_seg_loss: -0.6238 - val_loss: -0.6061 - val_output_dis_loss: 0.0039 - val_output_dis_mse_score: 0.0039 - val_output_seg_dice_coef: 0.6855 - val_output_seg_loss: -0.6100 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.6220 - output_dis_loss: 0.0054 - output_dis_mse_score: 0.0054 - output_seg_dice_coef: 0.7303 - output_seg_loss: -0.6275\n",
      "Epoch 28: val_output_seg_dice_coef improved from 0.69184 to 0.69259, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.6223 - output_dis_loss: 0.0054 - output_dis_mse_score: 0.0054 - output_seg_dice_coef: 0.7305 - output_seg_loss: -0.6278 - val_loss: -0.6140 - val_output_dis_loss: 0.0038 - val_output_dis_mse_score: 0.0038 - val_output_seg_dice_coef: 0.6926 - val_output_seg_loss: -0.6178 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.6331 - output_dis_loss: 0.0051 - output_dis_mse_score: 0.0051 - output_seg_dice_coef: 0.7367 - output_seg_loss: -0.6384\n",
      "Epoch 29: val_output_seg_dice_coef improved from 0.69259 to 0.69340, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.6332 - output_dis_loss: 0.0051 - output_dis_mse_score: 0.0051 - output_seg_dice_coef: 0.7367 - output_seg_loss: -0.6385 - val_loss: -0.6143 - val_output_dis_loss: 0.0037 - val_output_dis_mse_score: 0.0037 - val_output_seg_dice_coef: 0.6934 - val_output_seg_loss: -0.6181 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.6345 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7408 - output_seg_loss: -0.6398\n",
      "Epoch 30: val_output_seg_dice_coef improved from 0.69340 to 0.69622, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6347 - output_dis_loss: 0.0053 - output_dis_mse_score: 0.0053 - output_seg_dice_coef: 0.7409 - output_seg_loss: -0.6400 - val_loss: -0.6171 - val_output_dis_loss: 0.0037 - val_output_dis_mse_score: 0.0037 - val_output_seg_dice_coef: 0.6962 - val_output_seg_loss: -0.6207 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 31/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.6397 - output_dis_loss: 0.0052 - output_dis_mse_score: 0.0052 - output_seg_dice_coef: 0.7451 - output_seg_loss: -0.6450\n",
      "Epoch 31: val_output_seg_dice_coef did not improve from 0.69622\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.6398 - output_dis_loss: 0.0052 - output_dis_mse_score: 0.0052 - output_seg_dice_coef: 0.7451 - output_seg_loss: -0.6451 - val_loss: -0.6056 - val_output_dis_loss: 0.0038 - val_output_dis_mse_score: 0.0038 - val_output_seg_dice_coef: 0.6887 - val_output_seg_loss: -0.6094 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 32/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: -0.6529 - output_dis_loss: 0.0050 - output_dis_mse_score: 0.0050 - output_seg_dice_coef: 0.7554 - output_seg_loss: -0.6580\n",
      "Epoch 32: val_output_seg_dice_coef did not improve from 0.69622\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.6528 - output_dis_loss: 0.0050 - output_dis_mse_score: 0.0050 - output_seg_dice_coef: 0.7552 - output_seg_loss: -0.6579 - val_loss: -0.6141 - val_output_dis_loss: 0.0037 - val_output_dis_mse_score: 0.0037 - val_output_seg_dice_coef: 0.6955 - val_output_seg_loss: -0.6178 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 33/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.6502 - output_dis_loss: 0.0050 - output_dis_mse_score: 0.0050 - output_seg_dice_coef: 0.7554 - output_seg_loss: -0.6554\n",
      "Epoch 33: val_output_seg_dice_coef improved from 0.69622 to 0.69973, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.6503 - output_dis_loss: 0.0050 - output_dis_mse_score: 0.0050 - output_seg_dice_coef: 0.7553 - output_seg_loss: -0.6554 - val_loss: -0.6188 - val_output_dis_loss: 0.0037 - val_output_dis_mse_score: 0.0037 - val_output_seg_dice_coef: 0.6997 - val_output_seg_loss: -0.6225 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 34/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: -0.6480 - output_dis_loss: 0.0052 - output_dis_mse_score: 0.0052 - output_seg_dice_coef: 0.7548 - output_seg_loss: -0.6533\n",
      "Epoch 34: val_output_seg_dice_coef improved from 0.69973 to 0.70556, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.6481 - output_dis_loss: 0.0052 - output_dis_mse_score: 0.0052 - output_seg_dice_coef: 0.7547 - output_seg_loss: -0.6534 - val_loss: -0.6266 - val_output_dis_loss: 0.0036 - val_output_dis_mse_score: 0.0036 - val_output_seg_dice_coef: 0.7056 - val_output_seg_loss: -0.6302 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 35/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.6581 - output_dis_loss: 0.0049 - output_dis_mse_score: 0.0049 - output_seg_dice_coef: 0.7598 - output_seg_loss: -0.6631\n",
      "Epoch 35: val_output_seg_dice_coef improved from 0.70556 to 0.70962, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.6581 - output_dis_loss: 0.0049 - output_dis_mse_score: 0.0049 - output_seg_dice_coef: 0.7596 - output_seg_loss: -0.6631 - val_loss: -0.6319 - val_output_dis_loss: 0.0035 - val_output_dis_mse_score: 0.0035 - val_output_seg_dice_coef: 0.7096 - val_output_seg_loss: -0.6354 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 36/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6551 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7543 - output_seg_loss: -0.6600\n",
      "Epoch 36: val_output_seg_dice_coef did not improve from 0.70962\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 404ms/step - loss: -0.6552 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7543 - output_seg_loss: -0.6600 - val_loss: -0.6242 - val_output_dis_loss: 0.0037 - val_output_dis_mse_score: 0.0037 - val_output_seg_dice_coef: 0.7044 - val_output_seg_loss: -0.6279 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 37/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.6566 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7549 - output_seg_loss: -0.6614\n",
      "Epoch 37: val_output_seg_dice_coef did not improve from 0.70962\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 406ms/step - loss: -0.6566 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7549 - output_seg_loss: -0.6615 - val_loss: -0.6267 - val_output_dis_loss: 0.0037 - val_output_dis_mse_score: 0.0037 - val_output_seg_dice_coef: 0.7070 - val_output_seg_loss: -0.6304 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 38/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.6602 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7593 - output_seg_loss: -0.6650\n",
      "Epoch 38: val_output_seg_dice_coef did not improve from 0.70962\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6603 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7593 - output_seg_loss: -0.6651 - val_loss: -0.6275 - val_output_dis_loss: 0.0036 - val_output_dis_mse_score: 0.0036 - val_output_seg_dice_coef: 0.7075 - val_output_seg_loss: -0.6311 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 39/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.6687 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7630 - output_seg_loss: -0.6732\n",
      "Epoch 39: val_output_seg_dice_coef did not improve from 0.70962\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 407ms/step - loss: -0.6686 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7630 - output_seg_loss: -0.6732 - val_loss: -0.6279 - val_output_dis_loss: 0.0036 - val_output_dis_mse_score: 0.0036 - val_output_seg_dice_coef: 0.7083 - val_output_seg_loss: -0.6315 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 40/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.6712 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7673 - output_seg_loss: -0.6758\n",
      "Epoch 40: val_output_seg_dice_coef improved from 0.70962 to 0.71312, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.6712 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7672 - output_seg_loss: -0.6758 - val_loss: -0.6352 - val_output_dis_loss: 0.0035 - val_output_dis_mse_score: 0.0035 - val_output_seg_dice_coef: 0.7131 - val_output_seg_loss: -0.6387 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 41/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.6818 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7735 - output_seg_loss: -0.6862\n",
      "Epoch 41: val_output_seg_dice_coef did not improve from 0.71312\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6817 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7734 - output_seg_loss: -0.6861 - val_loss: -0.6359 - val_output_dis_loss: 0.0035 - val_output_dis_mse_score: 0.0035 - val_output_seg_dice_coef: 0.7123 - val_output_seg_loss: -0.6393 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 42/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.6857 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6900\n",
      "Epoch 42: val_output_seg_dice_coef improved from 0.71312 to 0.71578, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.6855 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7756 - output_seg_loss: -0.6897 - val_loss: -0.6406 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7158 - val_output_seg_loss: -0.6440 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 43/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.6894 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7766 - output_seg_loss: -0.6935\n",
      "Epoch 43: val_output_seg_dice_coef did not improve from 0.71578\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.6891 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7765 - output_seg_loss: -0.6933 - val_loss: -0.6399 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7151 - val_output_seg_loss: -0.6433 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 44/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.6904 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7783 - output_seg_loss: -0.6951\n",
      "Epoch 44: val_output_seg_dice_coef did not improve from 0.71578\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.6901 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7781 - output_seg_loss: -0.6948 - val_loss: -0.6376 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7136 - val_output_seg_loss: -0.6410 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 45/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.6917 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7792 - output_seg_loss: -0.6966\n",
      "Epoch 45: val_output_seg_dice_coef improved from 0.71578 to 0.71634, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.6914 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7790 - output_seg_loss: -0.6964 - val_loss: -0.6410 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7163 - val_output_seg_loss: -0.6444 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 46/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.6824 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7785 - output_seg_loss: -0.6881\n",
      "Epoch 46: val_output_seg_dice_coef improved from 0.71634 to 0.71753, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6824 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7783 - output_seg_loss: -0.6880 - val_loss: -0.6427 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7175 - val_output_seg_loss: -0.6461 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 47/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.6800 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7783 - output_seg_loss: -0.6855\n",
      "Epoch 47: val_output_seg_dice_coef improved from 0.71753 to 0.71820, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.6800 - output_dis_loss: 0.0047 - output_dis_mse_score: 0.0047 - output_seg_dice_coef: 0.7781 - output_seg_loss: -0.6855 - val_loss: -0.6437 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7182 - val_output_seg_loss: -0.6470 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 48/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.6813 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7768 - output_seg_loss: -0.6868\n",
      "Epoch 48: val_output_seg_dice_coef did not improve from 0.71820\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 407ms/step - loss: -0.6813 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7767 - output_seg_loss: -0.6868 - val_loss: -0.6411 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7166 - val_output_seg_loss: -0.6445 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 49/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6755 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7707 - output_seg_loss: -0.6813\n",
      "Epoch 49: val_output_seg_dice_coef improved from 0.71820 to 0.72081, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.6756 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7707 - output_seg_loss: -0.6814 - val_loss: -0.6470 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7208 - val_output_seg_loss: -0.6503 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 50/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.6766 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7701 - output_seg_loss: -0.6821\n",
      "Epoch 50: val_output_seg_dice_coef did not improve from 0.72081\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.6767 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7702 - output_seg_loss: -0.6821 - val_loss: -0.6447 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7193 - val_output_seg_loss: -0.6481 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 51/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: -0.6836 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7741 - output_seg_loss: -0.6888\n",
      "Epoch 51: val_output_seg_dice_coef did not improve from 0.72081\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.6835 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7740 - output_seg_loss: -0.6888 - val_loss: -0.6462 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7205 - val_output_seg_loss: -0.6496 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 52/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.6837 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6890\n",
      "Epoch 52: val_output_seg_dice_coef improved from 0.72081 to 0.72127, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.6837 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7757 - output_seg_loss: -0.6889 - val_loss: -0.6471 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7213 - val_output_seg_loss: -0.6504 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 53/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6863 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7779 - output_seg_loss: -0.6914\n",
      "Epoch 53: val_output_seg_dice_coef improved from 0.72127 to 0.72270, saving model to /kaggle/working/output_model/unet_1.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.6862 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7778 - output_seg_loss: -0.6913 - val_loss: -0.6492 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7227 - val_output_seg_loss: -0.6525 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 54/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.6817 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7736 - output_seg_loss: -0.6868\n",
      "Epoch 54: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.6818 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7736 - output_seg_loss: -0.6868 - val_loss: -0.6466 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7209 - val_output_seg_loss: -0.6499 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 55/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.6852 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7756 - output_seg_loss: -0.6902\n",
      "Epoch 55: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 407ms/step - loss: -0.6852 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7756 - output_seg_loss: -0.6902 - val_loss: -0.6439 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7190 - val_output_seg_loss: -0.6472 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 56/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.6803 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7682 - output_seg_loss: -0.6852\n",
      "Epoch 56: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.6803 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7683 - output_seg_loss: -0.6852 - val_loss: -0.6474 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7217 - val_output_seg_loss: -0.6507 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 57/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: -0.6864 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7720 - output_seg_loss: -0.6912\n",
      "Epoch 57: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.6863 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7720 - output_seg_loss: -0.6912 - val_loss: -0.6450 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7201 - val_output_seg_loss: -0.6484 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 58/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.6825 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7688 - output_seg_loss: -0.6872\n",
      "Epoch 58: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.6825 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7689 - output_seg_loss: -0.6872 - val_loss: -0.6450 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7201 - val_output_seg_loss: -0.6483 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 59/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: -0.6884 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7724 - output_seg_loss: -0.6929\n",
      "Epoch 59: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 428ms/step - loss: -0.6882 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7724 - output_seg_loss: -0.6928 - val_loss: -0.6453 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7203 - val_output_seg_loss: -0.6487 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 60/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: -0.6898 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7729 - output_seg_loss: -0.6943\n",
      "Epoch 60: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.6896 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7730 - output_seg_loss: -0.6941 - val_loss: -0.6443 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7198 - val_output_seg_loss: -0.6477 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 61/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.6921 - output_dis_loss: 0.0039 - output_dis_mse_score: 0.0039 - output_seg_dice_coef: 0.7730 - output_seg_loss: -0.6964\n",
      "Epoch 61: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.6920 - output_dis_loss: 0.0039 - output_dis_mse_score: 0.0039 - output_seg_dice_coef: 0.7731 - output_seg_loss: -0.6963 - val_loss: -0.6431 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7189 - val_output_seg_loss: -0.6465 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 62/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.6873 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7710 - output_seg_loss: -0.6917\n",
      "Epoch 62: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6872 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7711 - output_seg_loss: -0.6916 - val_loss: -0.6420 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7181 - val_output_seg_loss: -0.6453 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 63/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.6925 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7750 - output_seg_loss: -0.6968\n",
      "Epoch 63: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.6924 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7750 - output_seg_loss: -0.6967 - val_loss: -0.6410 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7174 - val_output_seg_loss: -0.6443 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 64/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.6756 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7643 - output_seg_loss: -0.6802\n",
      "Epoch 64: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.6758 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7646 - output_seg_loss: -0.6805 - val_loss: -0.6416 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7178 - val_output_seg_loss: -0.6450 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 65/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.6759 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7607 - output_seg_loss: -0.6803\n",
      "Epoch 65: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 406ms/step - loss: -0.6761 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7610 - output_seg_loss: -0.6805 - val_loss: -0.6418 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7180 - val_output_seg_loss: -0.6452 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 66/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: -0.6726 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7616 - output_seg_loss: -0.6771\n",
      "Epoch 66: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 402ms/step - loss: -0.6729 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7619 - output_seg_loss: -0.6774 - val_loss: -0.6413 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7177 - val_output_seg_loss: -0.6447 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 67/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: -0.6715 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7634 - output_seg_loss: -0.6761\n",
      "Epoch 67: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 402ms/step - loss: -0.6718 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7636 - output_seg_loss: -0.6764 - val_loss: -0.6417 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7179 - val_output_seg_loss: -0.6451 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 68/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: -0.6757 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7675 - output_seg_loss: -0.6804\n",
      "Epoch 68: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 401ms/step - loss: -0.6759 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7677 - output_seg_loss: -0.6806 - val_loss: -0.6427 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7187 - val_output_seg_loss: -0.6460 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 69/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: -0.6762 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7703 - output_seg_loss: -0.6810\n",
      "Epoch 69: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.6764 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7704 - output_seg_loss: -0.6812 - val_loss: -0.6425 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7186 - val_output_seg_loss: -0.6459 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 70/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.6763 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7716 - output_seg_loss: -0.6811\n",
      "Epoch 70: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.6765 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7716 - output_seg_loss: -0.6813 - val_loss: -0.6429 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7188 - val_output_seg_loss: -0.6462 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 71/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.6819 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7735 - output_seg_loss: -0.6865\n",
      "Epoch 71: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.6820 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7735 - output_seg_loss: -0.6866 - val_loss: -0.6429 - val_output_dis_loss: 0.0034 - val_output_dis_mse_score: 0.0034 - val_output_seg_dice_coef: 0.7188 - val_output_seg_loss: -0.6462 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 72/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.6784 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7736 - output_seg_loss: -0.6831\n",
      "Epoch 72: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.6785 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7736 - output_seg_loss: -0.6832 - val_loss: -0.6429 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7189 - val_output_seg_loss: -0.6463 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 73/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: -0.6812 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6858\n",
      "Epoch 73: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 404ms/step - loss: -0.6812 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7757 - output_seg_loss: -0.6859 - val_loss: -0.6435 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7193 - val_output_seg_loss: -0.6469 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 74/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.6868 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7804 - output_seg_loss: -0.6914\n",
      "Epoch 74: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 406ms/step - loss: -0.6868 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7803 - output_seg_loss: -0.6913 - val_loss: -0.6439 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7196 - val_output_seg_loss: -0.6473 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 75/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: -0.6830 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7791 - output_seg_loss: -0.6876\n",
      "Epoch 75: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 404ms/step - loss: -0.6830 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7790 - output_seg_loss: -0.6877 - val_loss: -0.6441 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7197 - val_output_seg_loss: -0.6474 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 76/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.6797 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7775 - output_seg_loss: -0.6845\n",
      "Epoch 76: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 407ms/step - loss: -0.6798 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7774 - output_seg_loss: -0.6846 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6472 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 77/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.6856 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7797 - output_seg_loss: -0.6901\n",
      "Epoch 77: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6855 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7796 - output_seg_loss: -0.6901 - val_loss: -0.6430 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7189 - val_output_seg_loss: -0.6464 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 78/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.6808 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7721 - output_seg_loss: -0.6853\n",
      "Epoch 78: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.6809 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7722 - output_seg_loss: -0.6853 - val_loss: -0.6435 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6468 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 79/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: -0.6814 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7724 - output_seg_loss: -0.6858\n",
      "Epoch 79: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 405ms/step - loss: -0.6815 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7724 - output_seg_loss: -0.6859 - val_loss: -0.6435 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7193 - val_output_seg_loss: -0.6469 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 80/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.6847 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6890\n",
      "Epoch 80: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.6846 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6890 - val_loss: -0.6433 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7191 - val_output_seg_loss: -0.6466 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 81/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.6877 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6920\n",
      "Epoch 81: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6877 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6919 - val_loss: -0.6433 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7191 - val_output_seg_loss: -0.6466 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 82/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.6853 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7764 - output_seg_loss: -0.6896\n",
      "Epoch 82: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 403ms/step - loss: -0.6852 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7764 - output_seg_loss: -0.6896 - val_loss: -0.6433 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7191 - val_output_seg_loss: -0.6466 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 83/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.6902 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7784 - output_seg_loss: -0.6943\n",
      "Epoch 83: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6900 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7783 - output_seg_loss: -0.6942 - val_loss: -0.6433 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 84/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.6945 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7818 - output_seg_loss: -0.6986\n",
      "Epoch 84: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6942 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7816 - output_seg_loss: -0.6983 - val_loss: -0.6434 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 85/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: -0.6940 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7801 - output_seg_loss: -0.6981\n",
      "Epoch 85: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.6938 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7799 - output_seg_loss: -0.6979 - val_loss: -0.6434 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 86/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: -0.6977 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7838 - output_seg_loss: -0.7027\n",
      "Epoch 86: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.6974 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7836 - output_seg_loss: -0.7024 - val_loss: -0.6433 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7191 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 87/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.6960 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7828 - output_seg_loss: -0.7011\n",
      "Epoch 87: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 406ms/step - loss: -0.6958 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7826 - output_seg_loss: -0.7008 - val_loss: -0.6434 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 88/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6864 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7815 - output_seg_loss: -0.6922\n",
      "Epoch 88: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 403ms/step - loss: -0.6864 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7813 - output_seg_loss: -0.6921 - val_loss: -0.6434 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 89/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.6836 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7816 - output_seg_loss: -0.6896\n",
      "Epoch 89: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.6836 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7814 - output_seg_loss: -0.6896 - val_loss: -0.6434 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6467 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 90/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.6859 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7803 - output_seg_loss: -0.6917\n",
      "Epoch 90: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6859 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7802 - output_seg_loss: -0.6917 - val_loss: -0.6434 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7192 - val_output_seg_loss: -0.6468 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 91/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: -0.6815 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7753 - output_seg_loss: -0.6872\n",
      "Epoch 91: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.6816 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7753 - output_seg_loss: -0.6873 - val_loss: -0.6435 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7193 - val_output_seg_loss: -0.6468 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 92/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.6818 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7741 - output_seg_loss: -0.6873\n",
      "Epoch 92: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.6819 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7741 - output_seg_loss: -0.6873 - val_loss: -0.6435 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7193 - val_output_seg_loss: -0.6469 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 93/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.6865 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7765 - output_seg_loss: -0.6919\n",
      "Epoch 93: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.6864 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7764 - output_seg_loss: -0.6918 - val_loss: -0.6436 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7194 - val_output_seg_loss: -0.6469 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 94/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.6854 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7770 - output_seg_loss: -0.6906\n",
      "Epoch 94: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.6854 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7770 - output_seg_loss: -0.6905 - val_loss: -0.6437 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7194 - val_output_seg_loss: -0.6470 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 95/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.6893 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7802 - output_seg_loss: -0.6945\n",
      "Epoch 95: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6892 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7800 - output_seg_loss: -0.6944 - val_loss: -0.6437 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7194 - val_output_seg_loss: -0.6470 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 96/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.6847 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7759 - output_seg_loss: -0.6897\n",
      "Epoch 96: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.6847 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7759 - output_seg_loss: -0.6897 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 97/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.6886 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7780 - output_seg_loss: -0.6935\n",
      "Epoch 97: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.6886 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7780 - output_seg_loss: -0.6935 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 98/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.6836 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7702 - output_seg_loss: -0.6885\n",
      "Epoch 98: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.6836 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7704 - output_seg_loss: -0.6885 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6472 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 99/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.6882 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7733 - output_seg_loss: -0.6929\n",
      "Epoch 99: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6882 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7734 - output_seg_loss: -0.6929 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 100/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.6845 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7703 - output_seg_loss: -0.6891\n",
      "Epoch 100: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.6845 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7704 - output_seg_loss: -0.6891 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 101/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.6931 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6974\n",
      "Epoch 101: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.6929 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7757 - output_seg_loss: -0.6972 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 102/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.6933 - output_dis_loss: 0.0039 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7756 - output_seg_loss: -0.6978\n",
      "Epoch 102: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.6931 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7756 - output_seg_loss: -0.6976 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 103/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.6922 - output_dis_loss: 0.0039 - output_dis_mse_score: 0.0039 - output_seg_dice_coef: 0.7733 - output_seg_loss: -0.6966\n",
      "Epoch 103: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.6921 - output_dis_loss: 0.0039 - output_dis_mse_score: 0.0039 - output_seg_dice_coef: 0.7734 - output_seg_loss: -0.6965 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 104/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.6869 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7710 - output_seg_loss: -0.6913\n",
      "Epoch 104: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.6868 - output_dis_loss: 0.0041 - output_dis_mse_score: 0.0041 - output_seg_dice_coef: 0.7711 - output_seg_loss: -0.6912 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 105/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.6916 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7745 - output_seg_loss: -0.6961\n",
      "Epoch 105: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.6915 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7745 - output_seg_loss: -0.6960 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 106/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.6755 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7641 - output_seg_loss: -0.6801\n",
      "Epoch 106: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.6758 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7644 - output_seg_loss: -0.6803 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 107/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.6751 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7602 - output_seg_loss: -0.6793\n",
      "Epoch 107: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.6753 - output_dis_loss: 0.0040 - output_dis_mse_score: 0.0040 - output_seg_dice_coef: 0.7605 - output_seg_loss: -0.6796 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 108/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.6730 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7618 - output_seg_loss: -0.6776\n",
      "Epoch 108: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.6733 - output_dis_loss: 0.0042 - output_dis_mse_score: 0.0042 - output_seg_dice_coef: 0.7621 - output_seg_loss: -0.6779 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 109/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.6716 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7637 - output_seg_loss: -0.6763\n",
      "Epoch 109: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.6719 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7639 - output_seg_loss: -0.6766 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 110/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.6763 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7678 - output_seg_loss: -0.6809\n",
      "Epoch 110: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.6765 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7680 - output_seg_loss: -0.6811 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 111/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.6768 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7704 - output_seg_loss: -0.6815\n",
      "Epoch 111: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 406ms/step - loss: -0.6770 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7705 - output_seg_loss: -0.6817 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 112/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.6789 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7730 - output_seg_loss: -0.6836\n",
      "Epoch 112: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.6791 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7730 - output_seg_loss: -0.6838 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 113/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.6827 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7740 - output_seg_loss: -0.6873\n",
      "Epoch 113: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 407ms/step - loss: -0.6828 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7741 - output_seg_loss: -0.6874 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 114/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6774 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7728 - output_seg_loss: -0.6821\n",
      "Epoch 114: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 403ms/step - loss: -0.6775 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7728 - output_seg_loss: -0.6823 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 115/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.6815 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7759 - output_seg_loss: -0.6862\n",
      "Epoch 115: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.6815 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7758 - output_seg_loss: -0.6862 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 116/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.6898 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7822 - output_seg_loss: -0.6943\n",
      "Epoch 116: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.6897 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7820 - output_seg_loss: -0.6942 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 117/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: -0.6830 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7792 - output_seg_loss: -0.6876\n",
      "Epoch 117: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 403ms/step - loss: -0.6830 - output_dis_loss: 0.0045 - output_dis_mse_score: 0.0045 - output_seg_dice_coef: 0.7791 - output_seg_loss: -0.6877 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 118/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: -0.6800 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7776 - output_seg_loss: -0.6847\n",
      "Epoch 118: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 403ms/step - loss: -0.6801 - output_dis_loss: 0.0046 - output_dis_mse_score: 0.0046 - output_seg_dice_coef: 0.7775 - output_seg_loss: -0.6848 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 119/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.6859 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7797 - output_seg_loss: -0.6905\n",
      "Epoch 119: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.6859 - output_dis_loss: 0.0044 - output_dis_mse_score: 0.0044 - output_seg_dice_coef: 0.7796 - output_seg_loss: -0.6905 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 120/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.6835 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7740 - output_seg_loss: -0.6879\n",
      "Epoch 120: val_output_seg_dice_coef did not improve from 0.72270\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.6836 - output_dis_loss: 0.0043 - output_dis_mse_score: 0.0043 - output_seg_dice_coef: 0.7741 - output_seg_loss: -0.6880 - val_loss: -0.6438 - val_output_dis_loss: 0.0033 - val_output_dis_mse_score: 0.0033 - val_output_seg_dice_coef: 0.7195 - val_output_seg_loss: -0.6471 - learning_rate: 1.0000e-08\n",
      "\u001b[1m333/333\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [01:48<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold1: 68.59\n",
      "average AJI pure Unet for fold1: 38.91\n",
      "average PQ pure Unet for fold1: 33.94\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold1: 62.04\n",
      "average AJI Unet watershed for fold1: 35.32\n",
      "average PQ Unet watershed for fold1: 30.54\n",
      "==========\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - loss: 0.1058 - output_dis_loss: 0.0149 - output_dis_mse_score: 0.0149 - output_seg_dice_coef: 0.1946 - output_seg_loss: 0.0909\n",
      "Epoch 1: val_output_seg_dice_coef improved from -inf to 0.13272, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 540ms/step - loss: 0.1052 - output_dis_loss: 0.0149 - output_dis_mse_score: 0.0149 - output_seg_dice_coef: 0.1944 - output_seg_loss: 0.0903 - val_loss: 0.0959 - val_output_dis_loss: 0.0107 - val_output_dis_mse_score: 0.0107 - val_output_seg_dice_coef: 0.1327 - val_output_seg_loss: 0.0852 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1762438366.406780      61 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1762438366.639421      61 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: 0.0626 - output_dis_loss: 0.0139 - output_dis_mse_score: 0.0141 - output_seg_dice_coef: 0.1706 - output_seg_loss: 0.0500\n",
      "Epoch 2: val_output_seg_dice_coef improved from 0.13272 to 0.14448, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 428ms/step - loss: 0.0624 - output_dis_loss: 0.0140 - output_dis_mse_score: 0.0141 - output_seg_dice_coef: 0.1708 - output_seg_loss: 0.0498 - val_loss: 0.0792 - val_output_dis_loss: 0.0102 - val_output_dis_mse_score: 0.0102 - val_output_seg_dice_coef: 0.1445 - val_output_seg_loss: 0.0690 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: 0.0298 - output_dis_loss: 0.0142 - output_dis_mse_score: 0.0145 - output_seg_dice_coef: 0.1977 - output_seg_loss: 0.0167\n",
      "Epoch 3: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: 0.0305 - output_dis_loss: 0.0143 - output_dis_mse_score: 0.0145 - output_seg_dice_coef: 0.1977 - output_seg_loss: 0.0174 - val_loss: 0.1317 - val_output_dis_loss: 0.0103 - val_output_dis_mse_score: 0.0103 - val_output_seg_dice_coef: 0.1357 - val_output_seg_loss: 0.1213 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: 0.0738 - output_dis_loss: 0.0145 - output_dis_mse_score: 0.0147 - output_seg_dice_coef: 0.1913 - output_seg_loss: 0.0614\n",
      "Epoch 4: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: 0.0736 - output_dis_loss: 0.0145 - output_dis_mse_score: 0.0147 - output_seg_dice_coef: 0.1910 - output_seg_loss: 0.0612 - val_loss: 0.0650 - val_output_dis_loss: 0.0102 - val_output_dis_mse_score: 0.0102 - val_output_seg_dice_coef: 0.1203 - val_output_seg_loss: 0.0548 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: 0.0580 - output_dis_loss: 0.0142 - output_dis_mse_score: 0.0144 - output_seg_dice_coef: 0.1716 - output_seg_loss: 0.0442\n",
      "Epoch 5: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: 0.0580 - output_dis_loss: 0.0142 - output_dis_mse_score: 0.0144 - output_seg_dice_coef: 0.1716 - output_seg_loss: 0.0442 - val_loss: 0.0611 - val_output_dis_loss: 0.0098 - val_output_dis_mse_score: 0.0098 - val_output_seg_dice_coef: 0.1204 - val_output_seg_loss: 0.0513 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 0.0551 - output_dis_loss: 0.0139 - output_dis_mse_score: 0.0140 - output_seg_dice_coef: 0.1732 - output_seg_loss: 0.0416\n",
      "Epoch 6: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: 0.0551 - output_dis_loss: 0.0138 - output_dis_mse_score: 0.0140 - output_seg_dice_coef: 0.1732 - output_seg_loss: 0.0416 - val_loss: 0.0428 - val_output_dis_loss: 0.0093 - val_output_dis_mse_score: 0.0093 - val_output_seg_dice_coef: 0.1227 - val_output_seg_loss: 0.0335 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 0.0354 - output_dis_loss: 0.0136 - output_dis_mse_score: 0.0137 - output_seg_dice_coef: 0.1867 - output_seg_loss: 0.0225\n",
      "Epoch 7: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: 0.0357 - output_dis_loss: 0.0136 - output_dis_mse_score: 0.0137 - output_seg_dice_coef: 0.1867 - output_seg_loss: 0.0227 - val_loss: 0.1040 - val_output_dis_loss: 0.0113 - val_output_dis_mse_score: 0.0113 - val_output_seg_dice_coef: 0.1280 - val_output_seg_loss: 0.0928 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: 0.0689 - output_dis_loss: 0.0150 - output_dis_mse_score: 0.0152 - output_seg_dice_coef: 0.1720 - output_seg_loss: 0.0542\n",
      "Epoch 8: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: 0.0688 - output_dis_loss: 0.0150 - output_dis_mse_score: 0.0151 - output_seg_dice_coef: 0.1720 - output_seg_loss: 0.0541 - val_loss: 0.0607 - val_output_dis_loss: 0.0103 - val_output_dis_mse_score: 0.0103 - val_output_seg_dice_coef: 0.1118 - val_output_seg_loss: 0.0504 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: 0.0635 - output_dis_loss: 0.0147 - output_dis_mse_score: 0.0148 - output_seg_dice_coef: 0.1725 - output_seg_loss: 0.0494\n",
      "Epoch 9: val_output_seg_dice_coef did not improve from 0.14448\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: 0.0633 - output_dis_loss: 0.0147 - output_dis_mse_score: 0.0148 - output_seg_dice_coef: 0.1726 - output_seg_loss: 0.0492 - val_loss: 0.0316 - val_output_dis_loss: 0.0099 - val_output_dis_mse_score: 0.0099 - val_output_seg_dice_coef: 0.1163 - val_output_seg_loss: 0.0217 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: 0.0194 - output_dis_loss: 0.0143 - output_dis_mse_score: 0.0144 - output_seg_dice_coef: 0.2033 - output_seg_loss: 0.0067\n",
      "Epoch 10: val_output_seg_dice_coef improved from 0.14448 to 0.19123, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 430ms/step - loss: 0.0187 - output_dis_loss: 0.0143 - output_dis_mse_score: 0.0144 - output_seg_dice_coef: 0.2038 - output_seg_loss: 0.0059 - val_loss: 0.0321 - val_output_dis_loss: 0.0105 - val_output_dis_mse_score: 0.0105 - val_output_seg_dice_coef: 0.1912 - val_output_seg_loss: 0.0216 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 0.0541 - output_dis_loss: 0.0136 - output_dis_mse_score: 0.0137 - output_seg_dice_coef: 0.2080 - output_seg_loss: 0.0389\n",
      "Epoch 11: val_output_seg_dice_coef improved from 0.19123 to 0.26761, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 435ms/step - loss: 0.0529 - output_dis_loss: 0.0136 - output_dis_mse_score: 0.0137 - output_seg_dice_coef: 0.2085 - output_seg_loss: 0.0377 - val_loss: -0.1391 - val_output_dis_loss: 0.0097 - val_output_dis_mse_score: 0.0097 - val_output_seg_dice_coef: 0.2676 - val_output_seg_loss: -0.1488 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.0952 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0123 - output_seg_dice_coef: 0.2860 - output_seg_loss: -0.1070\n",
      "Epoch 12: val_output_seg_dice_coef improved from 0.26761 to 0.30361, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 422ms/step - loss: -0.0952 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0123 - output_seg_dice_coef: 0.2864 - output_seg_loss: -0.1070 - val_loss: -0.1931 - val_output_dis_loss: 0.0089 - val_output_dis_mse_score: 0.0089 - val_output_seg_dice_coef: 0.3036 - val_output_seg_loss: -0.2020 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.0262 - output_dis_loss: 0.0126 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.2471 - output_seg_loss: -0.0362\n",
      "Epoch 13: val_output_seg_dice_coef improved from 0.30361 to 0.34719, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.0269 - output_dis_loss: 0.0126 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.2478 - output_seg_loss: -0.0370 - val_loss: -0.2337 - val_output_dis_loss: 0.0089 - val_output_dis_mse_score: 0.0089 - val_output_seg_dice_coef: 0.3472 - val_output_seg_loss: -0.2426 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: -0.1251 - output_dis_loss: 0.0120 - output_dis_mse_score: 0.0121 - output_seg_dice_coef: 0.3366 - output_seg_loss: -0.1368\n",
      "Epoch 14: val_output_seg_dice_coef did not improve from 0.34719\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.1262 - output_dis_loss: 0.0120 - output_dis_mse_score: 0.0121 - output_seg_dice_coef: 0.3376 - output_seg_loss: -0.1379 - val_loss: -0.1030 - val_output_dis_loss: 0.0101 - val_output_dis_mse_score: 0.0101 - val_output_seg_dice_coef: 0.3239 - val_output_seg_loss: -0.1131 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: -0.1272 - output_dis_loss: 0.0117 - output_dis_mse_score: 0.0117 - output_seg_dice_coef: 0.3577 - output_seg_loss: -0.1387\n",
      "Epoch 15: val_output_seg_dice_coef improved from 0.34719 to 0.34882, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 429ms/step - loss: -0.1283 - output_dis_loss: 0.0117 - output_dis_mse_score: 0.0118 - output_seg_dice_coef: 0.3585 - output_seg_loss: -0.1398 - val_loss: -0.1911 - val_output_dis_loss: 0.0092 - val_output_dis_mse_score: 0.0092 - val_output_seg_dice_coef: 0.3488 - val_output_seg_loss: -0.2003 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.1742 - output_dis_loss: 0.0113 - output_dis_mse_score: 0.0114 - output_seg_dice_coef: 0.3717 - output_seg_loss: -0.1848\n",
      "Epoch 16: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.1742 - output_dis_loss: 0.0113 - output_dis_mse_score: 0.0114 - output_seg_dice_coef: 0.3721 - output_seg_loss: -0.1848 - val_loss: -0.1214 - val_output_dis_loss: 0.0101 - val_output_dis_mse_score: 0.0101 - val_output_seg_dice_coef: 0.2989 - val_output_seg_loss: -0.1315 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.1744 - output_dis_loss: 0.0119 - output_dis_mse_score: 0.0120 - output_seg_dice_coef: 0.3667 - output_seg_loss: -0.1858\n",
      "Epoch 17: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.1746 - output_dis_loss: 0.0119 - output_dis_mse_score: 0.0120 - output_seg_dice_coef: 0.3672 - output_seg_loss: -0.1859 - val_loss: -0.1363 - val_output_dis_loss: 0.0099 - val_output_dis_mse_score: 0.0099 - val_output_seg_dice_coef: 0.3232 - val_output_seg_loss: -0.1461 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: -0.1918 - output_dis_loss: 0.0123 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.3862 - output_seg_loss: -0.2035\n",
      "Epoch 18: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 427ms/step - loss: -0.1918 - output_dis_loss: 0.0123 - output_dis_mse_score: 0.0123 - output_seg_dice_coef: 0.3865 - output_seg_loss: -0.2035 - val_loss: -0.0034 - val_output_dis_loss: 0.0126 - val_output_dis_mse_score: 0.0126 - val_output_seg_dice_coef: 0.2770 - val_output_seg_loss: -0.0160 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.1740 - output_dis_loss: 0.0123 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.3736 - output_seg_loss: -0.1858\n",
      "Epoch 19: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.1743 - output_dis_loss: 0.0123 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.3741 - output_seg_loss: -0.1861 - val_loss: 0.0845 - val_output_dis_loss: 0.0130 - val_output_dis_mse_score: 0.0130 - val_output_seg_dice_coef: 0.2664 - val_output_seg_loss: 0.0714 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.1675 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.3749 - output_seg_loss: -0.1790\n",
      "Epoch 20: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.1679 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.3753 - output_seg_loss: -0.1794 - val_loss: 0.0407 - val_output_dis_loss: 0.0121 - val_output_dis_mse_score: 0.0121 - val_output_seg_dice_coef: 0.2728 - val_output_seg_loss: 0.0286 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.1934 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.4030 - output_seg_loss: -0.2049\n",
      "Epoch 21: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.1940 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.4033 - output_seg_loss: -0.2056 - val_loss: -0.0516 - val_output_dis_loss: 0.0111 - val_output_dis_mse_score: 0.0111 - val_output_seg_dice_coef: 0.3005 - val_output_seg_loss: -0.0627 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.2108 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0125 - output_seg_dice_coef: 0.4144 - output_seg_loss: -0.2226\n",
      "Epoch 22: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.2111 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0125 - output_seg_dice_coef: 0.4146 - output_seg_loss: -0.2229 - val_loss: -0.0639 - val_output_dis_loss: 0.0110 - val_output_dis_mse_score: 0.0110 - val_output_seg_dice_coef: 0.3072 - val_output_seg_loss: -0.0749 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.2203 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.4228 - output_seg_loss: -0.2321\n",
      "Epoch 23: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.2204 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.4228 - output_seg_loss: -0.2321 - val_loss: -0.0726 - val_output_dis_loss: 0.0108 - val_output_dis_mse_score: 0.0108 - val_output_seg_dice_coef: 0.3113 - val_output_seg_loss: -0.0835 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.2277 - output_dis_loss: 0.0128 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4318 - output_seg_loss: -0.2398\n",
      "Epoch 24: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 408ms/step - loss: -0.2277 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4317 - output_seg_loss: -0.2398 - val_loss: -0.0796 - val_output_dis_loss: 0.0107 - val_output_dis_mse_score: 0.0107 - val_output_seg_dice_coef: 0.3142 - val_output_seg_loss: -0.0904 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.2104 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4268 - output_seg_loss: -0.2225\n",
      "Epoch 25: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.2107 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4268 - output_seg_loss: -0.2228 - val_loss: -0.0899 - val_output_dis_loss: 0.0106 - val_output_dis_mse_score: 0.0106 - val_output_seg_dice_coef: 0.3179 - val_output_seg_loss: -0.1005 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.2178 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4289 - output_seg_loss: -0.2301\n",
      "Epoch 26: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.2180 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4288 - output_seg_loss: -0.2302 - val_loss: -0.0958 - val_output_dis_loss: 0.0105 - val_output_dis_mse_score: 0.0105 - val_output_seg_dice_coef: 0.3201 - val_output_seg_loss: -0.1063 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.2174 - output_dis_loss: 0.0128 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4297 - output_seg_loss: -0.2298\n",
      "Epoch 27: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.2177 - output_dis_loss: 0.0128 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4296 - output_seg_loss: -0.2300 - val_loss: -0.1003 - val_output_dis_loss: 0.0105 - val_output_dis_mse_score: 0.0105 - val_output_seg_dice_coef: 0.3219 - val_output_seg_loss: -0.1108 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.2147 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0128 - output_seg_dice_coef: 0.4274 - output_seg_loss: -0.2270\n",
      "Epoch 28: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.2151 - output_dis_loss: 0.0127 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4275 - output_seg_loss: -0.2274 - val_loss: -0.1047 - val_output_dis_loss: 0.0104 - val_output_dis_mse_score: 0.0104 - val_output_seg_dice_coef: 0.3237 - val_output_seg_loss: -0.1151 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.2052 - output_dis_loss: 0.0126 - output_dis_mse_score: 0.0127 - output_seg_dice_coef: 0.4160 - output_seg_loss: -0.2175\n",
      "Epoch 29: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.2060 - output_dis_loss: 0.0126 - output_dis_mse_score: 0.0126 - output_seg_dice_coef: 0.4164 - output_seg_loss: -0.2183 - val_loss: -0.1266 - val_output_dis_loss: 0.0110 - val_output_dis_mse_score: 0.0110 - val_output_seg_dice_coef: 0.3400 - val_output_seg_loss: -0.1376 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.2766 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.4598 - output_seg_loss: -0.2885\n",
      "Epoch 30: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.2765 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.4599 - output_seg_loss: -0.2884 - val_loss: -0.1106 - val_output_dis_loss: 0.0097 - val_output_dis_mse_score: 0.0097 - val_output_seg_dice_coef: 0.3383 - val_output_seg_loss: -0.1204 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 31/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.2336 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.4384 - output_seg_loss: -0.2457\n",
      "Epoch 31: val_output_seg_dice_coef did not improve from 0.34882\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.2344 - output_dis_loss: 0.0122 - output_dis_mse_score: 0.0122 - output_seg_dice_coef: 0.4388 - output_seg_loss: -0.2464 - val_loss: -0.0727 - val_output_dis_loss: 0.0112 - val_output_dis_mse_score: 0.0112 - val_output_seg_dice_coef: 0.3226 - val_output_seg_loss: -0.0839 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 32/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.3004 - output_dis_loss: 0.0120 - output_dis_mse_score: 0.0120 - output_seg_dice_coef: 0.4709 - output_seg_loss: -0.3120\n",
      "Epoch 32: val_output_seg_dice_coef improved from 0.34882 to 0.36327, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 425ms/step - loss: -0.3008 - output_dis_loss: 0.0120 - output_dis_mse_score: 0.0120 - output_seg_dice_coef: 0.4713 - output_seg_loss: -0.3123 - val_loss: -0.1406 - val_output_dis_loss: 0.0096 - val_output_dis_mse_score: 0.0096 - val_output_seg_dice_coef: 0.3633 - val_output_seg_loss: -0.1502 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 33/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.3011 - output_dis_loss: 0.0119 - output_dis_mse_score: 0.0119 - output_seg_dice_coef: 0.4862 - output_seg_loss: -0.3129\n",
      "Epoch 33: val_output_seg_dice_coef improved from 0.36327 to 0.39349, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.3016 - output_dis_loss: 0.0119 - output_dis_mse_score: 0.0119 - output_seg_dice_coef: 0.4865 - output_seg_loss: -0.3134 - val_loss: -0.2073 - val_output_dis_loss: 0.0113 - val_output_dis_mse_score: 0.0113 - val_output_seg_dice_coef: 0.3935 - val_output_seg_loss: -0.2186 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 34/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.3638 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.5339 - output_seg_loss: -0.3759\n",
      "Epoch 34: val_output_seg_dice_coef improved from 0.39349 to 0.39908, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.3640 - output_dis_loss: 0.0124 - output_dis_mse_score: 0.0124 - output_seg_dice_coef: 0.5340 - output_seg_loss: -0.3761 - val_loss: -0.1899 - val_output_dis_loss: 0.0110 - val_output_dis_mse_score: 0.0110 - val_output_seg_dice_coef: 0.3991 - val_output_seg_loss: -0.2009 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 35/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.3887 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0121 - output_seg_dice_coef: 0.5550 - output_seg_loss: -0.4006\n",
      "Epoch 35: val_output_seg_dice_coef did not improve from 0.39908\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.3883 - output_dis_loss: 0.0121 - output_dis_mse_score: 0.0121 - output_seg_dice_coef: 0.5547 - output_seg_loss: -0.4001 - val_loss: -0.1350 - val_output_dis_loss: 0.0109 - val_output_dis_mse_score: 0.0109 - val_output_seg_dice_coef: 0.3816 - val_output_seg_loss: -0.1459 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 36/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4064 - output_dis_loss: 0.0109 - output_dis_mse_score: 0.0109 - output_seg_dice_coef: 0.5695 - output_seg_loss: -0.4171\n",
      "Epoch 36: val_output_seg_dice_coef did not improve from 0.39908\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.4062 - output_dis_loss: 0.0109 - output_dis_mse_score: 0.0109 - output_seg_dice_coef: 0.5692 - output_seg_loss: -0.4169 - val_loss: -0.1464 - val_output_dis_loss: 0.0113 - val_output_dis_mse_score: 0.0113 - val_output_seg_dice_coef: 0.3882 - val_output_seg_loss: -0.1577 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 37/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: -0.4071 - output_dis_loss: 0.0105 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.5751 - output_seg_loss: -0.4174\n",
      "Epoch 37: val_output_seg_dice_coef did not improve from 0.39908\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4068 - output_dis_loss: 0.0105 - output_dis_mse_score: 0.0105 - output_seg_dice_coef: 0.5747 - output_seg_loss: -0.4171 - val_loss: -0.1074 - val_output_dis_loss: 0.0116 - val_output_dis_mse_score: 0.0116 - val_output_seg_dice_coef: 0.3778 - val_output_seg_loss: -0.1189 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 38/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: -0.4144 - output_dis_loss: 0.0102 - output_dis_mse_score: 0.0102 - output_seg_dice_coef: 0.5854 - output_seg_loss: -0.4245\n",
      "Epoch 38: val_output_seg_dice_coef did not improve from 0.39908\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.4141 - output_dis_loss: 0.0102 - output_dis_mse_score: 0.0102 - output_seg_dice_coef: 0.5849 - output_seg_loss: -0.4242 - val_loss: -0.1394 - val_output_dis_loss: 0.0115 - val_output_dis_mse_score: 0.0115 - val_output_seg_dice_coef: 0.3898 - val_output_seg_loss: -0.1509 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 39/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: -0.4190 - output_dis_loss: 0.0099 - output_dis_mse_score: 0.0099 - output_seg_dice_coef: 0.5882 - output_seg_loss: -0.4289\n",
      "Epoch 39: val_output_seg_dice_coef improved from 0.39908 to 0.40589, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 430ms/step - loss: -0.4187 - output_dis_loss: 0.0099 - output_dis_mse_score: 0.0099 - output_seg_dice_coef: 0.5878 - output_seg_loss: -0.4286 - val_loss: -0.1746 - val_output_dis_loss: 0.0106 - val_output_dis_mse_score: 0.0106 - val_output_seg_dice_coef: 0.4059 - val_output_seg_loss: -0.1852 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 40/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4303 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5975 - output_seg_loss: -0.4399\n",
      "Epoch 40: val_output_seg_dice_coef improved from 0.40589 to 0.42846, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.4298 - output_dis_loss: 0.0097 - output_dis_mse_score: 0.0097 - output_seg_dice_coef: 0.5970 - output_seg_loss: -0.4395 - val_loss: -0.2252 - val_output_dis_loss: 0.0092 - val_output_dis_mse_score: 0.0092 - val_output_seg_dice_coef: 0.4285 - val_output_seg_loss: -0.2344 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 41/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4481 - output_dis_loss: 0.0094 - output_dis_mse_score: 0.0094 - output_seg_dice_coef: 0.6111 - output_seg_loss: -0.4575\n",
      "Epoch 41: val_output_seg_dice_coef improved from 0.42846 to 0.48159, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4476 - output_dis_loss: 0.0094 - output_dis_mse_score: 0.0094 - output_seg_dice_coef: 0.6106 - output_seg_loss: -0.4570 - val_loss: -0.3380 - val_output_dis_loss: 0.0082 - val_output_dis_mse_score: 0.0082 - val_output_seg_dice_coef: 0.4816 - val_output_seg_loss: -0.3462 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 42/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: -0.4522 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6030 - output_seg_loss: -0.4612\n",
      "Epoch 42: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.4517 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6026 - output_seg_loss: -0.4607 - val_loss: -0.3186 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4724 - val_output_seg_loss: -0.3271 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 43/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: -0.4541 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6039 - output_seg_loss: -0.4630\n",
      "Epoch 43: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 427ms/step - loss: -0.4537 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6036 - output_seg_loss: -0.4626 - val_loss: -0.3168 - val_output_dis_loss: 0.0085 - val_output_dis_mse_score: 0.0085 - val_output_seg_dice_coef: 0.4722 - val_output_seg_loss: -0.3253 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 44/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: -0.4541 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.5955 - output_seg_loss: -0.4619\n",
      "Epoch 44: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.4537 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5954 - output_seg_loss: -0.4615 - val_loss: -0.3162 - val_output_dis_loss: 0.0085 - val_output_dis_mse_score: 0.0085 - val_output_seg_dice_coef: 0.4725 - val_output_seg_loss: -0.3247 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 45/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4466 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.5987 - output_seg_loss: -0.4548\n",
      "Epoch 45: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4464 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.5985 - output_seg_loss: -0.4546 - val_loss: -0.3146 - val_output_dis_loss: 0.0085 - val_output_dis_mse_score: 0.0085 - val_output_seg_dice_coef: 0.4723 - val_output_seg_loss: -0.3231 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 46/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4511 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6032 - output_seg_loss: -0.4596\n",
      "Epoch 46: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.4509 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6030 - output_seg_loss: -0.4594 - val_loss: -0.3121 - val_output_dis_loss: 0.0085 - val_output_dis_mse_score: 0.0085 - val_output_seg_dice_coef: 0.4716 - val_output_seg_loss: -0.3207 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 47/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.4443 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.5989 - output_seg_loss: -0.4533\n",
      "Epoch 47: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.4442 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.5988 - output_seg_loss: -0.4532 - val_loss: -0.3102 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4712 - val_output_seg_loss: -0.3188 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 48/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: -0.4503 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6041 - output_seg_loss: -0.4590\n",
      "Epoch 48: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - loss: -0.4500 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6039 - output_seg_loss: -0.4588 - val_loss: -0.3105 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4717 - val_output_seg_loss: -0.3190 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 49/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: -0.4541 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6073 - output_seg_loss: -0.4626\n",
      "Epoch 49: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - loss: -0.4538 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6070 - output_seg_loss: -0.4623 - val_loss: -0.3057 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4698 - val_output_seg_loss: -0.3143 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 50/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: -0.4570 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6060 - output_seg_loss: -0.4654\n",
      "Epoch 50: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4567 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6057 - output_seg_loss: -0.4651 - val_loss: -0.3057 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4701 - val_output_seg_loss: -0.3143 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 51/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4551 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6100 - output_seg_loss: -0.4640\n",
      "Epoch 51: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4548 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6098 - output_seg_loss: -0.4637 - val_loss: -0.3031 - val_output_dis_loss: 0.0087 - val_output_dis_mse_score: 0.0087 - val_output_seg_dice_coef: 0.4692 - val_output_seg_loss: -0.3118 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 52/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.4512 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6052 - output_seg_loss: -0.4601\n",
      "Epoch 52: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4511 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6051 - output_seg_loss: -0.4600 - val_loss: -0.2991 - val_output_dis_loss: 0.0087 - val_output_dis_mse_score: 0.0087 - val_output_seg_dice_coef: 0.4676 - val_output_seg_loss: -0.3078 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 53/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.4402 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5916 - output_seg_loss: -0.4491\n",
      "Epoch 53: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.4404 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5919 - output_seg_loss: -0.4492 - val_loss: -0.2977 - val_output_dis_loss: 0.0087 - val_output_dis_mse_score: 0.0087 - val_output_seg_dice_coef: 0.4672 - val_output_seg_loss: -0.3065 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 54/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4321 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.5819 - output_seg_loss: -0.4406\n",
      "Epoch 54: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4325 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.5824 - output_seg_loss: -0.4410 - val_loss: -0.2960 - val_output_dis_loss: 0.0088 - val_output_dis_mse_score: 0.0088 - val_output_seg_dice_coef: 0.4667 - val_output_seg_loss: -0.3048 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 55/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.4337 - output_dis_loss: 0.0085 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.5855 - output_seg_loss: -0.4424\n",
      "Epoch 55: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.4341 - output_dis_loss: 0.0085 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5859 - output_seg_loss: -0.4427 - val_loss: -0.2980 - val_output_dis_loss: 0.0087 - val_output_dis_mse_score: 0.0087 - val_output_seg_dice_coef: 0.4680 - val_output_seg_loss: -0.3068 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 56/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4306 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5851 - output_seg_loss: -0.4393\n",
      "Epoch 56: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4309 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.5855 - output_seg_loss: -0.4397 - val_loss: -0.3017 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4701 - val_output_seg_loss: -0.3104 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 57/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.4364 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0084 - output_seg_dice_coef: 0.5849 - output_seg_loss: -0.4448\n",
      "Epoch 57: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.4367 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0084 - output_seg_dice_coef: 0.5853 - output_seg_loss: -0.4451 - val_loss: -0.3040 - val_output_dis_loss: 0.0086 - val_output_dis_mse_score: 0.0086 - val_output_seg_dice_coef: 0.4715 - val_output_seg_loss: -0.3126 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 58/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.4340 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.5820 - output_seg_loss: -0.4422\n",
      "Epoch 58: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.4343 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.5825 - output_seg_loss: -0.4425 - val_loss: -0.3119 - val_output_dis_loss: 0.0085 - val_output_dis_mse_score: 0.0085 - val_output_seg_dice_coef: 0.4758 - val_output_seg_loss: -0.3204 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 59/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.4369 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5913 - output_seg_loss: -0.4457\n",
      "Epoch 59: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.4371 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5915 - output_seg_loss: -0.4459 - val_loss: -0.3151 - val_output_dis_loss: 0.0085 - val_output_dis_mse_score: 0.0085 - val_output_seg_dice_coef: 0.4777 - val_output_seg_loss: -0.3236 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.0000000000000003e-05.\n",
      "Epoch 60/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4475 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6003 - output_seg_loss: -0.4566\n",
      "Epoch 60: val_output_seg_dice_coef did not improve from 0.48159\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.4475 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6004 - output_seg_loss: -0.4566 - val_loss: -0.3193 - val_output_dis_loss: 0.0084 - val_output_dis_mse_score: 0.0084 - val_output_seg_dice_coef: 0.4801 - val_output_seg_loss: -0.3277 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 61/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.4420 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.5978 - output_seg_loss: -0.4511\n",
      "Epoch 61: val_output_seg_dice_coef improved from 0.48159 to 0.48383, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.4422 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.5979 - output_seg_loss: -0.4513 - val_loss: -0.3265 - val_output_dis_loss: 0.0083 - val_output_dis_mse_score: 0.0083 - val_output_seg_dice_coef: 0.4838 - val_output_seg_loss: -0.3348 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 62/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4485 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6012 - output_seg_loss: -0.4574\n",
      "Epoch 62: val_output_seg_dice_coef improved from 0.48383 to 0.48687, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.4486 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6014 - output_seg_loss: -0.4575 - val_loss: -0.3323 - val_output_dis_loss: 0.0082 - val_output_dis_mse_score: 0.0082 - val_output_seg_dice_coef: 0.4869 - val_output_seg_loss: -0.3405 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 63/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.4408 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.5951 - output_seg_loss: -0.4498\n",
      "Epoch 63: val_output_seg_dice_coef improved from 0.48687 to 0.48872, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4410 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.5953 - output_seg_loss: -0.4500 - val_loss: -0.3358 - val_output_dis_loss: 0.0082 - val_output_dis_mse_score: 0.0082 - val_output_seg_dice_coef: 0.4887 - val_output_seg_loss: -0.3440 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 64/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4416 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.5993 - output_seg_loss: -0.4507\n",
      "Epoch 64: val_output_seg_dice_coef improved from 0.48872 to 0.48992, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.4418 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.5995 - output_seg_loss: -0.4510 - val_loss: -0.3380 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4899 - val_output_seg_loss: -0.3462 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 65/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4445 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6013 - output_seg_loss: -0.4538\n",
      "Epoch 65: val_output_seg_dice_coef improved from 0.48992 to 0.49092, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4446 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6014 - output_seg_loss: -0.4539 - val_loss: -0.3398 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4909 - val_output_seg_loss: -0.3480 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 66/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4469 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6060 - output_seg_loss: -0.4564\n",
      "Epoch 66: val_output_seg_dice_coef improved from 0.49092 to 0.49160, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4470 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6060 - output_seg_loss: -0.4565 - val_loss: -0.3411 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4916 - val_output_seg_loss: -0.3492 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 67/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.4488 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6052 - output_seg_loss: -0.4581\n",
      "Epoch 67: val_output_seg_dice_coef improved from 0.49160 to 0.49224, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 422ms/step - loss: -0.4488 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6052 - output_seg_loss: -0.4581 - val_loss: -0.3422 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4922 - val_output_seg_loss: -0.3503 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 68/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4537 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0094 - output_seg_dice_coef: 0.6086 - output_seg_loss: -0.4631\n",
      "Epoch 68: val_output_seg_dice_coef improved from 0.49224 to 0.49269, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4537 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6086 - output_seg_loss: -0.4631 - val_loss: -0.3430 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4927 - val_output_seg_loss: -0.3510 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 69/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: -0.4464 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6062 - output_seg_loss: -0.4559\n",
      "Epoch 69: val_output_seg_dice_coef improved from 0.49269 to 0.49331, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 427ms/step - loss: -0.4465 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6062 - output_seg_loss: -0.4560 - val_loss: -0.3441 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4933 - val_output_seg_loss: -0.3521 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 70/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4521 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6095 - output_seg_loss: -0.4614\n",
      "Epoch 70: val_output_seg_dice_coef improved from 0.49331 to 0.49363, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 425ms/step - loss: -0.4521 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6095 - output_seg_loss: -0.4614 - val_loss: -0.3446 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4936 - val_output_seg_loss: -0.3527 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 71/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.4461 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6050 - output_seg_loss: -0.4554\n",
      "Epoch 71: val_output_seg_dice_coef improved from 0.49363 to 0.49367, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.4462 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6050 - output_seg_loss: -0.4555 - val_loss: -0.3446 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4937 - val_output_seg_loss: -0.3527 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 72/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4546 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6085 - output_seg_loss: -0.4636\n",
      "Epoch 72: val_output_seg_dice_coef improved from 0.49367 to 0.49394, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 425ms/step - loss: -0.4546 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6085 - output_seg_loss: -0.4637 - val_loss: -0.3451 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4939 - val_output_seg_loss: -0.3531 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 73/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4364 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.5948 - output_seg_loss: -0.4455\n",
      "Epoch 73: val_output_seg_dice_coef improved from 0.49394 to 0.49435, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4367 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.5951 - output_seg_loss: -0.4458 - val_loss: -0.3458 - val_output_dis_loss: 0.0081 - val_output_dis_mse_score: 0.0081 - val_output_seg_dice_coef: 0.4944 - val_output_seg_loss: -0.3538 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 74/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4460 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5972 - output_seg_loss: -0.4549\n",
      "Epoch 74: val_output_seg_dice_coef improved from 0.49435 to 0.49494, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4462 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5975 - output_seg_loss: -0.4551 - val_loss: -0.3468 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4949 - val_output_seg_loss: -0.3549 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 75/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4338 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5904 - output_seg_loss: -0.4427\n",
      "Epoch 75: val_output_seg_dice_coef improved from 0.49494 to 0.49534, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4342 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5907 - output_seg_loss: -0.4431 - val_loss: -0.3475 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4953 - val_output_seg_loss: -0.3555 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 76/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4408 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6014 - output_seg_loss: -0.4500\n",
      "Epoch 76: val_output_seg_dice_coef improved from 0.49534 to 0.49570, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4410 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6015 - output_seg_loss: -0.4502 - val_loss: -0.3481 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4957 - val_output_seg_loss: -0.3562 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 77/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.4496 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6072 - output_seg_loss: -0.4588\n",
      "Epoch 77: val_output_seg_dice_coef improved from 0.49570 to 0.49611, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4496 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6071 - output_seg_loss: -0.4588 - val_loss: -0.3488 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4961 - val_output_seg_loss: -0.3569 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 78/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.4563 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6122 - output_seg_loss: -0.4654\n",
      "Epoch 78: val_output_seg_dice_coef improved from 0.49611 to 0.49612, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.4562 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6121 - output_seg_loss: -0.4653 - val_loss: -0.3488 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4961 - val_output_seg_loss: -0.3568 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 79/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4581 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6146 - output_seg_loss: -0.4673\n",
      "Epoch 79: val_output_seg_dice_coef improved from 0.49612 to 0.49632, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4580 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6144 - output_seg_loss: -0.4671 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4963 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 80/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.4561 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6166 - output_seg_loss: -0.4653\n",
      "Epoch 80: val_output_seg_dice_coef improved from 0.49632 to 0.49659, saving model to /kaggle/working/output_model/unet_2.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.4560 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6164 - output_seg_loss: -0.4652 - val_loss: -0.3495 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4966 - val_output_seg_loss: -0.3576 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 81/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.4566 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6158 - output_seg_loss: -0.4657\n",
      "Epoch 81: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - loss: -0.4564 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6156 - output_seg_loss: -0.4656 - val_loss: -0.3495 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4966 - val_output_seg_loss: -0.3576 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 82/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.4608 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6197 - output_seg_loss: -0.4700\n",
      "Epoch 82: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.4606 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6193 - output_seg_loss: -0.4697 - val_loss: -0.3495 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4966 - val_output_seg_loss: -0.3576 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 83/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: -0.4667 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6237 - output_seg_loss: -0.4757\n",
      "Epoch 83: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.4663 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6233 - output_seg_loss: -0.4753 - val_loss: -0.3495 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4966 - val_output_seg_loss: -0.3575 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 84/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - loss: -0.4742 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6240 - output_seg_loss: -0.4829\n",
      "Epoch 84: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4737 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6236 - output_seg_loss: -0.4824 - val_loss: -0.3495 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4966 - val_output_seg_loss: -0.3575 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 85/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.4708 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6203 - output_seg_loss: -0.4794\n",
      "Epoch 85: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.4703 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6200 - output_seg_loss: -0.4790 - val_loss: -0.3494 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3574 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 86/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4699 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.6111 - output_seg_loss: -0.4778\n",
      "Epoch 86: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.4695 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.6110 - output_seg_loss: -0.4774 - val_loss: -0.3494 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3574 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 87/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.4599 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6132 - output_seg_loss: -0.4686\n",
      "Epoch 87: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.4597 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.6130 - output_seg_loss: -0.4684 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 88/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4611 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6144 - output_seg_loss: -0.4696\n",
      "Epoch 88: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4609 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6142 - output_seg_loss: -0.4694 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 89/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4548 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6100 - output_seg_loss: -0.4636\n",
      "Epoch 89: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.4547 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6099 - output_seg_loss: -0.4635 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 90/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: -0.4605 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6150 - output_seg_loss: -0.4694\n",
      "Epoch 90: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 405ms/step - loss: -0.4603 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6148 - output_seg_loss: -0.4692 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 91/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4633 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6170 - output_seg_loss: -0.4721\n",
      "Epoch 91: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.4630 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6168 - output_seg_loss: -0.4718 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 92/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: -0.4673 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0086 - output_seg_dice_coef: 0.6159 - output_seg_loss: -0.4757\n",
      "Epoch 92: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - loss: -0.4670 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6157 - output_seg_loss: -0.4754 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 93/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.4629 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6181 - output_seg_loss: -0.4717\n",
      "Epoch 93: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.4627 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6178 - output_seg_loss: -0.4715 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 94/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: -0.4581 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6124 - output_seg_loss: -0.4670\n",
      "Epoch 94: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 422ms/step - loss: -0.4580 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6123 - output_seg_loss: -0.4669 - val_loss: -0.3490 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3570 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 95/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: -0.4507 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6006 - output_seg_loss: -0.4594\n",
      "Epoch 95: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - loss: -0.4508 - output_dis_loss: 0.0086 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.6008 - output_seg_loss: -0.4595 - val_loss: -0.3490 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3570 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 96/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.4409 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.5894 - output_seg_loss: -0.4493\n",
      "Epoch 96: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.4412 - output_dis_loss: 0.0083 - output_dis_mse_score: 0.0084 - output_seg_dice_coef: 0.5899 - output_seg_loss: -0.4496 - val_loss: -0.3490 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 97/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4415 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0084 - output_seg_dice_coef: 0.5920 - output_seg_loss: -0.4499\n",
      "Epoch 97: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.4418 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0084 - output_seg_dice_coef: 0.5924 - output_seg_loss: -0.4502 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 98/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4404 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.5923 - output_seg_loss: -0.4489\n",
      "Epoch 98: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 411ms/step - loss: -0.4407 - output_dis_loss: 0.0084 - output_dis_mse_score: 0.0085 - output_seg_dice_coef: 0.5926 - output_seg_loss: -0.4492 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3571 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 99/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4471 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0082 - output_seg_dice_coef: 0.5929 - output_seg_loss: -0.4554\n",
      "Epoch 99: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4473 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0083 - output_seg_dice_coef: 0.5932 - output_seg_loss: -0.4556 - val_loss: -0.3491 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4964 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.0000000000000002e-07.\n",
      "Epoch 100/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.4436 - output_dis_loss: 0.0081 - output_dis_mse_score: 0.0082 - output_seg_dice_coef: 0.5890 - output_seg_loss: -0.4517\n",
      "Epoch 100: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 406ms/step - loss: -0.4438 - output_dis_loss: 0.0082 - output_dis_mse_score: 0.0082 - output_seg_dice_coef: 0.5894 - output_seg_loss: -0.4520 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 101/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: -0.4446 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.5970 - output_seg_loss: -0.4534\n",
      "Epoch 101: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.4448 - output_dis_loss: 0.0087 - output_dis_mse_score: 0.0087 - output_seg_dice_coef: 0.5972 - output_seg_loss: -0.4536 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 102/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: -0.4519 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6033 - output_seg_loss: -0.4608\n",
      "Epoch 102: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - loss: -0.4519 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6034 - output_seg_loss: -0.4609 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 103/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - loss: -0.4462 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6000 - output_seg_loss: -0.4552\n",
      "Epoch 103: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 410ms/step - loss: -0.4463 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6001 - output_seg_loss: -0.4553 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 104/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.4498 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6018 - output_seg_loss: -0.4587\n",
      "Epoch 104: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.4499 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.6020 - output_seg_loss: -0.4589 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 105/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.4428 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5964 - output_seg_loss: -0.4517\n",
      "Epoch 105: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 407ms/step - loss: -0.4430 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5966 - output_seg_loss: -0.4519 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3572 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 106/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.4437 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6009 - output_seg_loss: -0.4529\n",
      "Epoch 106: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.4439 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6010 - output_seg_loss: -0.4531 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 107/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: -0.4456 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6021 - output_seg_loss: -0.4549\n",
      "Epoch 107: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 405ms/step - loss: -0.4458 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6022 - output_seg_loss: -0.4550 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 108/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: -0.4472 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6064 - output_seg_loss: -0.4567\n",
      "Epoch 108: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - loss: -0.4473 - output_dis_loss: 0.0094 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6064 - output_seg_loss: -0.4568 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 109/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: -0.4486 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6053 - output_seg_loss: -0.4579\n",
      "Epoch 109: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 407ms/step - loss: -0.4486 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6053 - output_seg_loss: -0.4580 - val_loss: -0.3492 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 110/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - loss: -0.4540 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6091 - output_seg_loss: -0.4633\n",
      "Epoch 110: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - loss: -0.4540 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6091 - output_seg_loss: -0.4633 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 111/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: -0.4466 - output_dis_loss: 0.0095 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6067 - output_seg_loss: -0.4561\n",
      "Epoch 111: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 422ms/step - loss: -0.4467 - output_dis_loss: 0.0094 - output_dis_mse_score: 0.0095 - output_seg_dice_coef: 0.6067 - output_seg_loss: -0.4562 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 112/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - loss: -0.4535 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6105 - output_seg_loss: -0.4628\n",
      "Epoch 112: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4535 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6104 - output_seg_loss: -0.4628 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 113/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: -0.4470 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6056 - output_seg_loss: -0.4563\n",
      "Epoch 113: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 417ms/step - loss: -0.4471 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6057 - output_seg_loss: -0.4564 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 114/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - loss: -0.4554 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6091 - output_seg_loss: -0.4644\n",
      "Epoch 114: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - loss: -0.4554 - output_dis_loss: 0.0090 - output_dis_mse_score: 0.0090 - output_seg_dice_coef: 0.6091 - output_seg_loss: -0.4644 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 115/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: -0.4373 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.5956 - output_seg_loss: -0.4465\n",
      "Epoch 115: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - loss: -0.4376 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.5958 - output_seg_loss: -0.4468 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 116/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4462 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5973 - output_seg_loss: -0.4550\n",
      "Epoch 116: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 415ms/step - loss: -0.4464 - output_dis_loss: 0.0088 - output_dis_mse_score: 0.0088 - output_seg_dice_coef: 0.5976 - output_seg_loss: -0.4552 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 117/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.4348 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5914 - output_seg_loss: -0.4437\n",
      "Epoch 117: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.4352 - output_dis_loss: 0.0089 - output_dis_mse_score: 0.0089 - output_seg_dice_coef: 0.5918 - output_seg_loss: -0.4441 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 118/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: -0.4417 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6023 - output_seg_loss: -0.4510\n",
      "Epoch 118: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - loss: -0.4419 - output_dis_loss: 0.0093 - output_dis_mse_score: 0.0093 - output_seg_dice_coef: 0.6023 - output_seg_loss: -0.4512 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 119/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: -0.4487 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6066 - output_seg_loss: -0.4579\n",
      "Epoch 119: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 409ms/step - loss: -0.4487 - output_dis_loss: 0.0092 - output_dis_mse_score: 0.0092 - output_seg_dice_coef: 0.6066 - output_seg_loss: -0.4580 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.0000000000000004e-08.\n",
      "Epoch 120/120\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: -0.4552 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6114 - output_seg_loss: -0.4643\n",
      "Epoch 120: val_output_seg_dice_coef did not improve from 0.49659\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - loss: -0.4551 - output_dis_loss: 0.0091 - output_dis_mse_score: 0.0091 - output_seg_dice_coef: 0.6113 - output_seg_loss: -0.4642 - val_loss: -0.3493 - val_output_dis_loss: 0.0080 - val_output_dis_mse_score: 0.0080 - val_output_seg_dice_coef: 0.4965 - val_output_seg_loss: -0.3573 - learning_rate: 1.0000e-08\n",
      "\u001b[1m332/332\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 332/332 [01:44<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "average dice pure Unet for fold2: 54.40\n",
      "average AJI pure Unet for fold2: 23.46\n",
      "average PQ pure Unet for fold2: 18.09\n",
      "==========\n",
      "==========\n",
      "average Dice Unet watershed for fold2: 50.00\n",
      "average AJI Unet watershed for fold2: 22.77\n",
      "average PQ Unet watershed for fold2: 16.06\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "current_fold = 1\n",
    "\n",
    "import time\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "import skimage.morphology\n",
    "from skimage.io import imsave\n",
    "from skimage.morphology import remove_small_objects\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "start_time = time.time()\n",
    "for index,[train_index,  test_index] in enumerate(kf.split(img_path)):\n",
    "    \n",
    "    shuffle(train_index)\n",
    "    shuffle(test_index)\n",
    "    \n",
    "    train_img   = [img_path[name] for name in train_index]\n",
    "    train_mask  = [binary_mask_path[name] for name in train_index]\n",
    "    train_DIS   = [distance_mask_path[name] for name in train_index]\n",
    "    train_label = [label_mask_path[name] for name in train_index]\n",
    "\n",
    "    test_img   = [img_path[name] for name in test_index]\n",
    "    test_mask  = [binary_mask_path[name] for name in test_index]\n",
    "    test_DIS   = [distance_mask_path[name] for name in test_index]\n",
    "    test_label = [label_mask_path[name] for name in test_index]\n",
    "\n",
    "    ## creating validation set ##\n",
    "    \n",
    "    validation_set_img = []\n",
    "    validation_set_label = []\n",
    "    validation_DIS = []\n",
    "    # validation_set_vague = []\n",
    "    # test_masks = []\n",
    "    \n",
    "    for counter in range(len(test_img)):\n",
    "        val_img = cv2.imread(test_img[counter])\n",
    "        val_img = cv2.cvtColor(val_img, cv2.COLOR_BGR2RGB)\n",
    "        val_img = val_img.astype(np.float32) / 255.0 \n",
    "        validation_set_img.append(val_img)\n",
    "\n",
    "        \n",
    "        val_label = cv2.imread(test_label[counter], -1) # cv2.IMREAD_UNCHANGED: \n",
    "        #It specifies to load an image as such including alpha channel. \n",
    "        #Alternatively, we can pass integer value -1 for this flag.\n",
    "        # val_vague = cv2.imread(test_vague[counter], -1)\n",
    "        \n",
    "        \n",
    "        validation_set_label.append(val_label)\n",
    "        # validation_set_vague.append(val_vague)\n",
    "        \n",
    "        # val_mask = cv2.imread(test_mask[counter],-1)\n",
    "        # val_mask = val_mask.astype(np.float32) / 255.0         \n",
    "        # test_masks.append(val_mask)\n",
    "        \n",
    "        # val_DIS = cv2.imread(test_DIS[counter], -1) \n",
    "        # val_DIS = val_DIS.astype(np.float32) / 255.0\n",
    "        # validation_DIS.append(val_DIS)\n",
    "        \n",
    "    validation_set_img = np.array(validation_set_img)\n",
    "    # validation_DIS = np.array(validation_DIS)\n",
    "\n",
    "    # test_img = validation_set_img\n",
    "    # test_mask = np.array(test_masks)\n",
    "    # test_mask = np.expand_dims(test_mask, axis=-1)\n",
    "    # test_DIS = np.expand_dims(validation_DIS, axis=-1)\n",
    "    validation_set_label = np.array(validation_set_label)\n",
    "    # validation_set_vague = np.array(validation_set_vague)\n",
    "\n",
    "    \n",
    "\n",
    "    model_path = opts['model_save_path'] + 'unet_{}.weights.h5'.format(current_fold)\n",
    "    logger = CSVLogger(opts['model_save_path']+ 'unet_{}.log'.format(current_fold))\n",
    "    LR_drop = step_decay_schedule()\n",
    "    model = dual_decoder_unet_binary(opts['number_of_channel'], opts['init_LR'])\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_output_seg_dice_coef', verbose=1,\n",
    "                         save_best_only=True, mode='max', save_weights_only = True)\n",
    "    # history = model.fit(x=train_img,y={\n",
    "    #                         'output_dis': train_DIS,  # Targets for the Distance Map head\n",
    "    #                         'output_seg': train_mask    # Targets for the Segmentation Mask head\n",
    "    #                     },\n",
    "    #                     validation_data=(test_img,{\n",
    "    #                         'output_dis': test_DIS,  # Targets for the Distance Map head\n",
    "    #                         'output_seg': test_mask    # Targets for the Segmentation Mask head\n",
    "    #                     }),  \n",
    "    #                   #validation_steps=1,\n",
    "    #                   epochs=opts['epoch_num'], verbose=1,\n",
    "    #                   callbacks=[checkpoint, logger, LR_drop],\n",
    "    #                   steps_per_epoch=(len(train_img) // opts['batch_size']) // opts['quick_run'])\n",
    "\n",
    "    history = model.fit(data_gen(train_img,train_label,train_DIS,\n",
    "                                                 opts['batch_size'],\n",
    "                                                 1,\n",
    "                                                 opts['crop_size'], opts['crop_size']),\n",
    "                        validation_data=data_gen(test_img,test_label,test_DIS,\n",
    "                                                 opts['batch_size'],\n",
    "                                                 1,\n",
    "                                                 opts['crop_size'], opts['crop_size']),  \n",
    "                      validation_steps=1,\n",
    "                      epochs=opts['epoch_num'], verbose=1,\n",
    "                      callbacks=[checkpoint, logger, LR_drop],\n",
    "                      steps_per_epoch=(len(train_img) // opts['batch_size']) // opts['quick_run'])\n",
    "    \n",
    "    model.load_weights(opts['model_save_path'] + 'unet_{}.weights.h5'.format(current_fold))\n",
    "\n",
    "    ## FOLD RESULTS ##\n",
    "\n",
    "    pred_val = model.predict(validation_set_img, verbose=1, batch_size=1)\n",
    "\n",
    "    pred_dis = pred_val[0]\n",
    "    pred_seg = pred_val[1]\n",
    "\n",
    "    pred_val_t = (pred_seg > opts['treshold']).astype(np.uint8) # Add this later\n",
    "    pred_seg = pred_val_t\n",
    "\n",
    "    for val_len in tqdm.tqdm(range(len(pred_dis))):\n",
    "        avg_nuclei = calculate_average_nucleus_diameter(pred_seg[val_len])\n",
    "        pred_dis[val_len] = apply_gaussian_smoothing(pred_dis[val_len],avg_nuclei)\n",
    "\n",
    "        footprint_size = max(3, int(avg_nuclei * 0.8) // 2 * 2 + 1)\n",
    "        \n",
    "        peak_coords = peak_local_max(np.squeeze(pred_dis[val_len]), \n",
    "                              # indices=False,\n",
    "                            exclude_border=False, footprint=np.ones((footprint_size, footprint_size)))\n",
    "        image_shape = np.squeeze(pred_dis[val_len]).shape\n",
    "        local_maxi = np.zeros(image_shape, dtype=bool)\n",
    "        if peak_coords.size > 0:\n",
    "    # Set the pixels at the peak coordinates to True\n",
    "            local_maxi[peak_coords[:, 0], peak_coords[:, 1]] = True\n",
    "\n",
    "        \n",
    "        marker = ndi.label(local_maxi)[0]\n",
    "        output_watershed = watershed(-np.squeeze(pred_dis[val_len]), marker,mask = np.squeeze(pred_val_t[[val_len]]))\n",
    "        output_watershed[np.squeeze(pred_seg[[val_len]])==0] = 0\n",
    "        output_watershed = remove_small_objects(output_watershed, min_size=50, connectivity=2)#remove small objects\n",
    "\n",
    "        # output_raw_0 = np.squeeze(pred_seg[val_len])\n",
    "        output_raw_binarized = (np.squeeze(pred_seg[val_len]) > opts['treshold']).astype(np.uint8)\n",
    "\n",
    "        # 2. Apply labeling to the binary mask\n",
    "        output_raw = skimage.morphology.label(output_raw_binarized) \n",
    "        # output_raw = skimage.morphology.label(output_raw_0)\n",
    "        output_raw = remove_small_objects(output_raw, min_size=50, connectivity=2) #remove small objects\n",
    "\n",
    "        output_watershed = remap_label(output_watershed)\n",
    "        validation_set_label[val_len] = remap_label(validation_set_label[val_len])\n",
    "        output_raw = remap_label(output_raw)\n",
    "        \n",
    "        test_name = get_id_from_file_path(test_img[val_len],'.png' )\n",
    "        \n",
    "        imsave(opts['result_save_path']+'validation/watershed_unet/{}.png'.format(test_name),\n",
    "               output_watershed.astype(np.uint16))\n",
    "        imsave(opts['result_save_path']+'validation/unet/{}.png'.format(test_name),output_raw.astype(np.uint16))\n",
    "\n",
    "        dice_unet[current_fold-1, val_len]= get_dice_1(validation_set_label[val_len], output_raw)\n",
    "        AJI_unet[current_fold-1, val_len] = get_fast_aji(validation_set_label[val_len], output_raw)\n",
    "        PQ_unet[current_fold-1, val_len] = get_fast_pq(validation_set_label[val_len], output_raw)[0][2]\n",
    "        \n",
    "        \n",
    "        dice_unet_watershed[current_fold-1, val_len]= get_dice_1(validation_set_label[val_len],output_watershed)\n",
    "        AJI_unet_watershed[current_fold-1, val_len] = get_fast_aji(validation_set_label[val_len], output_watershed)\n",
    "        PQ_unet_watershed[current_fold-1, val_len]  = get_fast_pq(validation_set_label[val_len], output_watershed)[0][2]\n",
    "\n",
    "    print('==========')    \n",
    "    print('average dice pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(dice_unet[current_fold-1, :]*100)))\n",
    "    print('average AJI pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(AJI_unet[current_fold-1, :]*100)))\n",
    "    print('average PQ pure Unet for fold{}: {:.2f}'.format(current_fold, np.mean(PQ_unet[current_fold-1, :]*100)))\n",
    "    dice_mean.append(np.mean(dice_unet[current_fold-1, :]*100))\n",
    "    aji_mean.append(np.mean(AJI_unet[current_fold-1, :]*100))\n",
    "    pq_mean.append(np.mean(PQ_unet[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "    \n",
    "    print('==========')    \n",
    "    print('average Dice Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                   np.mean(dice_unet_watershed[current_fold-1, :]*100)))\n",
    "    print('average AJI Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                  np.mean(AJI_unet_watershed[current_fold-1, :]*100)))\n",
    "    print('average PQ Unet watershed for fold{}: {:.2f}'.format(current_fold,\n",
    "                                                                 np.mean(PQ_unet_watershed[current_fold-1, :]*100)))\n",
    "    dice_watershed_mean.append(np.mean(dice_unet_watershed[current_fold-1, :]*100))\n",
    "    aji_watershed_mean.append(np.mean(AJI_unet_watershed[current_fold-1, :]*100))\n",
    "    pq_watershed_mean.append(np.mean(PQ_unet_watershed[current_fold-1, :]*100))\n",
    "    print('==========') \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    current_fold += 1\n",
    "    \n",
    "finish_time = time.time() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f58cfb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:48:39.446114Z",
     "iopub.status.busy": "2025-11-06T14:48:39.445450Z",
     "iopub.status.idle": "2025-11-06T14:48:39.469202Z",
     "shell.execute_reply": "2025-11-06T14:48:39.468535Z"
    },
    "papermill": {
     "duration": 0.527387,
     "end_time": "2025-11-06T14:48:39.470273",
     "exception": false,
     "start_time": "2025-11-06T14:48:38.942886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fold num  dice unet  dice unet watershed\n",
      "0    fold1  68.589808            62.041311\n",
      "1    fold2  54.404784            49.998211\n",
      "============================================================\n",
      "  fold num   AJI unet  AJI unet watershed\n",
      "0    fold1  38.911812           35.320433\n",
      "1    fold2  23.459896           22.774317\n",
      "============================================================\n",
      "  fold num    PQ unet  PQ unet watershed\n",
      "0    fold1  33.935528          30.541392\n",
      "1    fold2  18.088570          16.060592\n",
      "============================================================\n",
      "==========\n",
      "total training time (all 5 folds): 73.78 minutes\n"
     ]
    }
   ],
   "source": [
    "# fold_names = ['fold1', 'fold2','fold3','fold4','fold5']\n",
    "fold_names = ['fold1','fold2']\n",
    "df_dice = pd.DataFrame({'fold num':fold_names, 'dice unet':dice_mean,'dice unet watershed':dice_watershed_mean})\n",
    "\n",
    "df_aji = pd.DataFrame({'fold num':fold_names, 'AJI unet':aji_mean,'AJI unet watershed':aji_watershed_mean})\n",
    "\n",
    "df_pq = pd.DataFrame({'fold num':fold_names, 'PQ unet':pq_mean,'PQ unet watershed':pq_watershed_mean})\n",
    "\n",
    "df_dice.to_csv('/kaggle/working/dice.csv', index=False)\n",
    "df_aji.to_csv('/kaggle/working/aji.csv', index=False)\n",
    "df_pq.to_csv('/kaggle/working/pq.csv', index=False)\n",
    "\n",
    "print(df_dice.head())\n",
    "print('============================================================')\n",
    "print(df_aji.head())\n",
    "print('============================================================')\n",
    "print(df_pq.head())\n",
    "print('============================================================')\n",
    "\n",
    "print('==========') \n",
    "print('total training time (all 5 folds): {:.2f} minutes'.format((finish_time- start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b73324e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:48:40.556218Z",
     "iopub.status.busy": "2025-11-06T14:48:40.555941Z",
     "iopub.status.idle": "2025-11-06T14:48:40.824266Z",
     "shell.execute_reply": "2025-11-06T14:48:40.823522Z"
    },
    "papermill": {
     "duration": 0.768661,
     "end_time": "2025-11-06T14:48:40.825355",
     "exception": false,
     "start_time": "2025-11-06T14:48:40.056694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXwAAAHgCAYAAAAWmqVwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABUvklEQVR4nO3dd5hU5dkH4GdoC6x0QZEQQMSuGCE2UECNGImIkRBEDVhjL7HEDmgsKNYkEk3yYfs0NhRrYvCDGFuMGjU2IgjWCCiCKIKU9/vDzIRhF3YWtjHc93Vx6Z7z7pl3ZmfnOfPbd56TSSmlAAAAAABgnVevticAAAAAAEDVEPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAdcbMmTMjk8nEiBEj8rb37ds3MplMtd1u586do3PnztV2/Or0+OOPR69evaJVq1aRyWRi0KBBtT0lWCvr8u8jAEBdIPAFgPVQNlhd8V+jRo2iY8eOMWzYsHj11Vdre4pVasSIEZHJZGLmzJm1PZUqNXPmzDjggAPinXfeicMPPzxGjhwZQ4cOrdE53HzzzZHJZOLyyy+v0duFuqKqXl8eeuihOOmkk6JXr15RWloamUwmRo0aVeH3zZ49O0477bTo1q1bNG7cONq0aRO77rprjBs3bq3mAwCsuxrU9gQAgNrTtWvXOPTQQyMi4osvvojnnnsu7rzzzpgwYUI88cQT0atXr1qe4TduvfXWWLhwYbUd/4knnqi2Y1enSZMmxaJFi+Kqq66KYcOG1fZ0gLVw1VVXxV/+8pdo3rx5bLLJJjFt2rQKv+fll1+OffbZJz777LMYMGBADB48OL744ot4880346GHHorjjjuuBmYOANQ1Al8AWI9tttlmZVaQnX/++XHJJZfEeeedF1OmTKmVea3s29/+drUev2vXrtV6/Ory0UcfRUTEJptsUsszAdbWxRdfHBtvvHFsttlmcdddd8XBBx+82vGff/55HHDAARER8eKLL8b222+ft3/p0qXVNlcAoG7T0gEAyHPSSSdFRMTf//733LZMJhN9+/aNDz/8MH7yk5/ExhtvHPXq1csLhJ988snYf//9Y8MNN4ySkpLo1q1bnH/++eWuzF22bFmMGTMmNttss2jcuHFsttlmcdlll8Xy5cvLndPqevhOnDgx9tlnn2jTpk00btw4OnfuHIcddli89tprEfFNP9BbbrklIiK6dOmSa2HRt2/f3DFW1TP0yy+/jJEjR8aWW24ZjRs3jtatW8eAAQPi6aefLjN21KhRkclkYsqUKXHHHXfEDjvsEE2aNIn27dvHKaecEl999VWZ77nvvvuiT58+0a5du2jcuHFssskmsffee8d9991X7n3NyrbkGDlyZERE9OvXL3e/VvyZvPbaazFkyJBo165dlJSURJcuXeLUU0+NTz/9tMwxs4/BvHnz4sQTT4yOHTtGgwYN4uabb17tXFYle7z58+fHcccdF+3bt4/S0tLYY4894qWXXoqIbwLrQw89NNq1axdNmjSJffbZJ95+++0yx7r//vvj4IMPjs022yyaNm0aLVq0iN133321j9ONN94Y22yzTTRu3Dg6duwYZ511VixatKjMzz5rwYIFMXLkyNhmm22iSZMm0bJly+jfv3889dRTa3T/V7bi79CwYcNiww03jGbNmsWAAQPinXfeiYiIN998MwYNGhStW7eOZs2axeDBg2PWrFnlHu+hhx6Kfv36RYsWLaJJkybRvXv3uPrqq8uEfFOmTFlla4BV9cx+++234/DDD48uXbpESUlJtG7dOrp37x6nnnpqpJTyxlbn4/bFF1/EKaecEptsskmUlJTE9ttvH/fee2+5Y7/++uu4+uqrY8cdd4zS0tJo1qxZ7L777vHggw+WGfuvf/0rzjrrrNhxxx1zrxubb755nH322fHFF1+UGZ99/Vm0aFGcf/750bVr12jYsGGMGjWqoNeXQu2+++7RrVu3gvuV33DDDfHee+/F5ZdfXibsjYho0MDaHgBYXzkLAADKtXLo8Omnn8auu+4arVu3jqFDh8aiRYuiefPmERExbty4OOGEE6Jly5ax//77R7t27eKFF16ISy65JCZPnhyTJ0+ORo0a5Y51zDHHxP/8z/9Ely5d4oQTTohFixbF1VdfHc8880yl5nj66afH1VdfHa1bt45BgwZFu3bt4v33349JkyZFjx49Ytttt41TTz01br755njllVfilFNOiZYtW0ZEVHhRqEWLFsWee+4Zzz//fOy4445x6qmnxqxZs+Kuu+6KP/3pT3HnnXfGj370ozLf96tf/Sr++Mc/xgEHHBB77rln/PGPf4zrr78+Pvnkk/jf//3f3Lhx48bF8ccfH+3bt48DDzww2rRpEx9//HE8//zzcf/998dBBx20yrm1bNkyRo4cGVOmTIm//OUvMXz48Nz9yf73qaeeiv79+8fXX38dgwcPjs6dO8ezzz4b1113XTz88MPx3HPPxYYbbph33MWLF8eee+4ZX3zxRQwcODAaNGgQG220UcU/iFX4+uuv43vf+14sWrQofvzjH8esWbPi7rvvjr333jueeeaZ6N+/f7Rv3z4OPfTQmDZtWjz00EMxYMCAePPNN6N+/fq545xzzjnRqFGj6N27d7Rv3z7mzJkTDz74YAwePDiuv/763B8psi688MK4+OKLY6ONNoqjjz46GjZsGHfffXe89dZb5c5z7ty5sccee8Trr78evXr1imOPPTY+//zzmDhxYvTr1y/uueeevIvhTZkyJfr16xd9+vSp1Cr4zz77LHr37h0bb7xxDB8+PP71r3/Fww8/HG+99VZMnDgxdt999+jRo0ccccQR8eKLL8Z9990Xc+fOjf/7v//LO87VV18dp59+erRu3TqGDRsWpaWl8eCDD8bpp58ef/3rX2PChAlrfJHDjz76KHbaaaf48ssvY8CAAfHjH/84vvzyy3j77bfjhhtuiLFjx+aCxMo+bpWxZMmSXKuCgw46KBYuXBh/+MMfYsiQIfHHP/4x9tlnn9zYxYsXx7777htTpkyJHXbYIY488shYsmRJPPLII3HAAQfEL3/5yzjxxBNz4ydMmBC///3vo1+/ftG3b99Yvnx5PPfcczFmzJj4y1/+Ek8++WQ0bNiwzJwOOuigeOWVV2LfffeNli1b5v6AsiavL1XhrrvuikwmEwcddFBMnTo1Hn/88fjqq69iyy23jH333TfvNRcAWM8kAGC9M2PGjBQRqX///mX2XXjhhSkiUr9+/XLbIiJFRDr88MPT0qVL88a//vrrqUGDBql79+7pk08+ydt32WWXpYhIY8eOzW2bPHlyiojUvXv39MUXX+S2f/DBB2nDDTdMEZGGDx+ed5w+ffqklU9bHnrooRQRabvttitzu0uWLEkff/xx7uvhw4eniEgzZswo9/Ho1KlT6tSpU9620aNHp4hIhxxySFq+fHlu+0svvZQaNWqUWrZsmT7//PPc9pEjR6aISC1atEhvvfVWbvvChQvT5ptvnurVq5c+/PDD3PYdd9wxNWrUKM2aNavMfFa+P6uSvc3JkyfnbV+2bFnq2rVrioj0xz/+MW/fmWeemSIiHXHEEWUeg+xzYuHChQXdfkopjR8/PkVEuuyyy8o93o9+9KO0ZMmS3PYxY8akiEgtW7ZMp512Wt5je9xxx6WISPfdd1/esaZPn17mdhcsWJC222671KJFi/Tll1/mtk+dOjXVr18/dejQIe+x/fzzz9PWW2+dIiL16dMn71jDhg1LEZF++9vf5m2fNWtW6tixY2rbtm366quvctuzz+GVj7M62d+h0047LW979j63bNkyXXvttbnty5cvT/vtt1+KiPTiiy/mtk+bNi01aNAgtWvXLr333nu57YsWLUq9e/dOEZFuvfXWMnMdOXJkmTllXwdW/H27/vrrU0TkzSXr008/zfu6so9bobLPnQMOOCAtXrw4t33SpEnlvm6de+65KSLSBRdckPd8+vzzz1PPnj1To0aN8n73Pvjgg7zjZmV/52+//fa87dnXnx122KHMY5BSxa8va+LOO+9c5c8tpZQWL16c6tevn9q1a5cuvvjiVK9evdxzLCLSpptuml599dUqmw8AsG7R0gEA1mPTpk2LUaNGxahRo+LMM8+MPfbYIy666KJo3LhxXHLJJXljGzVqFFdccUXeysuIbz46v3Tp0vjlL38Zbdq0ydt31llnRdu2bePOO+/Mbbv11lsj4ptVmKWlpbntHTp0iFNOOaXgud9www0REXHdddeVud21XZkaEXHLLbdEw4YN4/LLL89bLfmd73wnhg8fHvPmzYsHHnigzPedcsopscUWW+S+btKkSRx88MGxfPnyePHFF/PGNmzYsNyVhCvfn8p6+umnY/r06fH9738/+vfvn7fvwgsvjNatW8cdd9wRX3/9dZnvveKKK6JJkyZrdfsrWnFFaETk+pIuXbo0fvGLX+Q9ttl9r7zySt4xNt100zLH3WCDDWLEiBExf/78vPYjd955ZyxbtixOP/30aNeuXW57s2bN4vzzzy9znE8++STuuuuu2HPPPeOoo47K29euXbs488wzY86cOTFp0qTc9p122inefPPN3HO5UBtssEH84he/yNuWvc9t2rSJk08+Obc9k8nE0KFDIyL/8bjjjjti6dKlcfrpp0fHjh1z20tKSmLMmDEREWvchmNF5T0HWrdunfv/NXncKuuaa67JW6W61157RadOnfJ+3suXL49x48ZF165dY/To0XnPp2bNmsWFF14YX3/9dUyYMCG3vUOHDuWufs2uAl7VnEePHp33GNSmuXPnxrJly+LTTz+Niy66KK644oqYNWtWfPDBB3HBBRfEjBkzYv/9949FixbV9lQBgFqgpQMArMemT58eo0ePjohvwseNNtoohg0bFmeffXZst912eWO7dOlSpgVARMRzzz0XERF/+tOf4oknniizv2HDhnkfpc+GV7vvvnuZseVtW5Xnn38+SkpKok+fPgV/T6E+//zzeOedd2KrrbaKb33rW2X29+vXL37729/Gyy+/HIcddljevh49epQZnz3GvHnzctuGDh0aZ511Vmy77bYxbNiw6NevX/Tu3TvXJmNt/OMf/4iIKLeP6AYbbBA9e/aMxx9/PKZOnZr3c27cuHGZn/vaaNWqVZkL7rVv3z4iIrp16xZNmzYtd1/2YnRZs2fPjssvvzwee+yxePfdd8v0Q15xfPb51bt37zLz6dWrV5ltf//732PZsmWxePHicvvcZnsKv/XWW/GDH/wgIiKaNm0aW265Zdk7XIHV3eftt9++TBuG8h6P1f1sd91112jcuHG8/PLLlZ5b1v777x/nnHNOnHDCCfHEE0/EvvvuG3369CkTuq/J41YZ2ZYJK/vWt74Vzz77bO7rqVOnxmeffRabbLJJ7rVsRXPmzMnNIyulFOPHj4+bb745XnvttZg/f35e//CVn39ZO+20U6XvR3XJznfZsmVx4oknxumnn57bd9FFF8XUqVPj7rvvjnvvvTcOPfTQ2pomAFBLBL4AsB7r379//PGPfyxo7KpWzM6dOzciosyK4FWZP39+1KtXr9zwuDKrcufPnx8dOnSIevWq/gNLn3/++Wrnkw3isuNWVF5gm13humzZsty2M844I9q0aRPjxo2Lq666KrcSdsCAAXHNNdeUG3ZV9/zbtWu3xr1fy7O6x2J1+5YsWZLbNnfu3Pjud78b7733XvTq1Sv23nvvaNmyZdSvXz9efvnlmDhxYixevDg3PnufVlzdm1Xe45F9/j799NPlXowv68svv1zlvkJVxeOxup9tJpOJjTbaKD788MM1nmPnzp3jueeei1GjRsWjjz4ad999d0REbLnllnHRRRfl+lZX9+PWokWLcrc3aNAgL5zNzuP111+P119/vaB5nHzyyfGrX/0qOnbsGAMHDoz27dtHSUlJRHyzinfF59OK1vZTA1Vpxcdn4MCBZfYPHDgw7r777njhhRcEvgCwHhL4AgAFWVUQmA2qPv/882jWrFmFx2nRokUsX748Pvnkk2jbtm3evlmzZhU8n5YtW8bHH38cy5cvr/LQN3ufVjWfjz/+OG/cmshkMnHEEUfEEUccEZ9++mn89a9/jTvvvDPuvvvuePvtt+PVV18t0z6jUGs6/6oMe6vK73//+3jvvffi4osvLtOS4fLLL4+JEyfmbcvep9mzZ0enTp3y9pX3eGTHn3766TF27NiqnHq1WPFnu/L9SynFrFmz8n6u2d+NpUuXljnW/Pnzy72NbbfdNu69995YsmRJvPjii/HYY4/F9ddfHz/+8Y9jk002iV69etWZxy07j4MOOijuvffeCsfPnj07fv3rX8f2228fzz77bN6K648//rjcVcJZden3o7S0NDp06BAffvhh7kJxK8puW3k1PACwftDDFwBYKzvvvHNE/Le1Q0W6d+8eERF//etfy+wrb9uq7LTTTrF48eL4y1/+UuHYbHC64grb1WnevHlsuummMW3atHJXS06ZMiUiInbYYYeC57s6bdq0iUGDBuV6or7xxhsxbdq0NT7ed77znYj47zxX9OWXX8YLL7wQTZo0yes1XFdNnz49IiIOOOCAMvvKe75kn1/lrTp95plnymz77ne/G5lMJq9NQF22up/t3/72t1i0aFHe87JVq1YREeU+j7PtIValYcOGscsuu8To0aPj+uuvj5RSPPzwwxFRdx63rbbaKpo3bx4vvPBC3kroVXnnnXcipRR77713mfYalXn9WVFlX1+qyp577hkREW+88UaZfdltnTt3rskpAQB1hMAXAFgrxx9/fDRo0CBOOumkeO+998rsnzdvXl6wlO15e9FFF+V9zPrDDz+M6667ruDbPeGEEyLim4ukZT/WnbV06dK81ZzZCy29//77BR9/+PDhsWTJkjjnnHMipZTb/uqrr8bNN98cLVq0iEGDBhV8vJVNmTIl77gR33x0P3tfGjduvMbH7tWrV3Tt2jUee+yxMheg+sUvfhGffvppHHzwweVeuKquya5ifeqpp/K233HHHfHoo4+WGT906NCoV69eXHXVVfHJJ5/ktn/55Zflth3ZeOONY8iQIfHMM8/ElVdeWeZnEvFNkLpw4cLc1wsXLoy33nqr3Od7dRs2bFg0aNAgrr766rxes19//XX8/Oc/j4iIESNG5LZvscUW0axZs3jwwQfzfk9mzZpV5gJyEREvvvhiua1Ksr9P2eflmjxu1aFBgwZx3HHHxbvvvhtnnHFGuaHva6+9FrNnz46I/z6fnnnmmbzWEB988EGcc845azSHNXl9qQrHHntsRHyz0n3F/uAff/xxXHfddVGvXr046KCDanROAEDdoKUDALBWtt1227jhhhviuOOOiy222CL222+/6Nq1ayxYsCDeeeed+Mtf/hIjRoyI3/zmNxHxzQXPDj/88Bg/fnxst912ceCBB8bixYvjrrvuil122SW3grAi++23X5xxxhkxduzY6NatWxx44IHRrl27+PDDD+OJJ56IM844I0499dSI+GYl3NixY+OYY46Jgw46KEpLS6NTp05lLri2orPOOiseeeSRuO222+LNN9+MvfbaK2bPnh133XVXLF26NH77298W1MJiVQYNGhTNmzePXXbZJTp16hRLliyJP//5z/HGG2/E4MGDy3xcvzLq1asXN998c/Tv3z/222+/+NGPfhSdOnWKZ599NqZMmRJdu3aNyy+/fI2PX5MOO+ywGDNmTJx00kkxefLk6NSpU7zyyivxxBNPxA9/+MOYMGFC3vgtttgizj777Lj00ktju+22iyFDhkSDBg1iwoQJsd1228Vrr71WpgXIDTfcEFOnTo2zzjorbrvttth1112jZcuW8f7778cLL7wQb7/9dvz73//OrQh9/vnno1+/ftGnT59yV9pWp65du8aYMWPi9NNPj+233z6GDBkSpaWl8dBDD8XUqVPjgAMOyOvZ2qhRozjppJPi0ksvjR133DEOOOCAWLBgQTz00EPRp0+f3ArqrNtuuy1uvPHG2GOPPaJr167RvHnzeOONN+LRRx+N1q1bx+GHH54bW9nHrbqMHj06Xnrppbj++uvjkUceiT322CP3WvDPf/4zXnnllXj22WejXbt20b59+zjooIPivvvui549e8Zee+0Vs2bNiocffjj22muvMo9HIdbk9aU8DzzwQDzwwAMRETFjxozctpkzZ0bEN32Uzz777Nz43XbbLX72s5/F1VdfHdtvv33sv//+sWTJkpg4cWLMnj07Lr300th8880rfX8AgCKQAID1zowZM1JEpP79+xc0PiJSnz59Vjvm+eefT0OHDk2bbLJJatiwYdpwww3TjjvumM4+++z05ptv5o1dunRpuuyyy9Kmm26aGjVqlDbddNN06aWXpmnTpqWISMOHD88b36dPn7Sq05b77rsv9evXL7Vo0SKVlJSkzp07p8MOOyy99tpreeOuuOKK1K1bt9SwYcMy96dTp06pU6dOZY79xRdfpAsuuCBtvvnmqVGjRqlly5bp+9//fvrrX/9aZuzIkSNTRKTJkyeX2Td+/PgUEWn8+PG5bTfccEMaOHBg6tSpU2rcuHFq06ZN2mmnndK4cePS119/Xe59rcxtppTSq6++mgYPHpw23HDD1LBhw9SpU6d0yimnpDlz5pQZu6rHoCLZ+3bZZZcVfLxVPZ+yz8uVf/4vv/xy2meffVKrVq1Ss2bNUp8+fdKkSZPKfVyzbrjhhrTVVlulRo0apW9961vpjDPOSO+//36KiHTAAQeUGb9w4cJ0xRVXpB49eqTS0tLUpEmT1KVLlzRo0KB06623piVLluTGTp48uaDfibW5zyvezsiRI8vsmzhxYurTp09q1qxZKikpSdttt1266qqr8uaZtWzZsjRq1KjUsWPH1KhRo7T55pun6667Lr3zzjtlbvu5555LP/3pT9O2226bWrZsmZo0aZK6deuWTjzxxPTuu++WOXZlHrdCre65s6rXgqVLl6Ybb7wx9erVKzVv3jyVlJSkb3/722nfffdN48aNS1988UVu7IIFC9Lpp5+eOnfunEpKSlK3bt3SxRdfnL7++utyf06re/3JWt3rS6Gyv8+r+reqY44fPz717NkzNW3aNJWWlqbevXunCRMmVPr2AYDikUmpnM9fAQBAkZk0aVJ873vfi7POOivGjBlT29MBAIBqoYcvAABFZc6cOWUuoDVv3rxcj9a16b0MAAB1nR6+AAAUlf/93/+NsWPHxp577hmbbLJJ/Pvf/44//vGPMXv27BgxYkTsuuuutT1FAACoNgJfAACKym677RY9evSISZMmxdy5c6N+/fqx1VZbxQUXXBDHH398bU9vvfPAAw/Eyy+/XOG4vn37Rt++fat9PjXl2muvjXnz5lU4bsSIEdG5c+dqnw8AsP4Q+AIAUFR22mmnmDhxYm1Pg/944IEH4pZbbilobLEFvu+++26F4/r27SvwBQCqlIu2AQAAAAAUCRdtAwAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8GW9kMlkYtSoUbU9jdUaMWJEbLDBBrU9jYiIGDVqVGQymfjkk0+q7JgjRoyIzp07V9nxAAAAoFB9+/aNbbfdtkZua13IIChuAl9yZsyYESeeeGJsvvnm0bRp02jatGlsvfXWccIJJ8Srr75a29OrVn379o1MJlPhv7V9wV64cGGMGjUqpkyZUiXzXlFNFi8A6o6bb745r1Y1btw4Nt988zjxxBNj1qxZtT29nJkzZ0Ymk4mxY8eWu3/s2LGRyWRi5syZFR6rc+fOkclk4qSTTiqzb8qUKZHJZOLee++t9Bw/+uijGDVqVLz88suV+r7XX389Dj300OjQoUOUlJTEJptsEocccki8/vrrlZ7Dii699NJ44IEH1uoYhXrmmWdi1KhRMW/evBq5PYCaVNGClm233Tb69u1b4XGyNSaTycSLL75YZv/aLOJ59NFHayUgPP7446NevXoxd+7cvO1z586NevXqRUlJSSxatChv3zvvvBOZTCbOPffcgm+nOt8Lr+s+/fTTOPPMM2OLLbaIxo0bR+vWraN///7x8MMPr9Vx77jjjrj22murZpIVWNNzKKqPwJeIiHj44Ydj2223jdtuuy323nvvuOaaa+K6666L73//+/Hoo4/GDjvsEO+++25tT7PanHfeeXHbbbfl/p188skREXHuuefmbf/hD3+4VrezcOHCGD16tCIHQJW76KKL4rbbbotf/epXsdtuu8W4ceNi1113jYULF9b21KrNb3/72/joo4+q7HgfffRRjB49ulJvViZMmBA77rhjPPHEE3H44YfHDTfcEEceeWRMnjw5dtxxx7j//vvXeD41HfiOHj1a4AtQoKoOZx999NEYPXp0lR6zEL17946UUjz99NN525955pmoV69eLFmyJF544YW8fdmxvXv3Lvh2vBcu39SpU6N79+5x/fXXR79+/eJXv/pVnHvuuTF79uzYf//948wzz1zjY9d04FvZcyiqV4PangC1b/r06TF06NDo1KlTPPHEE9G+ffu8/WPGjIkbbrgh6tVb/d8HvvzyyygtLa3OqVab733ve3lfN27cOK6//vr43ve+t9q/9K7L9xmA4vL9738/evbsGRERRx11VLRp0yauvvrqmDhxYhx88MFrdeylS5fG8uXLo1GjRlUx1SqxzTbbxNSpU+Pyyy+P66+/vlbmMH369DjssMNi0003jSeffDLatm2b23fKKafE7rvvHocddli8+uqrsemmm9bKHAGoejvssEM8/PDD8dJLL8WOO+5Y29OJiG8+SdOlS5eYPHlyQauVs7Kh7VNPPRX7779/bvvTTz8d22+/fXz11Vfx1FNP5YW7Tz31VNSrVy922223Kpv/mlqX35MvWbIkBg8eHJ999lk8+eSTsfPOO+f2nXbaaXHIIYfE2LFjo2fPnvHjH/+4FmfKusgKX+KKK66IL7/8MsaPH18m7I2IaNCgQZx88snRsWPH3LbsR1WmT58e++23XzRr1iwOOeSQiPjmBff000+Pjh07RklJSWyxxRYxduzYSCnlvj/7sc6bb765zO2t3Doh+/GbadOmxYgRI6Jly5bRokWLOPzww8usWlq8eHGcdtpp0bZt22jWrFkMHDgwPvjgg7V8hPLn8cYbb8SwYcOiVatWuaLXt2/fcovqin1rZ86cmXsjOHr06FW2ifjwww9j0KBBscEGG0Tbtm3jjDPOiGXLllXJfXj11VdjxIgRsemmm0bjxo1j4403jiOOOCI+/fTTcsd/8sknMWTIkGjevHm0adMmTjnllDIf54mIuP3226NHjx7RpEmTaN26dQwdOjTef//9KpkzAGtmzz33jIhvWjZFFFarIvJbL1x77bXRtWvXKCkpiTfeeCMiIt56660YPHhwtG7dOho3bhw9e/aMBx98sNrvz8o6d+4cP/nJTwpe5fvhhx/GEUccERtttFGUlJTENttsE//zP/+T2z9lypT47ne/GxERhx9+eK5Ol3euknXllVfGwoUL46abbsoLeyMiNtxww7jxxhvjyy+/jCuuuCK3fVU97bPnGVmZTCa+/PLLuOWWW3JzGTFiRN7Yt956a7V1utDzrVGjRuVWEHXp0iV3e4W01wBYH5100knRqlWrglf5PvbYY7H77rtHaWlpNGvWLAYMGJDX9mfEiBHx61//OiIir01TTfj2t78dHTt2LLPC9+mnn45evXrFbrvtVu6+bbbZJlq2bBlff/11XHjhhdGjR49o0aJFlJaWxu677x6TJ0/OjS/kvXAh5xfZNlZ/+ctf4vjjj4927drFt771rYiIWLBgQZx66qnRuXPnKCkpiXbt2sX3vve9eOmll8rc5zfeeCP69esXTZs2jQ4dOuTV6azFixfHyJEjY7PNNouSkpLo2LFjnHXWWbF48eIy49Y0g7jvvvvitddei7PPPjsv7I2IqF+/ftx4443RsmXLvMcp+xisXKOz7UayK6j79u0bjzzySLz77ru5xzt7/pEde9ddd8W5554bG2+8cZSWlsbAgQPLvI/v3Llz7vxjRSueV67JORTVzwpf4uGHH47NNtuszAtMRZYuXRr9+/eP3r17x9ixY6Np06aRUoqBAwfG5MmT48gjj4wddtgh/vSnP8WZZ54ZH374YVxzzTVrPM8hQ4ZEly5d4rLLLouXXnopfve730W7du1izJgxuTFHHXVU3H777TFs2LDYbbfd4v/+7/9iwIABa3yb5fnRj34U3bp1i0svvTQvxK5I27ZtY9y4cXHcccfFgQcemGsPsf322+fGLFu2LPr37x8777xzjB07NiZNmhRXXXVVdO3aNY477ri1nvuf//zneOedd+Lwww+PjTfeOF5//fW46aab4vXXX4/nnnuuzEnFkCFDonPnznHZZZfFc889F9dff3189tlnceutt+bGXHLJJXHBBRfEkCFD4qijjoo5c+bEL3/5y9hjjz3iH//4R7Rs2XKt5w1A5U2fPj0iItq0abNG3z9+/PhYtGhRHHPMMVFSUhKtW7eO119/PXr16hUdOnSIs88+O0pLS+Puu++OQYMGxX333RcHHnhgVd6FCp133nlx6623VrjKd9asWbHLLrtEJpOJE088Mdq2bRuPPfZYHHnkkfH555/HqaeeGltttVVcdNFFceGFF8YxxxwTu+++e0TEalcvPfTQQ9G5c+fc2JXtscce0blz53jkkUcqfd9uu+22OOqoo2KnnXaKY445JiIiunbtmjemkDpdiB/+8Ifxr3/9K+6888645pprYsMNN4yIKBNiA/CN5s2bx2mnnRYXXnhhhat8b7vtthg+fHj0798/xowZEwsXLoxx48ZF79694x//+Ed07tw5fvrTn8ZHH30Uf/7zn+O2226rwXvyjd69e8eECRNi8eLFUVJSEl9//XX8/e9/j+OOOy4WLlwYZ511VqSUIpPJxGeffRZvvPFGHHvssRER8fnnn8fvfve7OPjgg+Poo4+OBQsWxO9///vo379/PP/887HDDjtU+F64sucXxx9/fLRt2zYuvPDC+PLLLyMi4thjj4177703TjzxxNh6663j008/jaeeeirefPPNvJ/PZ599Fvvuu2/88Ic/jCFDhsS9994bP//5z2O77baL73//+xERsXz58hg4cGA89dRTccwxx8RWW20V//znP+Oaa66Jf/3rX3ntltYmg3jooYciIuInP/lJuftbtGgRBxxwQNxyyy0xbdq02GyzzQo6bsQ350jz58+PDz74IJfDrNxf+pJLLolMJhM///nPY/bs2XHttdfG3nvvHS+//HI0adKk4Ntak3MoakBivTZ//vwUEWnQoEFl9n322Wdpzpw5uX8LFy7M7Rs+fHiKiHT22Wfnfc8DDzyQIiL94he/yNs+ePDglMlk0rRp01JKKc2YMSNFRBo/fnyZ242INHLkyNzXI0eOTBGRjjjiiLxxBx54YGrTpk3u65dffjlFRDr++OPzxg0bNqzMMStyzz33pIhIkydPLjOPgw8+uMz4Pn36pD59+pTZPnz48NSpU6fc13PmzFnlXLKP6UUXXZS3/Tvf+U7q0aNHhXPu06dP2mabbVY7ZsWfYdadd96ZIiI9+eSTuW3Z+zpw4MC8sccff3yKiPTKK6+klFKaOXNmql+/frrkkkvyxv3zn/9MDRo0yNu+8mMBQNUYP358iog0adKkNGfOnPT++++nP/zhD6lNmzapSZMm6YMPPkgpFV6rsjW6efPmafbs2Xlj99prr7TddtulRYsW5bYtX7487bbbbqlbt26rnWf2uFdeeWW5+6+88soUEWnGjBkV3udOnTqlAQMGpJRSOvzww1Pjxo3TRx99lFJKafLkySki0j333JMbf+SRR6b27dunTz75JO84Q4cOTS1atMjVx7///e+rPD9Z2bx581JEpAMOOGC14wYOHJgiIn3++ecppVXXw2ztXVFpaWkaPnz4KsdWVKcrc75VmccfYF2Tfd2cM2dOufu32WabcmvkylasMfPmzUutWrXKey0ePnx4Ki0tzX29YMGC1LJly3T00UfnHefjjz9OLVq0yNt+wgknlKkDlZF9zV/xPWyhfv3rX6eISH/9619TSik9++yzKSLSu+++m954440UEen1119PKaX08MMPp4hI//u//5tSSmnp0qVp8eLFecf77LPP0kYbbZT3Hn5174ULPb/InvP07t07LV26NO8YLVq0SCeccMJq72efPn1SRKRbb701t23x4sVp4403TgcddFBu22233Zbq1auXezyyfvOb36SISE8//XRKae0ziB122CG1aNFitWOuvvrqFBHpwQcfTCn99zFYuV5nn5sr/vwHDBhQ7jlHdmyHDh1y5ycppXT33XeniEjXXXddblunTp3KPRdZ+byyMudQ1AwtHdZzn3/+eUSU/UtPxDdL9Nu2bZv7l/2IyYpWXnX66KOPRv369XMXPcs6/fTTI6UUjz322BrPNfsXxKzdd989Pv3009x9ePTRRyMiytz2qaeeusa3Wcg8qlp59/Odd96pkmOv+Fe6RYsWxSeffBK77LJLRES5H3U54YQT8r7OXg09+1hPmDAhli9fHkOGDIlPPvkk92/jjTeObt265X2MB4Dqtffee0fbtm2jY8eOMXTo0Nhggw3i/vvvjw4dOqzR8Q466KC8FZ5z586N//u//4shQ4bEggULcq/5n376afTv3z/efvvt+PDDD6vq7hTs/PPPj6VLl8bll19e7v6UUtx3332x//77R0opr171798/5s+fX24NrMiCBQsiIqJZs2arHZfdnz1fqUoV1WkAqk+LFi3i1FNPjQcffDD+8Y9/lDvmz3/+c8ybNy8OPvjgvPpTv3792Hnnndfq/dIXX3yRd8zPPvssIiLmz5+ft33+/PkVHmvFPr4R37Rs6NChQ3z729+OLbfcMlq3bp1r67DyBdvq16+f6/G/fPnymDt3bixdujR69uxZUH1dk/OLo48+OurXr5+3rWXLlvG3v/2twjZPG2ywQRx66KG5rxs1ahQ77bRT3nvue+65J7baaqvYcsst8x7LbLus7M9tbTOIBQsW1Op5xE9+8pO82x88eHC0b9/eeUSR0NJhPZf95f7iiy/K7LvxxhtjwYIFMWvWrLwXxKwGDRrk+uVkvfvuu7HJJpuUedHaaqutcvvX1Le//e28r1u1ahUR33wko3nz5vHuu+9GvXr1ynzccYsttljj2yxPly5dqvR4K2rcuHGZj0+2atUqV7zX1ty5c2P06NHxhz/8IWbPnp23r7wTgW7duuV93bVr16hXr16uX9Dbb78dKaUy47IaNmxYJfMGoGK//vWvY/PNN48GDRrERhttFFtssUWFF1xdnZXr3bRp0yKlFBdccEFccMEF5X7P7Nmz1zhgzsq2F5o/f3589dVXue2NGjWK1q1blxm/6aabxmGHHRY33XRTnH322WX2z5kzJ+bNmxc33XRT3HTTTaucd2Vlz3Wywe+qFBoMr4mK6jQAhVuxvd3HH3+ct69FixblfsT9lFNOiWuuuSZGjRoVEydOLLP/7bffjoj/9tVfWfPmzdd4vieeeGLccsstZbYPGjQo7+s+ffrk+rquyrbbbhstW7bMC3V79eoVEd88Lrvuums8/fTTcfTRR8fTTz8dHTt2zHt/fsstt8RVV10Vb731VixZsiS3vZD3zmtyflHeca+44ooYPnx4dOzYMXr06BH77bdf/OQnPylz0dRvfetbZVoZtmrVKl599dXc12+//Xa8+eabq2xtlD1vWNsMolmzZvHJJ5+sdkxNnkdkMpnYbLPNnEcUCYHveq5FixbRvn37eO2118rsy/b0XdUve0lJyRq/kVxVA/rVXZxs5b/gZaVK9NGtCuUV+kwmU+48KnuxtVXdx6oyZMiQeOaZZ+LMM8+MHXbYITbYYINYvnx57LvvvrF8+fIKv3/ln9vy5csjk8nEY489Vu7cy1s5DkD12GmnnaJnz56r3F/ZWrVyvcvWiTPOOCP69+9f7vesrrdc48aNIyLyQtwVZS/Emh13yimn5L2RXd0b1vPOOy9uu+22GDNmTJk3utl5H3rooTF8+PByv3/FfvqFyp5DrfgGsTyvvvpqdOjQIfemfk3OgQq18rGr87YA1iWF1KDsmIgoczHz8ePHl3vhquwq31GjRpW7yjdbg2677bbYeOONy+xv0GDNI5mzzjorb2FWdqHW2LFjo3v37rnt2YVSq1OvXr3Ydddd45lnnomUUjz99NNx7rnn5vbvtttu8T//8z+53r4r1trbb789RowYEYMGDYozzzwz2rVrF/Xr14/LLrssdz2B1VmT84vy3pMPGTIkdt9997j//vvj8ccfjyuvvDLGjBkTEyZMyPXmjSgsV1i+fHlst912cfXVV5c7dsUL2q+NrbbaKl5++eV47733yixwy8qeZ2y99dYRUfO1fXW3V935BWtH4EsMGDAgfve738Xzzz8fO+2001odq1OnTjFp0qQyH0146623cvsj/lt05s2bl/f9a7MCuFOnTrF8+fKYPn163l/Upk6dusbHLFSrVq3Kbbuw8v2pqSutluezzz6LJ554IkaPHh0XXnhhbnv2r87lefvtt/P+ejpt2rRYvnx57uqeXbt2jZRSdOnSJTbffPNqmzsAa6/QWrUq2RUyDRs2jL333rvSt9+2bdto2rTpKuvy1KlTo2nTprkLhq38RnZ1b1i7du0ahx56aNx4441lLkKbvWr2smXLKpx3Zev0D37wg/jtb38bTz31VO6jrSv661//GjNnzoyf/vSnefdj5fOfiPJ/DhXNp6I6XZnzrdo8RwGobtn3oVOnTi0T1i1cuDDef//92GeffXLb/vznP+eN2WabbVZ57FNPPTWuvfbaGD16dJkLVmdXfrZr167Ka9DWW2+dCwEj/rtQq0ePHtG3b99KHSvimxYNjz32WDz44IMxe/bs3ArfiG8C3/POOy8effTR+Oqrr/Jq3r333hubbrppTJgwIe8+jBw5Mu/4q7p/a3t+saL27dvH8ccfH8cff3zMnj07dtxxx7jkkkvyAt9CdO3aNV555ZXYa6+9VvtzWdsM4gc/+EHceeedceutt8b5559fZv/nn38eEydOjC233DIXeldlbV85C0gpxbRp0/L+EL6685YVV087j6h79PAlzjrrrGjatGkcccQRMWvWrDL7K7OCdr/99otly5bFr371q7zt11xzTWQymdwLbfPmzWPDDTeMJ598Mm/cDTfcsAb34BvZY698le5rr712jY9ZqK5du8Zbb70Vc+bMyW175ZVXch+JyWratGlElH1xrgnZv76t/PNc3eOzct/mX/7ylxHx38f6hz/8YdSvXz9Gjx5d5rgppfj000/XdtoAVJFCa9WqtGvXLvr27Rs33nhj/Pvf/y6zf8Xjlqd+/fqxzz77xEMPPRTvvfde3r733nsvHnroodhnn31y9WrrrbeOvffeO/evR48eqz3++eefH0uWLIkrrriizO0edNBBcd9995X7iaYV511aWhoRhdfpM888M5o0aRI//elPy9S8uXPnxrHHHhtNmzaNM888M7e9a9euMX/+/LyVwf/+97/j/vvvL3P80tLS1c6lojpdmfOtyt53gHXJXnvtFY0aNYpx48aV+WTjTTfdFEuXLs0LBVesP3vvvXeZFb8ryq7ynThxYrz88st5+/r37x/NmzePSy+9NK/VQdba1KCqlg1xx4wZE02bNo0ddtght2+nnXaKBg0a5GrsioFvee8z//a3v8Wzzz6bd/xVvRde2/OLiG9Wm67corBdu3axySabxOLFiyv8/pUNGTIkPvzww/jtb39bZt9XX30VX375ZUSsfQYxePDg2HrrrePyyy+PF154IW/f8uXL47jjjovPPvssLzzP/hFhxdq+bNmycttWlZaWrraH86233prXmuree++Nf//733m/C127do3nnnsuvv7669y2hx9+ON5///0ytxXhPKIuscKX6NatW9xxxx1x8MEHxxZbbBGHHHJIdO/ePVJKMWPGjLjjjjuiXr16Zfr1lmf//fePfv36xXnnnRczZ86M7t27x+OPPx4TJ06MU089Na+3zVFHHRWXX355HHXUUdGzZ8948skn41//+tca348ddtghDj744Ljhhhti/vz5sdtuu8UTTzwR06ZNW+NjFuqII46Iq6++Ovr37x9HHnlkzJ49O37zm9/ENttsk9dcvUmTJrH11lvHXXfdFZtvvnm0bt06tt1229h2222rZB5z5syJX/ziF2W2d+nSJQ455JDYY4894oorroglS5ZEhw4d4vHHH48ZM2as8ngzZsyIgQMHxr777hvPPvts3H777TFs2LDcR4S6du0av/jFL+Kcc86JmTNnxqBBg6JZs2YxY8aMuP/+++OYY46JM844o0ruGwBrp9BatTq//vWvo3fv3rHddtvF0UcfHZtuumnMmjUrnn322fjggw/ilVdeWe33X3rppbHLLrvEjjvuGMccc0x07tw5Zs6cGTfddFNkMpm49NJL1/j+ZVf5ltfP8PLLL4/JkyfHzjvvHEcffXRsvfXWMXfu3HjppZdi0qRJMXfu3NwxWrZsGb/5zW+iWbNmUVpaGjvvvPMqexB269YtbrnlljjkkENiu+22iyOPPDK6dOkSM2fOjN///vfxySefxJ133pl3/jN06ND4+c9/HgceeGCcfPLJsXDhwhg3blxsvvnmZS5u06NHj5g0aVJcffXVsckmm0SXLl3yVjBXVKcjCj/fygbq5513XgwdOjQaNmwY+++/f+4NHMC6rF27dnHhhRfG+eefH3vssUcMHDgwmjZtGs8880zceeedsc8++8T++++/xsfP9vJ95ZVX8l43mzdvHuPGjYvDDjssdtxxxxg6dGi0bds23nvvvXjkkUeiV69eucVS2dfhk08+Ofr37x/169ePoUOHrt0dr4SddtopGjVqFM8++2z07ds3r91E06ZNo3v37vHss89Gy5Yt896//uAHP4gJEybEgQceGAMGDIgZM2bEb37zm9h6663zrhW0uvfCa3t+sWDBgvjWt74VgwcPju7du8cGG2wQkyZNir///e9x1VVXVfqxOOyww+Luu++OY489NiZPnhy9evWKZcuWxVtvvRV33313/OlPf4qePXuudQbRqFGjuPfee2OvvfaK3r17x+GHHx49e/aMefPmxR133BEvvfRSnH766XnPg2222SZ22WWXOOecc2Lu3LnRunXr+MMf/hBLly4tc/wePXrEXXfdFT/72c/iu9/9bmywwQZ5z/PWrVvnbnfWrFlx7bXXxmabbRZHH310bsxRRx0V9957b+y7774xZMiQmD59etx+++1l+hZX9hyKGpDgP6ZNm5aOO+64tNlmm6XGjRunJk2apC233DIde+yx6eWXX84bO3z48FRaWlrucRYsWJBOO+20tMkmm6SGDRumbt26pSuvvDItX748b9zChQvTkUcemVq0aJGaNWuWhgwZkmbPnp0iIo0cOTI3buTIkSki0pw5c/K+f/z48Ski0owZM3Lbvvrqq3TyySenNm3apNLS0rT//vun999/v8wxK3LPPfekiEiTJ0+ucB5Zt99+e9p0001To0aN0g477JD+9Kc/peHDh6dOnTrljXvmmWdSjx49UqNGjfLmtarHNHu7FenTp0+KiHL/7bXXXimllD744IN04IEHppYtW6YWLVqkH/3oR+mjjz5a5WP+xhtvpMGDB6dmzZqlVq1apRNPPDF99dVXZW77vvvuS717906lpaWptLQ0bbnllumEE05IU6dOzY0p77EAYO1l6+Hf//73CscWUqtmzJiRIiJdeeWV5R5j+vTp6Sc/+UnaeOONU8OGDVOHDh3SD37wg3TvvfcWNN8333wz/fjHP07t2rVLDRo0SO3atUtDhw5Nb775ZkHfn1JKnTp1SgMGDCiz/e23307169dPEZHuueeevH2zZs1KJ5xwQurYsWNq2LBh2njjjdNee+2VbrrpprxxEydOTFtvvXVq0KBBiog0fvz4Cufz6quvpoMPPji1b98+d+yDDz44/fOf/yx3/OOPP5623Xbb1KhRo7TFFluk22+/vdx6/9Zbb6U99tgjNWnSJEVEGj58eEqpcnW60POtlFK6+OKLU4cOHVK9evXKnGMBFIPbb7897bLLLqm0tDSVlJSkLbfcMo0ePTotWrSooO+fPHlyuTUmpf++Npf3nm7y5Mmpf//+qUWLFqlx48apa9euacSIEemFF17IjVm6dGk66aSTUtu2bVMmkynoPeCKsvV7xfewlbXrrrumiEjnnntumX0nn3xyioj0/e9/P2/78uXL06WXXpo6deqUSkpK0ne+85308MMPV+q9cEqFnV+s6pxn8eLF6cwzz0zdu3dPzZo1S6Wlpal79+7phhtuyBvXp0+ftM0225S5b+XN9euvv05jxoxJ22yzTSopKUmtWrVKPXr0SKNHj07z58/PjauKDGL27NnpZz/7Wdpss81SSUlJatmyZdp7773Tgw8+WO746dOnp7333juVlJSkjTbaKJ177rnpz3/+c5mf/xdffJGGDRuWWrZsmSIidx+zz+M777wznXPOOaldu3apSZMmacCAAendd98tc3tXXXVV6tChQyopKUm9evVKL7zwQurTp0/q06dP3rg1OYei+mRSquErXgEAAGts1KhRMXr06JgzZ06u5zEAQCGmTJkS/fr1i3vuuScGDx5c29OhmujhCwAAAABQJAS+AAAAAABFQuALAAAAAFAk9PAFAAAAACgSVvgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkWhQ6MBMJlOd8wCgCLgOaN2idgNQEbW7blG7AahIIbXbCl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCLRoLYnAFAXHBNnFjz2priyGmcCAAAAsOYEvgCVVFE4LBAGAAAAaouWDsB6rzKrewEAAADqMoEvQBUTIAMAAAC1ReALAAAAAFAkBL4AAAAAAEVC4AsAAAAAUCQEvgAAAAAARULgCwAAAABQJAS+AAAAAABFQuALAAAAAFAkBL7Aeu+muLK2pwAAAABQJQS+ACH0BQAAAIqDwBfgP4S+AAAAwLpO4AuwgqoIfQXHAAAAQG0R+AIAAAAAFAmBL8BK1maFrtW9AAAAQG3KpJRSQQMzmeqeC0Cdc0ycWfBYYW9EgSWFGqJ2A1ARtbtuUbsBqEghtVvgC0CV8aaxblG7AaiI2l23qN0AVKSQ2q2lAwAAAABAkWhQ2xMAWJ/9In5d7vbz44QangkAAABQDKzwBaiDVhUEAwAAAKyOwBcAAAAAoEgIfAHqKKt8AQAAgMoS+ALUYUJfAAAAoDIEvgAAAAAARULgCwAAAABQJAS+AHWctg4AAABAoQS+AAAAAABFQuALAAAAAFAkBL4AAAAAAEVC4AsAAAAAUCQEvgC16Pw4obanAAAAABQRgS8AAAAAQJEQ+ALUsvPjBCt9AQAAgCoh8AUAAAAAKBICXwAAAACAIiHwBQAAAAAoEgJfgDpCH18AAABgbWVSSqmggZlMdc8FgHVcgSWFGqJ2A1ARtbtuUbsBqEghtdsKXwAAAACAIiHwBQAAAAAoEgJfAAAAAIAi0aC2JwBA9dkubs/9/z/j0FqcCQAAAFATXLQNoEitGPaurLrCXxd+qVvUbgAqonbXLWo3ABVx0TYAyrW6MBgAAABYdwl8AdZT28Xtgl8AAAAoMgJfAAAAAIAiIfAFWM9Z5QsAAADFQ+ALgPYOAAAAUCQEvgDkCH0BAABg3SbwBQAAAAAoEgJfAPJY5QsAAADrLoEvQJH6Zxxa21MAAAAAapjAF6CIrWnoa5UvAAAArJsEvgAAAAAARSKTUkoFDcxkqnsuAFSjNVm1W9kVwgWWFGqI2g1ARdTuukXtBqAihdRuK3wBAAAAAIqEwBdgPeEibgAAAFD8BL4ArJKLtwEAAMC6ReALsB5Zk1W+Ql8AAABYdwh8AdYzVdva4W8r/AMAAABqm8AXgDUk5AUAAIC6pkFtTwCAmpdd5btm7RoEvQAAAFBXWeELsB6rXHsHrRsAAACgrhP4AgAAAAAUCYEvwHrun3FoFV/IDQAAAKgtmZRSKmhgJlPdcwGgTquoncPOUWBJoYao3QBURO2uW9RuACpSSO22whcAAAAAoEgIfAEo0M61PQEAAACgAgJfAAAAAIAiIfAFAAAAACgSAl8AqoB2DwAAAFAXCHwBAAAAAIpEg9qeAAXqNz3/68lda2cewHouu5L3b7U6CwAAAKB8VviuK1YOeFcOgAEAAACA9V4mpZQKGpjJVPdcKER5Qa/VvkCtWHGV7zcrfwssKdQQtRuAiqjddYvaDUBFCqndVviua8oLd/tNt+IXAAAAABD4FhWhL1Cjdq54CAAAAFCjBL7rIi0cAAAAAIByCHyLjVW+QI2yyhcAAADqEoFvMRL6AjVK6AsAAAB1hcC3WAl9AQAAAGC9I/BdV+njCwAAAACsROC7Lqso9LXKFwAAAADWKwJfAAAAAIAiIfBd11nlCwAAAAD8h8B3fSD0BQAAAID1gsC3GBRyATehLwAAAAAUPYHv+kToCwAAAABFTeBbLApZ5Rsh9AUAAACAIibwLSZCXwAAAABYrwl811dCXwAAAAAoOgLf9ZnQFwAAAACKSiallAoamMlU91yoKmsS5BbaDgJgNQosKdQQtRuAiqjddYvaDUBFCqndVvgCAAAAABQJgW8xsloXAAAAANZLAt9iJfQFAAAAgPWOwBcAAAAAoEgIfIuZVb4AAAAAsF4R+AIAAAAAFIlMSikVNDCTqe65UJ36TV/1PiuBgSpSYEmhhqjdAFRE7a5b1G4AKlJI7bbCd32xqlBX2AsAAAAARUPguz4R7gIAAABAUdPSAYAq42OhdYvaDUBF1O66Re0GoCJaOgAAAAAArEcEvgAAAAAARULgCwAAAABQJAS+AAAAAABFQuALAAAAAFAkBL4AAAAAAEVC4AsAAAAAUCQEvgAAAAAARULgCwAAAABQJBrU9gRgnTX+7//9/8O/W3vzAAAAAID/EPhS3C6ZXv7287pW7e2sGP5GCIABAAAAqBWZlFIqaGAmU/mj331z+duHjKj8sWBNrCrwjaia0HfloHdFQl/WQwWWFGrIGtVuANYranfdonYDUJFCanf1rfBdVdgLdcWKYXBVr/iN+G8YLPgFAAAAoIZUz0XbhL2sL4S5AAAAANQh1RP4wrrmkumrb/+wNlbX9gEAAAAAqpDAF1ZUXaEvAAAAANSA2gl8tXygmGjrAAAAAEAdYYUvxa06LsZWnopCX20dAAAAAKgBVR/4Wr1LXVNo6Hte17ULiK30BQAAAKCWZVJKqaCBmUxhRyw08B0yorBxUJVW1aO3qlcCr2pF7/oSCt/5s7LbDr665udBjSuwpFBDCq7dAKy31O66Re0GoCKF1O6qDXwru7pX6EuxWzn4LebAt7yQd3UEwEXJm8a6xZtGACqidtctajcAFSmkduvhC9Xp8O8Wd8ibVdmwN/s9a/J9AAAAAKxSg9qeAKwXijn0FdoCAAAA1BlVt8J3TS7W5gJvsG6rirBXYAwAAABQZbR0AGqf0BcAAACgSgh8gbpB6AsAAACw1gS+AAAAAABFovYDX318AQAAAACqRO0HvgAAAAAAVAmBLwAAAABAkagbga+2DgAAAAAAa63qAt8hI6rsUMB66OCra3sGAAAAAOu8ql3hK/QF1oSwFwAAAKBKVH1LB6EvAAAAAECtqJ4evkJfoFBW9wIAAABUmbpx0TYAAAAAANaawBcAAAAAoEg0qLYjZ9s63H1ztd0EsA7TygEAAACgylX/Cl/9fAEAAAAAakT1rfBd0ZARVvoC37CyFwAAAKDa1EzgG2GlLwAAAABANau5wBdYv1nZCwAAAFDtqr+HLwAAAAAANULgC1Q/q3sBAAAAaoTAFwAAAACgSAh8AQAAAACKhMAXqF7aOQAAAADUmAa1PQGgSAl6AQAAAGqcFb5A1RP2AgAAANQKgS8AAAAAQJEQ+AJVy+peAAAAgFqTSSmlggZmMtU9F2BddOfPvvmvoJeIKLCkUEPUbgAqonbXLWo3ABUppHZb4QsAAAAAUCQEvgAAAAAARUJLBwCqjI+F1i1qNwAVUbvrFrUbgIpo6QAAAAAAsB4R+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBL9RVv/vPPwAAAAAokMAX6jrBLwAAAAAFyqSUUkEDM5nqngsQsfpw96gamwWskQJLCjVE7QagImp33aJ2A1CRQmq3Fb6wLrHaFwAAAIDVEPhCXVJomCv0BQAAAKAcAl8AAAAAgCIh8AUAAAAAKBICXwAAAACAIiHwhXXRUbU9AQAAAADqIoEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+MK6Rv9eAAAAAFZB4AsAAAAAUCQEvgAAAAAARSKTUkoFDcxkqnsuQNbvytmmlQPrgAJLCjVE7QagImp33aJ2A1CRQmq3wJeaM+k//927VmcBVCNvGusWtRuAiqjddYvaDUBFCqndWjoAAAAAABQJgS81b1L8d7UvAAAAAFBlCg98p1bjLFg/CX0BAAAAoEpVboWv0BcAAAAAoM6qfEsHoS8AAAAAQJ2khy8AAAAAQJFYs8DXKl+qij6+AAAAAFBlrPCl5uxd2xMAAAAAgOIm8KVmCX0BAAAAoNoIfAEAAAAAioTAl5pnlS8AAAAAVAuBL7VD6AsAAAAAVU7gCwAAAABQJAS+1B6rfAEAAACgSgl8qX2TansCAAAAAFAcBL4AAAAAAEVC4Evt0tYBAAAAAKqMwJe6QVsHAAAAAFhrmZRSKmjgvzLf/M8W1TkdANZlBZYUakgmk6ntKQBQx6nddYvaDUBFCqndVvgCAAAAABSJygW+VvcCAAAAANRZhbd08NESACrgY6F1i9oNQEXU7rpF7QagIlo6sG5ZXNsTAAAAAIB1m8CXukHYCwAAAABrTeALAAAAAFAkBL7UvsUr/b/VvgAAAACwRgS+AAAAAABFQuBL7bKaFwAAAACqjMCXuklrBwAAAACoNIEvAAAAAECREPhSt1npCwAAAAAFa1DbE4CCLI6IktqeBMXk4pT/9QWZ2pkHAAAAQFWywpd1h5W+VKOVA2AAAACAdZHAl3WL0JdqdHES/AIAAADrNoEvwEqEvgAAAMC6SuDLuscqX1bw9oJv/lU1q30BAACAdZHAF1indWv2zX+rK/gFAAAAWJcIfKk9VupSDbLBb1WFv1b5AgAAAOuSTEqpoDgjk8lU91xYn6xt2FtSJbOgiBQS8GZXA0esWZB7gZfBChVYUqghajcAFVG76xa1G4CKFFK7rfAFisKKYe6qaPkAAAAAFDuBLzVPKweqidAXAAAAWN9p6UDNWxxaMlBtCg10uzVb8/68Wjusmo+F1i1qNwAVUbvrFrUbgIoUUrsFvtQ8gS/VqDIreNcm9I0Q/JbHm8a6Re0GoCJqd92idgNQET18qZuEvVSjQto6ZL29QGgLAAAAFBeBL1B0air0XZvVwQAAAADVQUsHoChV9uJsK4bElQ1yrRL+Lx8LrVvUbgAqonbXLWo3ABXR0gFYb1VmlW9E5QPiFVnpCwAAANQVAl+A/8iGvhdkrNoFAAAA1k0CX4AVrLjSV/ALAAAArGsEvgAVEPwCAAAA6wqBLwAAAABAkRD4AkWrshduq4iVvgAAAEBd16C2JwBQnbKh74q9edfWiqHvxanqjgsAAACwtjIppYLiikzGsjZg3VZo6FvVK4PXJwWWFGqI2g1ARdTuukXtBqAihdRuLR2A9YYgFwAAACh2VvjCGkiPrPn3ZgZU3TygrrFKqG5RuwGoiNpdt6jdAFSkkNot8IUCrU3IuzKh7/rtq6lltzXZoubnUR28aaxb1G4AKqJ21y1qNwAV0dIBqkhVhr1QnvJCYAAAAIDKalDbE4C6TNBLTfpqavGs9AUAAABqh8AXyiHoBQAAAGBdpKUDrETYS23S2gEAAABYGwJfgDpG6AsAAACsKS0d4D+s7AUAAABgXWeFLwAAAABAkRD4AgAAAAAUCYEvhHYOAAAAABQHgS8AAAAAQJEQ+ALUQV9Nre0ZAAAAAOsigS8AAAAAQJEQ+AIAAAAAFAmBL9SwzIDangG1rckWtT0DAAAAoFgJfAFqgdAXAAAAqA4NansCsL6wspeqkg4rbFzmtuqdBwAAAFD3WOFLhRbU9gSqWXqk+m9D2EtVKTTsBQAAANZPAl8q1Cy+CX2LPfitLsJeqkplw17hMAAAAKx/MimlVNDATKa650IdVl7Y26zGZ1H1qnN1r6CXQnw1ddX7Vuzzu7bhbU21dyiwpFBD1G4AKqJ21y1qNwAVKaR2W+FLQYoh3K1Jwl4AAAAAaoPAFwAAAACgSAh8KdjKq3z19C2f1b1Uhaps5wAAAACsPxrU9gSgWAh6WRNNtlh9H19hLwAAAFAZVviyVtb1Vb5CWtYHNXXBNgAAAKD2WeFLpTSLdT/krWpCY6qL1b0AAABAZWVSSqmggZlMdc+FdUh5oe/KPX7XJemRyo0X8lIT1jbwrY2VvQWWFGqI2g1ARdTuukXtBqAihdRuK3yhEgS91JR1MewFAAAAap/AlzWitQPUTYJeAAAAWL8JfKkyKwbA63J7hxVZ0cu6QtALAAAARETUq+0JsO5aXahbDKt/hb2sK4S9AAAAQJbAl7XSLFYd/C6IdSf4XTHczQwQ9rLuEPYCAAAAK9LSgSqxup6+C2LdaPGQGRCRHqntWUDFhLwAAADAqmRSSqmggZlMdc+FIrGq4HddCH2BtVNgSaGGqN0AVETtrlvUbgAqUkjt1tKBKre6Ng8AAAAAQPUR+FJthL4AAAAAULP08KVaCX0BAAAAoOZY4QsAAAAAUCQEvgAAAAAARULgCwAAAABQJAS+AAAAAABFQuALAAAAAFAkBL4AAAAAAEVC4AsAAAAAUCQEvgAAAAAARULgCwAAAABQJAS+AAAAAABFQuALAAAAAFAkGtT2BGBdM3WF/9+i1mYBAAAAAGVZ4QuVMLWCrwEAAACgNgl8YS0JfQEAAACoKwS+AAAAAABFQuALVcAqXwAAAADqAoEvAAAAAECREPhCFbHKFwAAAIDaJvAFAAAAACgSAl+oQlb5AgAAAFCbBL4AAAAAAEVC4AsFsnoXAAAAgLpO4AsAAAAAUCQEvgAAAAAARULgCwAAAABQJAS+AAAAAABFYq0C3xc6dIgXOnSoqrlAnbbFWu4HAAAAgOqWSSmlggZmMmW2rSrs7fnhh2s3K4C19MILLxQ8tmfPntU4k/VLgSWFGlJe7QaAFanddYvaDUBFCqnd1RL4Rgh9gZpXmZB3ZULfquFNY93iTSMAFVG76xa1G4CKVGvgW5lWDsJfoLqsTchbHsHv2vGmsW7xphGAiqjddYvaDUBFqi3wrWzfXoEvUB2qOuxdmfC38rxprFu8aQSgImp33aJ2A1CRQmr3Wl20DaC2VHfYW1O3AQAAAFCVKh34VnZ1L0BVE8QCAAAAlE8PX2CdUVtBr9YOhfOx0LrFx0IBqIjaXbeo3QBUpFpbOghxgZpUm6t6rSgGAAAA1hVr1cNX6AusL4S+AAAAwLpgrS/a1vPDDwW/AAAAAAB1wFoHvllCX6C61JXVtXVlHgAAAACr0qAqD7Zi6FuZi7oBrIqQFQAAAKBwmVTgZVldLRSoDXUx8O3Zs2dtT6HOcqXvukXtBqAianfdonYDUJFCaneVtXQAqGp1MeyNqLvzAgAAABD4AqwBoS8AAABQFwl8gTpJoAoAAABQeQJfAAAAAIAiIfAFAAAAACgSAl8AAAAAgCLRoLYnALAqPXv2rO0pAAAAAKxTMimlVNDATKa65wLAOq7AkkINUbsBqIjaXbeo3QBUpJDaXXDgCwAAAABA3aaHLwAAAABAkRD4AgAAAAAUCYEvAAAAAECREPgCAAAAABQJgS8AAAAAQJEQ+AIAAAAAFAmBLwAAAABAkRD4AgAAAAAUCYEvAAAAAECR+H8hkQMwezrQtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "# --- Configuration (Set these variables based on your environment) ---\n",
    "# NOTE: The predictions must already be saved by the previous code!\n",
    "\n",
    "# Assuming 'val_len' was the last index processed or you choose a specific index (e.g., 0)\n",
    "val_index_to_view = 0 \n",
    "test_name = get_id_from_file_path(test_img[val_index_to_view], '.png')\n",
    "\n",
    "# Assuming opts['result_save_path'] is defined as in your code\n",
    "# Replace this with the actual base path if 'opts' is not accessible\n",
    "BASE_SAVE_PATH = opts['result_save_path'] \n",
    "\n",
    "# Define paths to the saved images\n",
    "GT_LABEL = validation_set_label[val_index_to_view]\n",
    "UNET_PATH = BASE_SAVE_PATH + 'validation/unet/{}.png'.format(test_name)\n",
    "WS_PATH = BASE_SAVE_PATH + 'validation/watershed_unet/{}.png'.format(test_name)\n",
    "\n",
    "# --- Load the saved predictions ---\n",
    "try:\n",
    "    unet_pred = imread(UNET_PATH)\n",
    "    ws_pred = imread(WS_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Prediction files not found. Ensure the previous code ran and saved the files correctly.\")\n",
    "    # Fallback/Debug: You might try displaying the final in-memory variables if available\n",
    "    # print(\"Attempting to show in-memory variables...\")\n",
    "    # unet_pred = output_raw # Only works if run right after the loop\n",
    "    # ws_pred = output_watershed\n",
    "    \n",
    "    # If using in-memory variables, ensure you remap them again:\n",
    "    # unet_pred = remap_label(unet_pred)\n",
    "    # ws_pred = remap_label(ws_pred)\n",
    "    # GT_LABEL = remap_label(validation_set_label[val_index_to_view])\n",
    "    \n",
    "    \n",
    "# --- Visualization ---\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "titles = [\"Ground Truth Label\", \"Pure U-Net Output\", \"U-Net + Watershed Output\"]\n",
    "images = [GT_LABEL, unet_pred, ws_pred]\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    # Use 'viridis' colormap for labeled images to distinguish instances\n",
    "    ax.imshow(img, cmap='nipy_spectral', interpolation='none')\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Predictions for Image: {test_name}\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15433938",
   "metadata": {
    "papermill": {
     "duration": 0.524404,
     "end_time": "2025-11-06T14:48:41.849498",
     "exception": false,
     "start_time": "2025-11-06T14:48:41.325094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1911713,
     "sourceId": 5909621,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4460.382426,
   "end_time": "2025-11-06T14:48:45.937239",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-06T13:34:25.554813",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
